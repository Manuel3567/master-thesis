{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX\n",
    "- Autoregression model where the value at index t depends on the value at index value t - 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from analysis.datasets import load_entsoe\n",
    "from analysis.transformations import scale_power_data, add_lagged_features, add_interval_index\n",
    "from analysis.splits import to_train_validation_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['power_t-96']\n",
    "target_column='power'\n",
    "\n",
    "entsoe = load_entsoe()\n",
    "entsoe = scale_power_data(entsoe)\n",
    "entsoe = add_lagged_features(entsoe)\n",
    "entsoe = add_interval_index(entsoe)\n",
    "entsoe.dropna(inplace=True)\n",
    "\n",
    "train_end = \"2022-12-31 23:45:00\"\n",
    "#train_end = \"2016-01-31 23:45:00\"\n",
    "#train_end = \"2016-12-31 23:45:00\"\n",
    "\n",
    "\n",
    "validation_end = \"2023-12-31 23:45:00\"\n",
    "#validation_end = \"2023-12-31 23:45:00\"\n",
    "#validation_end = \"2017-12-31 23:45:00\"\n",
    "\n",
    "train, validation, test = to_train_validation_test_data(entsoe, train_end, validation_end)\n",
    "X_train, y_train = train[feature_columns], train[target_column]\n",
    "X_validation, y_validation = validation[feature_columns], validation[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array = y_train.values\n",
    "y_train_array = y_train_array.astype(np.float32)  # Downcast to float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-01-01 00:00:00   -0.539165\n",
       "2023-01-01 00:15:00   -0.518601\n",
       "2023-01-01 00:30:00   -0.555433\n",
       "2023-01-01 00:45:00   -0.509552\n",
       "2023-01-01 01:00:00   -0.552363\n",
       "                         ...   \n",
       "2023-12-31 22:45:00   -0.756651\n",
       "2023-12-31 23:00:00   -0.740979\n",
       "2023-12-31 23:15:00   -0.755649\n",
       "2023-12-31 23:30:00   -0.747790\n",
       "2023-12-31 23:45:00   -0.726035\n",
       "Name: power, Length: 35040, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.3242364, -3.2381785, -3.171487 , ..., -1.1947993, -1.1830175,\n",
       "       -1.1789933], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vielleicht apply Methode von model für die prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                SARIMAX Results                                 \n",
      "================================================================================\n",
      "Dep. Variable:                        y   No. Observations:               245376\n",
      "Model:             SARIMAX(1, 0, 0, 96)   Log Likelihood             -384385.614\n",
      "Date:                  Wed, 19 Mar 2025   AIC                         768775.228\n",
      "Time:                          16:15:40   BIC                         768796.049\n",
      "Sample:                               0   HQIC                        768781.302\n",
      "                               - 245376                                         \n",
      "Covariance Type:                 approx                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.S.L96       0.8663      0.001    860.802      0.000       0.864       0.868\n",
      "sigma2         1.3426      0.004    350.272      0.000       1.335       1.350\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):              243980.12   Jarque-Bera (JB):              6564.90\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.88   Skew:                            -0.10\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         3.77\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using numerical (complex-step) differentiation.\n"
     ]
    }
   ],
   "source": [
    "model = SARIMAX(endog=y_train_array,\n",
    "                order=(0,0,0),\n",
    "                seasonal_order=(1,0,0,96), trend_offset=0)\n",
    "model.ssm.memory_no_filtered = True\n",
    "model.ssm.memory_no_gain = True\n",
    "model.ssm.memory_no_smoothing = True\n",
    "model.ssm.memory_no_std_forecast = True\n",
    "\n",
    "result = model.fit(low_memory=True)\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency 15min will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency 15min will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper at 0x2c6c550a6f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.apply(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) + 2880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "248256 - 245376 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-01-31 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.index[2880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_t-96   -1.415892\n",
       "Name: 2023-01-30 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.iloc[2880-96] * result.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_validation = X_validation.iloc[2880:2891].values  # 11 steps (from 2880 to 2890), one for each forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.3242364 , -3.2381785 , -3.171487  , ..., -0.54807967,\n",
       "       -0.5207769 , -0.54981107], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245376,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.47559870000000004"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.549*0.8663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdynamic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minformation_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predicted'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msignal_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "predict(self, start=None, end=None, dynamic=False, information_set='predicted', signal_only=False, **kwargs)\n",
      "\n",
      "In-sample prediction and out-of-sample forecasting\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "start : {int, str,datetime}, optional\n",
      "    Zero-indexed observation number at which to start forecasting,\n",
      "    i.e., the first forecast is start. Can also be a date string to\n",
      "    parse or a datetime type. Default is the zeroth observation.\n",
      "end : {int, str,datetime}, optional\n",
      "    Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "    the last forecast is end. Can also be a date string to\n",
      "    parse or a datetime type. However, if the dates index does not\n",
      "    have a fixed frequency, end must be an integer index if you\n",
      "    want out of sample prediction. Default is the last observation in\n",
      "    the sample.\n",
      "dynamic : {bool, int, str,datetime}, optional\n",
      "    Integer offset relative to `start` at which to begin dynamic\n",
      "    prediction. Can also be an absolute date string to parse or a\n",
      "    datetime type (these are not interpreted as offsets).\n",
      "    Prior to this observation, true endogenous values will be used for\n",
      "    prediction; starting with this observation and continuing through\n",
      "    the end of prediction, forecasted endogenous values will be used\n",
      "    instead.\n",
      "information_set : str, optional\n",
      "    The information set to condition each prediction on. Default is\n",
      "    \"predicted\", which computes predictions of period t values\n",
      "    conditional on observed data through period t-1; these are\n",
      "    one-step-ahead predictions, and correspond with the typical\n",
      "    `fittedvalues` results attribute. Alternatives are \"filtered\",\n",
      "    which computes predictions of period t values conditional on\n",
      "    observed data through period t, and \"smoothed\", which computes\n",
      "    predictions of period t values conditional on the entire dataset\n",
      "    (including also future observations t+1, t+2, ...).\n",
      "signal_only : bool, optional\n",
      "    Whether to compute predictions of only the \"signal\" component of\n",
      "    the observation equation. Default is False. For example, the\n",
      "    observation equation of a time-invariant model is\n",
      "    :math:`y_t = d + Z \\alpha_t + \\varepsilon_t`, and the \"signal\"\n",
      "    component is then :math:`Z \\alpha_t`. If this argument is set to\n",
      "    True, then predictions of the \"signal\" :math:`Z \\alpha_t` will be\n",
      "    returned. Otherwise, the default is for predictions of :math:`y_t`\n",
      "    to be returned.\n",
      "**kwargs\n",
      "    Additional arguments may be required for forecasting beyond the end\n",
      "    of the sample. See ``FilterResults.predict`` for more details.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "predictions : array_like\n",
      "    In-sample predictions / Out-of-sample forecasts. (Numpy array or\n",
      "    Pandas Series or DataFrame, depending on input and dimensions).\n",
      "    Dimensions are `(npredict x k_endog)`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "forecast\n",
      "    Out-of-sample forecasts.\n",
      "get_forecast\n",
      "    Out-of-sample forecasts and results including confidence intervals.\n",
      "get_prediction\n",
      "    In-sample predictions / out-of-sample forecasts and results\n",
      "    including confidence intervals.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\minu\\documents\\master-thesis\\.venv\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "result.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.87 GiB for an array with shape (96, 96, 100001) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3538\u001b[0m, in \u001b[0;36mMLEResults.forecast\u001b[1;34m(self, steps, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3537\u001b[0m     end \u001b[38;5;241m=\u001b[39m steps\n\u001b[1;32m-> 3538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3539\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3488\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3425\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3485\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3487\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3488\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3366\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3363\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;66;03m# This is a (k_endog x npredictions) array; do not want to squeeze in\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;66;03m# case of npredictions = 1\u001b[39;00m\n\u001b[1;32m-> 3366\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_of_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;66;03m# Return a new mlemodel.PredictionResults object\u001b[39;00m\n\u001b[0;32m   3370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResultsWrapper(PredictionResults(\n\u001b[0;32m   3371\u001b[0m     \u001b[38;5;28mself\u001b[39m, prediction_results, information_set\u001b[38;5;241m=\u001b[39minformation_set,\n\u001b[0;32m   3372\u001b[0m     signal_only\u001b[38;5;241m=\u001b[39msignal_only, row_labels\u001b[38;5;241m=\u001b[39mprediction_index))\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:2096\u001b[0m, in \u001b[0;36mFilterResults.predict\u001b[1;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m   2093\u001b[0m         model\u001b[38;5;241m.\u001b[39mendog[:, \u001b[38;5;241m-\u001b[39m(ndynamic \u001b[38;5;241m+\u001b[39m nforecast):] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfixed_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale):\n\u001b[1;32m-> 2096\u001b[0m         oos_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResults(results, start, end, nstatic, ndynamic,\n\u001b[0;32m   2101\u001b[0m                          nforecast, oos_results\u001b[38;5;241m=\u001b[39moos_results)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:970\u001b[0m, in \u001b[0;36mKalmanFilter.filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_conserve_memory(conserve_memory)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m--> 970\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# Create the results object\u001b[39;00m\n\u001b[0;32m    975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_class(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:913\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    909\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    918\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:501\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Setup the filter\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_kalman_filter_map[prefix]\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Otherwise, update the filter parameters\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     kalman_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1720\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:2131\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.set_filter_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1911\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.87 GiB for an array with shape (96, 96, 100001) and data type float64"
     ]
    }
   ],
   "source": [
    "result.forecast(steps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -2.14080707e-13, -1.14485313e-13, -3.63602807e-13,\n",
       "       -4.55942043e-13, -3.91198519e-13, -3.68881079e-13, -2.75452492e-13,\n",
       "       -2.03141404e-13, -1.81327367e-13,  3.96616796e-14])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.predict(start=0, end=10, exog=y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00615951, -0.00611883, -0.00652127, -0.00668328, -0.00688716,\n",
       "       -0.00709087, -0.00741817, -0.00782718, -0.00773889, -0.00813743,\n",
       "       -0.00804814])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = result.predict(start=len(y_train) + 2880, end=len(y_train) + 2890, exog=exog_validation)\n",
    "sigma = np.sqrt(result.params[1])\n",
    "mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m z \u001b[38;5;241m=\u001b[39m (y_validation \u001b[38;5;241m-\u001b[39m mus) \u001b[38;5;241m/\u001b[39m sigma\n\u001b[0;32m      3\u001b[0m crps_score \u001b[38;5;241m=\u001b[39m sigma \u001b[38;5;241m*\u001b[39m ( \n\u001b[1;32m----> 4\u001b[0m     z \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mnorm\u001b[49m\u001b[38;5;241m.\u001b[39mcdf(z) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m norm\u001b[38;5;241m.\u001b[39mpdf(z) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mpi)\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get mean CRPS\u001b[39;00m\n\u001b[0;32m      8\u001b[0m mean_crps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(crps_score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'norm' is not defined"
     ]
    }
   ],
   "source": [
    "z = (y_validation - mus) / sigma\n",
    "\n",
    "crps_score = sigma * ( \n",
    "    z * (2 * norm.cdf(z) - 1) + 2 * norm.pdf(z) - 1 / np.sqrt(np.pi)\n",
    ")\n",
    "\n",
    "# Get mean CRPS\n",
    "mean_crps = np.mean(crps_score)\n",
    "\n",
    "print(f\"Mean CRPS: {mean_crps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minu\\AppData\\Local\\Temp\\ipykernel_20696\\4221127032.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  nll= - norm.logpdf(y_validation[i], loc=mus[i], scale=sigma)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1238171828569565"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_hand = []\n",
    "\n",
    "for i in range(0, y_validation.shape[0]):\n",
    "    nll= - norm.logpdf(y_validation[i], loc=mus[i], scale=sigma)\n",
    "    nll_hand.append(nll)\n",
    "\n",
    "np.mean(nll_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1723222"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_validation_array = y_validation.values\n",
    "#y_validation_array = y_validation_array.astype(np.float32)  # Downcast to float32\n",
    "#y_validation_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-01 00:00:00')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train.iloc[-96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35040"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 00:00:00')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[-96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 23:45:00')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[len(y_train) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMAX\n",
    "1. \"start\" tells the model where the prediction begins. The model has been trained on training data and it knows what the last entry is. SARIMAX automatically infers that the next time step is 2017-01-01 00:00:00 based on the spacing of y_train.\n",
    "2. Since the model was trained with seasonal_order=(1,0,0,96), it learned a relationship between y(t) and y(t-96).\n",
    "3. SARIMAX looks back 96 time steps (24h ago) from the \"start\" parameter and multiplies that value by a learned coefficient (ϕ₁).\n",
    "4. The \"end\" parameter tells the model where the prediction stops\n",
    "\n",
    "e.g. if y_train ends 2016-12-31 23:45 and you want to make a single prediction of the power of the next 15-minute time interval i.e. 2017-01-01 00:00\n",
    "- start = length of y_train\n",
    "- end = len(y_train)\n",
    "- Power_2017-01-01 00:00 = Power_shifted_by_96 (Power_2016-12-31 00:00) * ϕ₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.19257455 -1.18142727 -1.16496504]\n"
     ]
    }
   ],
   "source": [
    "exog_validation = y_train.iloc[-96]  # Take the last value in y_train as the regressor corresponds to '2016-12-31 00:00:00'\n",
    "\n",
    "# y_validation.index[0] = Timestamp('2017-01-01 00:00:00')\n",
    "\n",
    "# Predict the first value in y_validation using the model\n",
    "mu = result.predict(start=len(y_train), end=len(y_train) + 2)#, exog=[exog_validation])\n",
    "    #start = predict the next value after training data\n",
    "    #end = The time index (or date) where prediction stops\n",
    "\n",
    "# Print the prediction\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 23:45:00')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 00:00:00')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[-96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 00:15:00')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[-95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-31 00:30:00')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index[-94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1925745941492316"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_test = y_train.iloc[-96] * result.params[0] #ar.S.L96 = 0.8850\n",
    "# power at 2017-01-01 00:00:00 = power value at 2016-12-31 00:00:00 * learned parameter\n",
    "mu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1925745941492316\n",
      "-1.1814272185858108\n",
      "-1.1649650821269129\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[-96] * result.params[0]) # power at 2016-12-31 00:00:00 * learned parameter\n",
    "print(y_train.iloc[-95] * result.params[0]) # power at 2016-12-31 00:15:00 * learned parameter\n",
    "print(y_train.iloc[-94] * result.params[0]) # power at 2016-12-31 00:30:00 * learned parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power_t-96   -1.192575\n",
      "Name: 2017-01-01 00:00:00, dtype: float64\n",
      "power_t-96   -1.181427\n",
      "Name: 2017-01-01 00:15:00, dtype: float64\n",
      "power_t-96   -1.164965\n",
      "Name: 2017-01-01 00:30:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_validation.iloc[0] * result.params[0]) # first entry in X validation = y_train.iloc[-96]\n",
    "print(X_validation.iloc[1] * result.params[0])\n",
    "print(X_validation.iloc[2] * result.params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3475262390582907"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_validation[\"power_t-96\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.34752624, -1.33493048, -1.31632941, ..., -0.31229626,\n",
       "       -0.3231264 , -0.33959475])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_validation).squeeze().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.41 GiB for an array with shape (96, 96, 35040) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_mean \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredicted_mean\n\u001b[0;32m      2\u001b[0m y_pred_mean\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3366\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3363\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;66;03m# This is a (k_endog x npredictions) array; do not want to squeeze in\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;66;03m# case of npredictions = 1\u001b[39;00m\n\u001b[1;32m-> 3366\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_of_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;66;03m# Return a new mlemodel.PredictionResults object\u001b[39;00m\n\u001b[0;32m   3370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResultsWrapper(PredictionResults(\n\u001b[0;32m   3371\u001b[0m     \u001b[38;5;28mself\u001b[39m, prediction_results, information_set\u001b[38;5;241m=\u001b[39minformation_set,\n\u001b[0;32m   3372\u001b[0m     signal_only\u001b[38;5;241m=\u001b[39msignal_only, row_labels\u001b[38;5;241m=\u001b[39mprediction_index))\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:2096\u001b[0m, in \u001b[0;36mFilterResults.predict\u001b[1;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m   2093\u001b[0m         model\u001b[38;5;241m.\u001b[39mendog[:, \u001b[38;5;241m-\u001b[39m(ndynamic \u001b[38;5;241m+\u001b[39m nforecast):] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfixed_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale):\n\u001b[1;32m-> 2096\u001b[0m         oos_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResults(results, start, end, nstatic, ndynamic,\n\u001b[0;32m   2101\u001b[0m                          nforecast, oos_results\u001b[38;5;241m=\u001b[39moos_results)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:970\u001b[0m, in \u001b[0;36mKalmanFilter.filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_conserve_memory(conserve_memory)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m--> 970\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# Create the results object\u001b[39;00m\n\u001b[0;32m    975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_class(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:913\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    909\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    918\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:501\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Setup the filter\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_kalman_filter_map[prefix]\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Otherwise, update the filter parameters\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     kalman_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1720\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:2131\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.set_filter_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1882\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.41 GiB for an array with shape (96, 96, 35040) and data type float64"
     ]
    }
   ],
   "source": [
    "y_pred_mean = result.get_prediction(start=start, end=end).predicted_mean\n",
    "y_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 567. MiB for an array with shape (96, 96, 8065) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mstart_date, end\u001b[38;5;241m=\u001b[39mend_date, freq\u001b[38;5;241m=\u001b[39minterval_length):\n\u001b[0;32m     10\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m interval_length, end_date) \u001b[38;5;66;03m#prevent exceeding the total validation period (ensure the end date is capped at end_date)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mextend(pred)\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3488\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3425\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3485\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3487\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3488\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3366\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, includes_fixed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3363\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;66;03m# This is a (k_endog x npredictions) array; do not want to squeeze in\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;66;03m# case of npredictions = 1\u001b[39;00m\n\u001b[1;32m-> 3366\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_of_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;66;03m# Return a new mlemodel.PredictionResults object\u001b[39;00m\n\u001b[0;32m   3370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResultsWrapper(PredictionResults(\n\u001b[0;32m   3371\u001b[0m     \u001b[38;5;28mself\u001b[39m, prediction_results, information_set\u001b[38;5;241m=\u001b[39minformation_set,\n\u001b[0;32m   3372\u001b[0m     signal_only\u001b[38;5;241m=\u001b[39msignal_only, row_labels\u001b[38;5;241m=\u001b[39mprediction_index))\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:2096\u001b[0m, in \u001b[0;36mFilterResults.predict\u001b[1;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m   2093\u001b[0m         model\u001b[38;5;241m.\u001b[39mendog[:, \u001b[38;5;241m-\u001b[39m(ndynamic \u001b[38;5;241m+\u001b[39m nforecast):] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfixed_scale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale):\n\u001b[1;32m-> 2096\u001b[0m         oos_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PredictionResults(results, start, end, nstatic, ndynamic,\n\u001b[0;32m   2101\u001b[0m                          nforecast, oos_results\u001b[38;5;241m=\u001b[39moos_results)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:970\u001b[0m, in \u001b[0;36mKalmanFilter.filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_conserve_memory(conserve_memory)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m--> 970\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# Create the results object\u001b[39;00m\n\u001b[0;32m    975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_class(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:913\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    909\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    918\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:501\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Setup the filter\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_kalman_filter_map[prefix]\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Otherwise, update the filter parameters\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     kalman_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1720\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:2131\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.set_filter_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\\\tsa\\\\statespace\\\\_kalman_filter.pyx:1882\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 567. MiB for an array with shape (96, 96, 8065) and data type float64"
     ]
    }
   ],
   "source": [
    "start_date = y_validation.index[0]\n",
    "end_date = y_validation.index[-1]\n",
    "\n",
    "interval_length = pd.Timedelta(weeks=12)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for start in pd.date_range(start=start_date, end=end_date, freq=interval_length):\n",
    "\n",
    "    end = min(start + interval_length, end_date) #prevent exceeding the total validation period (ensure the end date is capped at end_date)\n",
    "    \n",
    "    pred = result.predict(start=start, end=end)\n",
    "    \n",
    "    y_pred.extend(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## per hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minu\\AppData\\Local\\Temp\\ipykernel_19592\\3158187406.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_validation[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.1723221500332002"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3475262"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1730858396600932"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.sqrt(result.params[\"sigma2\"])\n",
    "\n",
    "np.sqrt(result.params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minu\\AppData\\Local\\Temp\\ipykernel_19592\\394194632.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  single_nll = - norm.logpdf(y_validation[0], loc=mu[0], scale=np.sqrt(result.params[1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0897294586014523"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = X_alidation_array[0]\n",
    "single_nll = - norm.logpdf(y_validation[0], loc=mu[0], scale=np.sqrt(result.params[1]))\n",
    "single_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CRPS: 1.1446\n"
     ]
    }
   ],
   "source": [
    "import properscoring as ps\n",
    "\n",
    "crps_ps = ps.crps_gaussian(y_validation, mu=y_pred, sig=sigma)\n",
    "mean_crps = np.mean(crps_ps)  # Average over all time steps\n",
    "\n",
    "print(f\"Mean CRPS: {mean_crps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CRPS: 1.1446\n"
     ]
    }
   ],
   "source": [
    "mu = y_pred\n",
    "sigma = np.sqrt(result.params[\"sigma2\"])\n",
    "\n",
    "z = (y_validation - y_pred) / sigma\n",
    "\n",
    "crps_score = sigma * ( \n",
    "    z * (2 * norm.cdf(z) - 1) + 2 * norm.pdf(z) - 1 / np.sqrt(np.pi)\n",
    ")\n",
    "\n",
    "# Get mean CRPS\n",
    "mean_crps = np.mean(crps_score)\n",
    "\n",
    "print(f\"Mean CRPS: {mean_crps:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with properscoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CRPS: 1.1446\n"
     ]
    }
   ],
   "source": [
    "import properscoring as ps\n",
    "\n",
    "crps_ps = ps.crps_gaussian(y_validation, mu=y_pred, sig=sigma)\n",
    "mean_crps = np.mean(crps_ps)  # Average over all time steps\n",
    "\n",
    "print(f\"Mean CRPS: {mean_crps:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL: 3867.9798\n"
     ]
    }
   ],
   "source": [
    "nll = -result.llf  # llf = log-likelihood function value\n",
    "print(f\"NLL: {nll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_t-96   -3.171487\n",
       "Name: 2016-01-03 00:30:00, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[96+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_t-96</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:00:00</th>\n",
       "      <td>-2.465104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:15:00</th>\n",
       "      <td>-2.499602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:30:00</th>\n",
       "      <td>-2.485377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:45:00</th>\n",
       "      <td>-2.451358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 01:00:00</th>\n",
       "      <td>-2.405335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 22:45:00</th>\n",
       "      <td>-1.397653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:00:00</th>\n",
       "      <td>-1.400990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:15:00</th>\n",
       "      <td>-1.385354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:30:00</th>\n",
       "      <td>-1.372740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 23:45:00</th>\n",
       "      <td>-1.356165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     power_t-96\n",
       "time                           \n",
       "2016-01-02 00:00:00   -2.465104\n",
       "2016-01-02 00:15:00   -2.499602\n",
       "2016-01-02 00:30:00   -2.485377\n",
       "2016-01-02 00:45:00   -2.451358\n",
       "2016-01-02 01:00:00   -2.405335\n",
       "...                         ...\n",
       "2016-12-31 22:45:00   -1.397653\n",
       "2016-12-31 23:00:00   -1.400990\n",
       "2016-12-31 23:15:00   -1.385354\n",
       "2016-12-31 23:30:00   -1.372740\n",
       "2016-12-31 23:45:00   -1.356165\n",
       "\n",
       "[35040 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.171487202624057"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model = SARIMAX(endog=y_train, exog=X_train,\n",
    "                order=(0,0,0),\n",
    "                seasonal_order=(1,0,0,96))\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MemoryError: Unable to allocate 2.41 GiB for an array with shape (35040, 96, 96) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(1,0,0)\n",
      "Coefficients: [0.83832727]\n",
      "Intercept: 0.0\n",
      "p_t = 0.0 + 0.8383272710424725 * p_t-1 + 0.0 * t\n",
      "Mean Squared Error (MSE): 0.9543466840203708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_lin = LinearRegression(fit_intercept=False)\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_lin.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"ARIMA(1,0,0)\")\n",
    "print(\"Coefficients:\", model_lin.coef_)\n",
    "print(\"Intercept:\", model_lin.intercept_)\n",
    "print(f\"p_t = {model_lin.intercept_} + {model_lin.coef_[0]} * p_t-1 + {model_lin.intercept_} * t\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40095893]\n",
      "-1.0539988781295424\n"
     ]
    }
   ],
   "source": [
    "print(model_lin.coef_)\n",
    "print(model_lin.intercept_)\n",
    "#print(model_lin.score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2688,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
