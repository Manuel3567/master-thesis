{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of the `evaluate_model` Function\n",
    "\n",
    "## 1. **Function Definition and Parameters**\n",
    "The function `evaluate_model` takes in the following parameters:\n",
    "- `entsoe`: A DataFrame containing power data\n",
    "- `target_column`: Column name containing the target variable (default: 'power')\n",
    "- `dist`: Probability distribution (default: LogNormal)\n",
    "- `case`: Integer determining feature selection and loss function\n",
    "- `n_estimators`: Number of boosting iterations (default: 100)\n",
    "- `learning_rate`: Learning rate for the NGBoost model (default: 0.03)\n",
    "- `random_state`: Random seed (default: 42)\n",
    "- `output_file`: File path for saving results\n",
    "\n",
    "## 2. **Preprocessing the Data**\n",
    "- **Scaling the Power Data**:\n",
    "  - The maximum power value is identified and rounded up to the nearest 1000.\n",
    "  - The target variable (`power`) is normalized using this max value plus a small epsilon to avoid division by zero.\n",
    "  - A new feature, `power_t-96`, is created by shifting the target column by 96 time steps.\n",
    "  - A time-based interval index (`interval_index`) is computed to segment the data into 15-minute intervals.\n",
    "  - Any rows containing NaN values are dropped.\n",
    "\n",
    "## 3. **Train-Validation-Test Split**\n",
    "   - Split the dataset into three subsets:  \n",
    "     - **Train**: Data from 2016â€“2022.  \n",
    "     - **Validation**: Data from 2023.  \n",
    "     - **Test**: Data from 2024.  \n",
    "     \n",
    "## 4. **Feature Selection Based on Case Parameter**\n",
    "Different cases dictate which features are included and which loss function is used:\n",
    "- Cases 1-10 select different combinations of power history (`power_t-96`) and wind speed data at different heights (`ws_10m_loc`, `ws_100m_loc`).\n",
    "- Loss functions used: `CRPScore` or `LogScore`.\n",
    "- Output file paths are dynamically updated based on the selected case.\n",
    "\n",
    "## 5. **Extract Training and Validation Data**\n",
    "- Feature columns and target values are extracted for training and validation.\n",
    "\n",
    "## 6. **Initialize and Train NGBoost Model**\n",
    "- `NGBRegressor` is instantiated with:\n",
    "  - Distribution: `dist` (e.g., LogNormal)\n",
    "  - Loss function: Chosen based on case\n",
    "  - `n_estimators`, `learning_rate`, and `random_state`\n",
    "- The model is trained using `model.fit()` with validation data included.\n",
    "\n",
    "## 7. **Model Evaluation**\n",
    "- **Interval-Based Scoring**:\n",
    "  - Validation data is split into 96 sub-arrays, corresponding to 96 time intervals per day.\n",
    "  - The model's score is computed separately for each interval and overall.\n",
    "- **Predictions**:\n",
    "  - `y_val_pred`: Point predictions.\n",
    "  - `y_val_dists`: Predicted probability distributions.\n",
    "- **Compute CRPS and NLL**:\n",
    "  - Continuous Ranked Probability Score (CRPS) and Negative Log-Likelihood (NLL) are computed for each sample.\n",
    "  - CRPS is calculated for both Gaussian and log-normal distributions.\n",
    "  - Scores are stored in lists for later aggregation.\n",
    "\n",
    "## 8. **Compute Per-Interval Statistics**\n",
    "- For each of the 96 intervals:\n",
    "  - Mean, min, and max CRPS (Gaussian and log-normal) are computed.\n",
    "  - Mean, min, and max NLL are computed.\n",
    "  - Results are stored in dictionaries.\n",
    "\n",
    "## 9. **Store Results in DataFrames**\n",
    "- **`results_per_time_interval_df`**: Stores per-interval CRPS, NLL, and model scores.\n",
    "- **`results_summary_stats_df`**: Stores overall summary statistics (means, min, max for CRPS, NLL, and model scores).\n",
    "- **`results_per_row_df`**: Stores per-sample CRPS and NLL values.\n",
    "- **`hyperparameters_df`**: Stores model hyperparameters and dataset details.\n",
    "\n",
    "## 10. **Save Results to Excel**\n",
    "- An Excel file is created with multiple sheets:\n",
    "  - `Interval_Scores` (per-interval stats)\n",
    "  - `Summary_Scores` (aggregated stats)\n",
    "  - `Detailed_Scores` (per-row CRPS and NLL values)\n",
    "  - `Hyperparameters` (model settings)\n",
    "\n",
    "## 11. **Return DataFrames for Display**\n",
    "- The function returns and displays the four main result DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.datasets import load_entsoe\n",
    "from analysis.transformations import minute_to_daily\n",
    "from analysis.splits import to_train_validation_test_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ngboost.scores import LogScore, CRPScore\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.distns import LogNormal\n",
    "from ngboost.distns.normal import NormalCRPScore\n",
    "\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "feature_columns = ['ws_100m_loc_mean', 'ws_10m_loc_mean']\n",
    "target_column = ['power']\n",
    "dist=LogNormal\n",
    "loss_function=CRPScore\n",
    "n_estimators=3\n",
    "learning_rate=0.03\n",
    "random_state=42\n",
    "#output_file='model_evaluation.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max power: power    16676.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Scaling power data\n",
    "max_power_value = entsoe[target_column].max()\n",
    "print(\"max power:\", max_power_value)\n",
    "max_power_value_rounded = np.ceil(max_power_value / 1000) * 1000\n",
    "epsilon = 1e-9\n",
    "entsoe[target_column] = entsoe[target_column] / max_power_value_rounded + epsilon\n",
    "entsoe['power_t-96'] = entsoe[target_column].shift(96)\n",
    "entsoe['interval_index'] = ((entsoe.index.hour * 60 + entsoe.index.minute) // 15) + 1\n",
    "entsoe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 2976 | 0.94%\n",
      "# of test observations: 67197 | 21.30%\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = to_train_validation_test_data(entsoe, \"2022-12-31 23:45:00\", \"2023-01-31 23:45:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[feature_columns]\n",
    "y_train = train[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation, y_validation = validation[feature_columns], validation[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.8581 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.8343 scale=1.0000 norm=1.0961\n",
      "[iter 2] loss=0.6126 val_loss=0.8121 scale=1.0000 norm=1.0779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NGBRegressor(Dist=&lt;class &#x27;ngboost.distns.distn.Distn.uncensor.&lt;locals&gt;.DistWithUncensoredScore&#x27;&gt;,\n",
       "             Score=&lt;class &#x27;ngboost.scores.CRPScore&#x27;&gt;, learning_rate=0.03,\n",
       "             n_estimators=3,\n",
       "             random_state=RandomState(MT19937) at 0x1F1CFEDF840)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>NGBRegressor</div></div><div><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>NGBRegressor(Dist=&lt;class &#x27;ngboost.distns.distn.Distn.uncensor.&lt;locals&gt;.DistWithUncensoredScore&#x27;&gt;,\n",
       "             Score=&lt;class &#x27;ngboost.scores.CRPScore&#x27;&gt;, learning_rate=0.03,\n",
       "             n_estimators=3,\n",
       "             random_state=RandomState(MT19937) at 0x1F1CFEDF840)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Base: DecisionTreeRegressor</div></div></label><div class=\"sk-toggleable__content \"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a></div></label><div class=\"sk-toggleable__content \"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "NGBRegressor(Dist=<class 'ngboost.distns.distn.Distn.uncensor.<locals>.DistWithUncensoredScore'>,\n",
       "             Score=<class 'ngboost.scores.CRPScore'>, learning_rate=0.03,\n",
       "             n_estimators=3,\n",
       "             random_state=RandomState(MT19937) at 0x1F1CFEDF840)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the chosen loss function\n",
    "model = NGBRegressor(Dist=dist, Score=loss_function, n_estimators=n_estimators, learning_rate=learning_rate, random_state=random_state, verbose = True, verbose_eval = True)\n",
    "\n",
    "model.fit(X_train, y_train.squeeze(), X_val=X_validation, Y_val=y_validation.squeeze())\n",
    "#print(\"model.fit ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation data into 96 intervals\n",
    "X_validation_sub_arrays = [X_validation[i::96] for i in range(96)]\n",
    "y_validation_sub_arrays = [y_validation[i::96] for i in range(96)]\n",
    "\n",
    "#print(\"X_validation_sub_arrays[0] = \", display(X_validation_sub_arrays[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val_pred[0] 0.30951383057142146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_scores_intervals = [model.score(np.array(X_validation_sub_arrays[i]), np.array(y_validation_sub_arrays[i])) for i in range(96)]\n",
    "model_scores_overall = model.score(np.array(X_validation), np.array(y_validation))\n",
    "\n",
    "y_val_pred = model.predict(X_validation)\n",
    "y_val_dists = model.pred_dist(X_validation)\n",
    "\n",
    "print(\"y_val_pred[0]\", y_val_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_gaussian = [] # Gaussian formula with log(y) used for crps rather than the correct log normal crps formula by NGBoost\n",
    "crps_log_gaussian = []\n",
    "nll = []\n",
    "\n",
    "\n",
    "for i in range(len(y_val_pred)):\n",
    "        y = y_validation.iloc[i,0]\n",
    "        median = y_val_pred[i]\n",
    "        sigma = y_val_dists[i].scale\n",
    "        mu = y_val_dists[i].loc\n",
    "        ylog = np.log(y)\n",
    "        z = (ylog - mu) / sigma\n",
    "        crps_i = sigma * ( \n",
    "            z * (2 * norm.cdf(z) - 1)\n",
    "            + 2 * norm.pdf(z) \n",
    "            - 1/np.sqrt(np.pi)\n",
    "        )\n",
    "\n",
    "        crps_full_i = y * (2 * norm.cdf(z) - 1) - 2 * np.exp(mu + 0.5 * sigma**2) * (\n",
    "            norm.cdf(z - sigma) + norm.cdf(sigma/np.sqrt(2)) - 1)\n",
    "        \n",
    "        nll_i = lognorm.logpdf(y, s=sigma, scale=np.exp(mu))\n",
    "\n",
    "\n",
    "        crps_log_gaussian.append(crps_full_i)\n",
    "            \n",
    "        crps_gaussian.append(crps_i)\n",
    "\n",
    "        nll.append(nll_i)\n",
    "\n",
    "        nll_sub_arrays = [nll[i::96] for i in range(96)]\n",
    "        crps_gaussian_sub_arrays = [crps_gaussian[i::96] for i in range(96)]\n",
    "        crps_lognormal_sub_arrays = [crps_log_gaussian[i::96] for i in range(96)]\n",
    "\n",
    "        #print(\"i = \", i)\n",
    "\n",
    "\n",
    "\n",
    "#display('CRPS_gaussian shape:', len(crps_gaussian_sub_arrays))\n",
    "#display('CRPS_lognormal shape', len(crps_lognormal_sub_arrays))\n",
    "#display('NLL shape:', len(nll_sub_arrays))\n",
    "#display('model_scores shape', len(model_scores_intervals))\n",
    "\n",
    "#display('CRPS_gaussian shape', len(crps_gaussian))\n",
    "#display('CRPS_lognormal shape', len(crps_log_gaussian))\n",
    "#display('NLL shape', len(nll))\n",
    "#display('model_scores shape', model_scores_overall)\n",
    "\n",
    "\n",
    "#with pd.ExcelWriter(output_file) as writer:\n",
    "    #results_df.to_excel(writer, sheet_name='Interval_Scores', index=False)\n",
    "    #overall_df.to_excel(writer, sheet_name='Overall_Scores', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Save results to an Excel file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m results_per_time_interval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m97\u001b[39m)),\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRPS_gaussian_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: crps_gaussian_mean_per_interval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: model_scores_intervals\n\u001b[0;32m     31\u001b[0m })\n\u001b[1;32m---> 33\u001b[0m results_summary_stats_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInterval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_gaussian_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_gaussian_mean_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_gaussian_min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_gaussian_min_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_gaussian_max\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_gaussian_max_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_lognormal_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_lognormal_mean_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_lognormal_min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_lognormal_min_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCRPS_lognormal_max\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrps_lognormal_max_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLL_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnll_mean_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLL_min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnll_min_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLL_max\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnll_max_per_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_scores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_scores_intervals\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m results_per_row_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntry_no\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, y_validation\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRPS_gaussian\u001b[39m\u001b[38;5;124m'\u001b[39m: crps_gaussian,\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRPS_lognormal\u001b[39m\u001b[38;5;124m'\u001b[39m: crps_log_gaussian,\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLL\u001b[39m\u001b[38;5;124m'\u001b[39m: nll,\n\u001b[0;32m     55\u001b[0m })\n\u001b[0;32m     57\u001b[0m hyperparameters_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentsoe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_columns\u001b[39m\u001b[38;5;124m'\u001b[39m: [feature_columns],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: random_state\n\u001b[0;32m     65\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Compute statistics per interval\n",
    "\n",
    "crps_gaussian_min_per_interval = [np.min(crps_gaussian_sub_arrays[i]) for i in range(96)]\n",
    "crps_gaussian_max_per_interval = [np.max(crps_gaussian_sub_arrays[i]) for i in range(96)]\n",
    "crps_gaussian_mean_per_interval = [np.mean(crps_gaussian_sub_arrays[i]) for i in range(96)]\n",
    "\n",
    "nll_min_per_interval = [np.min(nll_sub_arrays[i]) for i in range(96)]\n",
    "nll_max_per_interval = [np.max(nll_sub_arrays[i]) for i in range(96)]\n",
    "nll_mean_per_interval = [np.mean(nll_sub_arrays[i]) for i in range(96)]\n",
    "\n",
    "\n",
    "crps_lognormal_min_per_interval = [np.min(crps_lognormal_sub_arrays[i]) for i in range(96)]\n",
    "crps_lognormal_max_per_interval = [np.max(crps_lognormal_sub_arrays[i]) for i in range(96)]\n",
    "crps_lognormal_mean_per_interval = [np.mean(crps_lognormal_sub_arrays[i]) for i in range(96)]\n",
    "\n",
    "# Save results to an Excel file\n",
    "results_per_time_interval_df = pd.DataFrame({\n",
    "    'Interval': list(range(1, 97)),\n",
    "    'CRPS_gaussian_mean': crps_gaussian_mean_per_interval,\n",
    "    'CRPS_gaussian_min': crps_gaussian_min_per_interval,\n",
    "    'CRPS_gaussian_max': crps_gaussian_max_per_interval,\n",
    "\n",
    "    'CRPS_lognormal_mean': crps_lognormal_mean_per_interval,\n",
    "    'CRPS_lognormal_min': crps_lognormal_min_per_interval,\n",
    "    'CRPS_lognormal_max': crps_lognormal_max_per_interval,\n",
    "\n",
    "    'NLL_mean': nll_mean_per_interval,\n",
    "    'NLL_min': nll_min_per_interval,\n",
    "    'NLL_max': nll_max_per_interval,\n",
    "    'model_scores': model_scores_intervals\n",
    "})\n",
    "\n",
    "results_summary_stats_df = pd.DataFrame({\n",
    "    'Interval': list(range(1, 2)),\n",
    "    'CRPS_gaussian_mean': np.mean(crps_gaussian_mean_per_interval),\n",
    "    'CRPS_gaussian_min': np.min(crps_gaussian_min_per_interval),\n",
    "    'CRPS_gaussian_max': np.max(crps_gaussian_max_per_interval),\n",
    "\n",
    "    'CRPS_lognormal_mean': np.mean(crps_lognormal_mean_per_interval),\n",
    "    'CRPS_lognormal_min': np.min(crps_lognormal_min_per_interval),\n",
    "    'CRPS_lognormal_max': np.max(crps_lognormal_max_per_interval),\n",
    "\n",
    "    'NLL_mean': np.mean(nll_mean_per_interval),\n",
    "    'NLL_min': np.min(nll_min_per_interval),\n",
    "    'NLL_max': np.max(nll_max_per_interval),\n",
    "\n",
    "    'model_scores': model_scores_intervals\n",
    "})\n",
    "\n",
    "results_per_row_df = pd.DataFrame({\n",
    "    'Entry_no': list(range(1, y_validation.shape[0] + 1)),\n",
    "    'CRPS_gaussian': crps_gaussian,\n",
    "    'CRPS_lognormal': crps_log_gaussian,\n",
    "    'NLL': nll,\n",
    "})\n",
    "\n",
    "hyperparameters_df = pd.DataFrame({\n",
    "    'dataset': 'entsoe',\n",
    "    'feature_columns': [feature_columns],\n",
    "    'distribution': dist,\n",
    "    'loss_function': loss_function,\n",
    "    'iterations': n_estimators,\n",
    "    'learning_rate': learning_rate,\n",
    "    'random_state': random_state\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('../data/dummy.xlsx') as writer:\n",
    "    results_per_time_interval_df.to_excel(writer, sheet_name='Interval_Scores', index=False)\n",
    "    results_summary_stats_df.to_excel(writer, sheet_name='Summary_Scores', index=False)\n",
    "    results_per_row_df.to_excel(writer, sheet_name='Detailed_Scores', index=False)\n",
    "    hyperparameters_df.to_excel(writer, sheet_name='Hyperparameters', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8262941186470588"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation.iloc[i,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function (automatic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    case 1: feature_columns = ['power_t-96'], loss: CRPS\n",
    "    case 2: feature_columns = ['power_t-96'], loss: NLL\n",
    "    case 3: feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean'], loss: CRPS\n",
    "    case 4: feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean'], loss: NLL\n",
    "    case 5: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean'], loss: CRPS\n",
    "    case 6: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean'], loss: NLL\n",
    "    case 7: feature_columns = ['power_t-96', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., 'ws_100m_loc_10'], loss: CRPS\n",
    "    case 8: feature_columns = ['power_t-96', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., 'ws_100m_loc_10'], loss: NLL\n",
    "    case 9: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., \n",
    "    'ws_100m_loc_10'], loss: CRPS\n",
    "    case 10: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., \n",
    "    'ws_100m_loc_10'], loss: NLL\n",
    "    case 11: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., \n",
    "    'ws_100m_loc_10', 'interval_index'], loss: CRPS\n",
    "    case 12: feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', ..., 'ws_10m_loc_10', 'ws_100m_loc_1', ..., \n",
    "    'ws_100m_loc_10', 'interval_index'], loss: NLL\n",
    "    case 13:...\n",
    "    case 14...\n",
    "    case 15...\n",
    "    case 16...\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ngboost import NGBRegressor\n",
    "from scipy.stats import norm, lognorm\n",
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def evaluate_ngboost_model( \n",
    "    entsoe, \n",
    "    target_column='power', \n",
    "    dist=Normal,\n",
    "    case=1,\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.03, \n",
    "    random_state=42, \n",
    "    output_file='../results/NGBoost/'\n",
    "):\n",
    "    \n",
    "    if dist == Normal:\n",
    "           output_file='../results/NGBoost/Normal_dist/'\n",
    "\n",
    "    else:\n",
    "           output_file='../results/NGBoost/Lognormal_dist/'\n",
    "\n",
    "    # Scale power data\n",
    "    max_power_value = entsoe[target_column].max()\n",
    "    max_power_value_rounded = np.ceil(max_power_value / 1000) * 1000\n",
    "    epsilon = 1e-9\n",
    "    entsoe[target_column] = np.log(entsoe[target_column] / max_power_value_rounded + epsilon)\n",
    "    entsoe['power_t-96'] = entsoe[target_column].shift(96)\n",
    "    entsoe['interval_index'] = ((entsoe.index.hour * 60 + entsoe.index.minute) // 15) + 1\n",
    "    entsoe.dropna(inplace=True)\n",
    "\n",
    "    # Train-test split\n",
    "    train, validation, test = to_train_validation_test_data(entsoe, \"2022-12-31 23:45:00\", \"2023-12-31 23:45:00\")\n",
    "\n",
    "    if case == 1:\n",
    "            feature_columns = ['power_t-96']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"P\"\n",
    "    \n",
    "    if case == 2:\n",
    "            feature_columns = ['power_t-96']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"P\"\n",
    "\n",
    "\n",
    "    if case == 3:\n",
    "            feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"ws_mean\"\n",
    "\n",
    "    \n",
    "    if case == 4:\n",
    "            feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"ws_mean\"\n",
    "    \n",
    "    elif case == 5:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean\"\n",
    "\n",
    "\n",
    "    elif case == 6:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean\"\n",
    "\n",
    "\n",
    "    elif case == 7:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_10_loc\"\n",
    "\n",
    "\n",
    "\n",
    "    elif case == 8:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_10_loc\"\n",
    "\n",
    "\n",
    "    elif case == 9:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean',\n",
    "                               'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean, ws_10_loc\"\n",
    "\n",
    "\n",
    "    elif case == 10:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean',\n",
    "                               'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean, ws_10_loc\"\n",
    "\n",
    "    \n",
    "    elif case == 11:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean',\n",
    "                               'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean, ws_10_loc, t_index\"\n",
    "\n",
    "    elif case == 12:\n",
    "            feature_columns = ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean',\n",
    "                               'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6',\n",
    "                               'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10',\n",
    "                               'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6',\n",
    "                               'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, ws_mean, ws_10_loc, t_index\"\n",
    "\n",
    "    elif case == 13:\n",
    "            feature_columns = ['power_t-96', 'interval_index']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, t_index\"\n",
    "\n",
    "    elif case == 14:\n",
    "            feature_columns = ['power_t-96', 'interval_index']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"p, t_index\"\n",
    "\n",
    "    elif case == 15:\n",
    "            feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean', 'interval_index']\n",
    "            loss_function = CRPScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"ws_mean, t_index\"\n",
    "\n",
    "    elif case == 16:\n",
    "            feature_columns = ['ws_10m_loc_mean', 'ws_100m_loc_mean', 'interval_index']\n",
    "            loss_function = LogScore\n",
    "            output_file = f'{output_file}case{case}.xlsx'\n",
    "            feature_abbr = \"ws_mean, t_index\"\n",
    "\n",
    "\n",
    "    X_train, y_train = train[feature_columns], train[target_column]\n",
    "    X_validation, y_validation = validation[feature_columns], validation[target_column]\n",
    "\n",
    "    # Train model\n",
    "    model = NGBRegressor(\n",
    "        Dist=dist, Score=loss_function, \n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, \n",
    "        random_state=random_state, verbose=True, verbose_eval=True\n",
    "    )\n",
    "    model.fit(X_train, y_train.squeeze(), X_val=X_validation, Y_val=y_validation.squeeze())\n",
    "\n",
    "    # Split validation data into 96 intervals\n",
    "    X_validation_sub_arrays = [X_validation[i::96] for i in range(96)]\n",
    "    y_validation_sub_arrays = [y_validation[i::96] for i in range(96)]\n",
    "\n",
    "    model_scores_intervals = [model.score(np.array(X_validation_sub_arrays[i]), np.array(y_validation_sub_arrays[i])) for i in range(96)]\n",
    "    model_scores_overall = model.score(np.array(X_validation), np.array(y_validation))\n",
    "\n",
    "    y_val_pred = model.predict(X_validation)\n",
    "    y_val_dists = model.pred_dist(X_validation)\n",
    "\n",
    "\n",
    "    # Compute predictions\n",
    "    #y_val_pred = model.predict(X_validation)\n",
    "    #y_val_dists = model.pred_dist(X_validation)\n",
    "\n",
    "    # Compute CRPS and NLL per sample\n",
    "    crps_gaussian, crps_log_gaussian, nll, pit_values = [], [], [], []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        y = y_validation.iloc[i]\n",
    "        sigma, mu = y_val_dists[i].scale, y_val_dists[i].loc\n",
    "\n",
    "        if dist == Normal:\n",
    "               pit_value = norm.cdf(y, scale=sigma, loc=mu) # Note: loc = mean, scale = standard deviation (scipy)\n",
    "               z = (y - mu) / sigma\n",
    "               crps_gaussian.append(\n",
    "                      sigma * (z * (2 * norm.cdf(z) - 1) + 2 * norm.pdf(z) - 1 / np.sqrt(np.pi)))\n",
    "               \n",
    "               crps_log_gaussian.append(0)\n",
    "\n",
    "               nll.append(-norm.logpdf(y, scale=sigma, loc=mu))\n",
    "        \n",
    "        # NGBoost uses the CRPS formula of the Normal distribution with y -> Ln(y) rather than the correct CRPS formula for the LogNormal distribution\n",
    "        # If dist == Normal only crps_gaussian is to be used.\n",
    "        # If dist == LogNormal then CRPS log_gaussian is the correct formula. CRPS_Gaussian is calculated to double check that this is the score that NGBoost returns\n",
    "        else:\n",
    "               pit_value = lognorm.cdf(y, s=sigma, scale=np.exp(mu)) # Note: s = sigma and scale = exp(mu) (scipy)\n",
    "               ylog = np.log(y)\n",
    "               z = (ylog - mu) / sigma\n",
    "               crps_gaussian.append(sigma * (z * (2 * norm.cdf(z) - 1) + 2 * norm.pdf(z) - 1 / np.sqrt(np.pi))\n",
    "                                    )\n",
    "               crps_log_gaussian.append(\n",
    "                      y * (2 * norm.cdf(z) - 1) - 2 * np.exp(mu + 0.5 * sigma**2) * (norm.cdf(z - sigma) + norm.cdf(sigma/np.sqrt(2)) - 1)\n",
    "                      )\n",
    "               nll.append(-lognorm.logpdf(y, s=sigma, scale=np.exp(mu)))\n",
    "\n",
    "\n",
    "        pit_values.append(pit_value)   \n",
    "\n",
    "\n",
    "    # Compute per-interval statistics\n",
    "    crps_gaussian_sub_arrays = [crps_gaussian[i::96] for i in range(96)]\n",
    "\n",
    "    nll_sub_arrays = [nll[i::96] for i in range(96)]\n",
    "    pit_sub_arrays = [pit_values[i::96] for i in range(96)]\n",
    "    \n",
    "    crps_lognormal_sub_arrays = [crps_log_gaussian[i::96] for i in range(96)]\n",
    "\n",
    "    crps_lognormal_stats = {\n",
    "           'mean': [np.mean(arr) for arr in crps_lognormal_sub_arrays],\n",
    "           'min': [np.min(arr) for arr in crps_lognormal_sub_arrays],\n",
    "           'max': [np.max(arr) for arr in crps_lognormal_sub_arrays]\n",
    "    }\n",
    "\n",
    "    crps_gaussian_stats = {\n",
    "        'mean': [np.mean(arr) for arr in crps_gaussian_sub_arrays],\n",
    "        'min': [np.min(arr) for arr in crps_gaussian_sub_arrays],\n",
    "        'max': [np.max(arr) for arr in crps_gaussian_sub_arrays]\n",
    "    }\n",
    "\n",
    "    nll_stats = {\n",
    "        'mean': [np.mean(arr) for arr in nll_sub_arrays],\n",
    "        'min': [np.min(arr) for arr in nll_sub_arrays],\n",
    "        'max': [np.max(arr) for arr in nll_sub_arrays]\n",
    "    }\n",
    "\n",
    "    # Calculates deciles per time interval\n",
    "    deciles = []\n",
    "    \n",
    "    for i in range(0, 96):\n",
    "        pit_a = pit_sub_arrays[i]\n",
    "        bin_edges = np.arange(0, 1.1, 0.1)  # Creating bin edges from 0 to 1 with a step of 0.1\n",
    "        decile, bins = np.histogram(pit_a, bins=bin_edges, density=True)\n",
    "        #decile, bin_edges = np.histogram(pit_a, bins=10, density=True)\n",
    "        deciles.append(decile)\n",
    "\n",
    "    bin_edges = np.arange(0, 1.1, 0.1)  # Creating bin edges from 0 to 1 with a step of 0.1\n",
    "    sum_deciles, bins = np.histogram(pit_values, bins=bin_edges, density=True)\n",
    "    \n",
    "    # Create DataFrames\n",
    "    results_per_time_interval_df = pd.DataFrame({\n",
    "       'Interval': list(range(1, 97)),\n",
    "        **{f'CRPS_gaussian_{k}': v for k, v in crps_gaussian_stats.items()},\n",
    "        **{f'CRPS_lognormal_{k}': v for k, v in crps_lognormal_stats.items()},\n",
    "        **{f'NLL_{k}': v for k, v in nll_stats.items()},\n",
    "        'model_scores': model_scores_intervals,\n",
    "        'pit_values': deciles\n",
    "        })\n",
    "\n",
    "    results_summary_stats_df = pd.DataFrame({\n",
    "        'CRPS_gaussian_mean': np.mean(crps_gaussian_stats['mean']),\n",
    "        'CRPS_gaussian_min': np.min(crps_gaussian_stats['min']),\n",
    "        'CRPS_gaussian_max': np.max(crps_gaussian_stats['max']),\n",
    "        'CRPS_lognormal_mean': np.mean(crps_lognormal_stats['mean']),\n",
    "        'CRPS_lognormal_min': np.min(crps_lognormal_stats['min']),\n",
    "        'CRPS_lognormal_max': np.max(crps_lognormal_stats['max']),\n",
    "        'NLL_mean': np.mean(nll_stats['mean']),\n",
    "        'NLL_min': np.min(nll_stats['min']),\n",
    "        'NLL_max': np.max(nll_stats['max']),\n",
    "        'model_scores_mean': np.mean(model_scores_intervals),\n",
    "        'pit_overall': [sum_deciles]\n",
    "\n",
    "    }, index=[0])\n",
    "\n",
    "    results_per_row_df = pd.DataFrame({\n",
    "        'Entry_no': list(range(1, len(y_validation) + 1)),\n",
    "        'CRPS_gaussian': crps_gaussian,\n",
    "        'CRPS_lognormal': crps_log_gaussian,\n",
    "        'NLL': nll\n",
    "    })\n",
    "\n",
    "    hyperparameters_df = pd.DataFrame({\n",
    "        'dataset': 'entsoe',\n",
    "        'feature_abbr': feature_abbr,\n",
    "        'feature_columns': [feature_columns],\n",
    "        'distribution': str(dist),\n",
    "        'loss_function': str(loss_function),\n",
    "        'iterations': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'random_state': random_state\n",
    "    })\n",
    "\n",
    "    # Save results to an Excel file\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        results_per_time_interval_df.to_excel(writer, sheet_name='Interval_Scores', index=False)\n",
    "        results_summary_stats_df.to_excel(writer, sheet_name='Summary_Scores', index=False)\n",
    "        results_per_row_df.to_excel(writer, sheet_name='Detailed_Scores', index=False)\n",
    "        hyperparameters_df.to_excel(writer, sheet_name='Hyperparameters', index=False)\n",
    "\n",
    "        if dist == Normal:\n",
    "               file_paths = glob.glob(f\"{output_file}/*.xlsx\")  # Update with the correct path\n",
    "        \n",
    "        else:\n",
    "                file_paths = glob.glob(f\"{output_file}/*.xlsx\")  # Update with the correct path\n",
    "\n",
    "\n",
    "    # Step 1: Get all Excel files in a folder\n",
    "\n",
    "    # Step 2: Check if there are exactly 12 Excel files\n",
    "    if len(file_paths) == 16:\n",
    "        merged_data = []\n",
    "\n",
    "        # Step 3: Loop through each file and extract both sheets\n",
    "        for file in file_paths:\n",
    "                try:\n",
    "                        # Read \"Summary_Scores\" sheet\n",
    "                        df_scores = pd.read_excel(file, sheet_name=\"Summary_Scores\")\n",
    "                        df_scores[\"Source_File\"] = file  # Optional: Track source file\n",
    "\n",
    "                        # Read \"Hyperparameters\" sheet\n",
    "                        df_hyperparams = pd.read_excel(file, sheet_name=\"Hyperparameters\")\n",
    "                        df_hyperparams[\"Source_File\"] = file  # Optional: Track source file\n",
    "\n",
    "                        # Combine the two dataframes horizontally (side by side)\n",
    "                        combined_df = pd.concat([df_scores, df_hyperparams], axis=1)\n",
    "                        merged_data.append(combined_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                        print(f\"Could not read {file}: {e}\")\n",
    "\n",
    "        # Step 4: Merge all data into one DataFrame\n",
    "        final_merged_df = pd.concat(merged_data, ignore_index=True)\n",
    "\n",
    "        # Step 5: Save to a new Excel file\n",
    "        final_merged_df.to_excel(f\"{output_file}/Merged_Sheet.xlsx\", index=False)\n",
    "\n",
    "        print(\"Merge completed! The final file is 'Merged_Sheet.xlsx'.\")\n",
    "\n",
    "        plt.hist(bin_edges[:-1], bin_edges, weights=results_summary_stats_df['pit_overall'].values, edgecolor='black', alpha=0.7)\n",
    "        plt.xlabel('Bin Edges')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Histogram of Deciles')\n",
    "        # Save the plot as an image (e.g., PNG format)\n",
    "        image_filename = 'histogram.png'\n",
    "        plt.savefig(image_filename)\n",
    "        plt.close()\n",
    "        \n",
    "        # Load the existing Excel file (if it already exists)\n",
    "        excel_file = f\"{output_file}/Merged_Sheet.xlsx\"\n",
    "\n",
    "        wb = openpyxl.load_workbook(excel_file)\n",
    "        \n",
    "        # Select the specific sheet where you want to insert the image\n",
    "        new_sheet = wb.create_sheet('Histogram Sheet')\n",
    "        \n",
    "        # Load the image you saved earlier\n",
    "        img = Image(image_filename)\n",
    "        \n",
    "        # Specify the location where you want the image to appear in the sheet (e.g., cell 'A1')\n",
    "        new_sheet.add_image(img, 'A1')\n",
    "        \n",
    "        # Save the modified Excel file\n",
    "        wb.save(excel_file)\n",
    "        \n",
    "    else:\n",
    "           print(f\"Expected 16 Excel files, but found {len(file_paths)} files. Skipping the merge step.\")\n",
    "\n",
    "\n",
    "    return results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGBoost with log(power) and normal distribution to allow comparison with TabPFN because CRPS with lognormal distribution cannot be converted to a CRPS value with normal distribution and log power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6806 scale=2.0000 norm=2.2332\n",
      "[iter 1] loss=0.6375 val_loss=0.6722 scale=2.0000 norm=2.2170\n",
      "[iter 2] loss=0.6307 val_loss=0.6647 scale=2.0000 norm=2.2042\n",
      "[iter 3] loss=0.6246 val_loss=0.6579 scale=2.0000 norm=2.1944\n",
      "[iter 4] loss=0.6192 val_loss=0.6519 scale=2.0000 norm=2.1869\n",
      "[iter 5] loss=0.6143 val_loss=0.6464 scale=2.0000 norm=2.1814\n",
      "[iter 6] loss=0.6099 val_loss=0.6415 scale=2.0000 norm=2.1775\n",
      "[iter 7] loss=0.6059 val_loss=0.6370 scale=2.0000 norm=2.1751\n",
      "[iter 8] loss=0.6022 val_loss=0.6330 scale=2.0000 norm=2.1740\n",
      "[iter 9] loss=0.5989 val_loss=0.6293 scale=2.0000 norm=2.1739\n",
      "[iter 10] loss=0.5959 val_loss=0.6259 scale=2.0000 norm=2.1747\n",
      "[iter 11] loss=0.5932 val_loss=0.6228 scale=2.0000 norm=2.1763\n",
      "[iter 12] loss=0.5907 val_loss=0.6200 scale=2.0000 norm=2.1787\n",
      "[iter 13] loss=0.5884 val_loss=0.6175 scale=2.0000 norm=2.1816\n",
      "[iter 14] loss=0.5863 val_loss=0.6152 scale=2.0000 norm=2.1851\n",
      "[iter 15] loss=0.5844 val_loss=0.6131 scale=2.0000 norm=2.1890\n",
      "[iter 16] loss=0.5826 val_loss=0.6112 scale=2.0000 norm=2.1933\n",
      "[iter 17] loss=0.5811 val_loss=0.6094 scale=2.0000 norm=2.1980\n",
      "[iter 18] loss=0.5796 val_loss=0.6078 scale=2.0000 norm=2.2029\n",
      "[iter 19] loss=0.5783 val_loss=0.6063 scale=2.0000 norm=2.2081\n",
      "[iter 20] loss=0.5771 val_loss=0.6050 scale=2.0000 norm=2.2135\n",
      "[iter 21] loss=0.5759 val_loss=0.6038 scale=2.0000 norm=2.2190\n",
      "[iter 22] loss=0.5749 val_loss=0.6027 scale=2.0000 norm=2.2247\n",
      "[iter 23] loss=0.5740 val_loss=0.6017 scale=2.0000 norm=2.2305\n",
      "[iter 24] loss=0.5731 val_loss=0.6008 scale=2.0000 norm=2.2363\n",
      "[iter 25] loss=0.5724 val_loss=0.5999 scale=2.0000 norm=2.2422\n",
      "[iter 26] loss=0.5717 val_loss=0.5992 scale=2.0000 norm=2.2482\n",
      "[iter 27] loss=0.5710 val_loss=0.5985 scale=2.0000 norm=2.2541\n",
      "[iter 28] loss=0.5704 val_loss=0.5979 scale=2.0000 norm=2.2601\n",
      "[iter 29] loss=0.5699 val_loss=0.5974 scale=2.0000 norm=2.2660\n",
      "[iter 30] loss=0.5694 val_loss=0.5969 scale=2.0000 norm=2.2720\n",
      "[iter 31] loss=0.5690 val_loss=0.5964 scale=2.0000 norm=2.2778\n",
      "[iter 32] loss=0.5686 val_loss=0.5960 scale=2.0000 norm=2.2836\n",
      "[iter 33] loss=0.5682 val_loss=0.5957 scale=2.0000 norm=2.2894\n",
      "[iter 34] loss=0.5679 val_loss=0.5953 scale=2.0000 norm=2.2951\n",
      "[iter 35] loss=0.5676 val_loss=0.5951 scale=2.0000 norm=2.3007\n",
      "[iter 36] loss=0.5673 val_loss=0.5948 scale=2.0000 norm=2.3061\n",
      "[iter 37] loss=0.5671 val_loss=0.5947 scale=1.0000 norm=1.1558\n",
      "[iter 38] loss=0.5670 val_loss=0.5945 scale=2.0000 norm=2.3141\n",
      "[iter 39] loss=0.5667 val_loss=0.5944 scale=1.0000 norm=1.1597\n",
      "[iter 40] loss=0.5667 val_loss=0.5943 scale=1.0000 norm=1.1610\n",
      "[iter 41] loss=0.5666 val_loss=0.5942 scale=1.0000 norm=1.1622\n",
      "[iter 42] loss=0.5665 val_loss=0.5941 scale=1.0000 norm=1.1634\n",
      "[iter 43] loss=0.5664 val_loss=0.5940 scale=1.0000 norm=1.1647\n",
      "[iter 44] loss=0.5663 val_loss=0.5940 scale=1.0000 norm=1.1659\n",
      "[iter 45] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1671\n",
      "[iter 46] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1682\n",
      "[iter 47] loss=0.5661 val_loss=0.5939 scale=1.0000 norm=1.1694\n",
      "[iter 48] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1705\n",
      "[iter 49] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1717\n",
      "[iter 50] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1728\n",
      "[iter 51] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1739\n",
      "[iter 52] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1749\n",
      "[iter 53] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1760\n",
      "[iter 54] loss=0.5657 val_loss=0.5937 scale=1.0000 norm=1.1770\n",
      "[iter 55] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1780\n",
      "[iter 56] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1790\n",
      "[iter 57] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1800\n",
      "[iter 58] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1810\n",
      "[iter 59] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1819\n",
      "[iter 60] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1828\n",
      "[iter 61] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1837\n",
      "[iter 62] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1846\n",
      "[iter 63] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1855\n",
      "[iter 64] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1863\n",
      "[iter 65] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1872\n",
      "[iter 66] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1880\n",
      "[iter 67] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1888\n",
      "[iter 68] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1896\n",
      "[iter 69] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1903\n",
      "[iter 70] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1911\n",
      "[iter 71] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1918\n",
      "[iter 72] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1925\n",
      "[iter 73] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1932\n",
      "[iter 74] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1939\n",
      "[iter 75] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1945\n",
      "[iter 76] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1952\n",
      "[iter 77] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1958\n",
      "[iter 78] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1964\n",
      "[iter 79] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1970\n",
      "[iter 80] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1976\n",
      "[iter 81] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1982\n",
      "[iter 82] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1987\n",
      "[iter 83] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1993\n",
      "[iter 84] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.1998\n",
      "[iter 85] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2003\n",
      "[iter 86] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2008\n",
      "[iter 87] loss=0.5651 val_loss=0.5940 scale=1.0000 norm=1.2013\n",
      "[iter 88] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2017\n",
      "[iter 89] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2022\n",
      "[iter 90] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2026\n",
      "[iter 91] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2031\n",
      "[iter 92] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2035\n",
      "[iter 93] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2039\n",
      "[iter 94] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2043\n",
      "[iter 95] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2047\n",
      "[iter 96] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2050\n",
      "[iter 97] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2054\n",
      "[iter 98] loss=0.5650 val_loss=0.5942 scale=2.0000 norm=2.4115\n",
      "[iter 99] loss=0.5650 val_loss=0.5942 scale=1.0000 norm=1.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 1 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=1, dist=Normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.6075 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5581 val_loss=1.6003 scale=1.0000 norm=1.1025\n",
      "[iter 2] loss=1.5517 val_loss=1.5936 scale=1.0000 norm=1.0957\n",
      "[iter 3] loss=1.5458 val_loss=1.5874 scale=1.0000 norm=1.0895\n",
      "[iter 4] loss=1.5403 val_loss=1.5816 scale=1.0000 norm=1.0837\n",
      "[iter 5] loss=1.5351 val_loss=1.5762 scale=1.0000 norm=1.0783\n",
      "[iter 6] loss=1.5303 val_loss=1.5711 scale=1.0000 norm=1.0733\n",
      "[iter 7] loss=1.5257 val_loss=1.5663 scale=1.0000 norm=1.0686\n",
      "[iter 8] loss=1.5214 val_loss=1.5617 scale=1.0000 norm=1.0642\n",
      "[iter 9] loss=1.5174 val_loss=1.5575 scale=1.0000 norm=1.0602\n",
      "[iter 10] loss=1.5135 val_loss=1.5535 scale=1.0000 norm=1.0563\n",
      "[iter 11] loss=1.5099 val_loss=1.5497 scale=1.0000 norm=1.0527\n",
      "[iter 12] loss=1.5064 val_loss=1.5461 scale=1.0000 norm=1.0494\n",
      "[iter 13] loss=1.5032 val_loss=1.5426 scale=1.0000 norm=1.0462\n",
      "[iter 14] loss=1.5001 val_loss=1.5361 scale=2.0000 norm=2.0866\n",
      "[iter 15] loss=1.4942 val_loss=1.5304 scale=2.0000 norm=2.0757\n",
      "[iter 16] loss=1.4889 val_loss=1.5251 scale=2.0000 norm=2.0663\n",
      "[iter 17] loss=1.4841 val_loss=1.5202 scale=2.0000 norm=2.0581\n",
      "[iter 18] loss=1.4798 val_loss=1.5159 scale=2.0000 norm=2.0510\n",
      "[iter 19] loss=1.4758 val_loss=1.5119 scale=2.0000 norm=2.0448\n",
      "[iter 20] loss=1.4721 val_loss=1.5083 scale=2.0000 norm=2.0394\n",
      "[iter 21] loss=1.4688 val_loss=1.5050 scale=2.0000 norm=2.0347\n",
      "[iter 22] loss=1.4657 val_loss=1.5021 scale=2.0000 norm=2.0307\n",
      "[iter 23] loss=1.4629 val_loss=1.4993 scale=2.0000 norm=2.0273\n",
      "[iter 24] loss=1.4602 val_loss=1.4969 scale=2.0000 norm=2.0243\n",
      "[iter 25] loss=1.4578 val_loss=1.4945 scale=2.0000 norm=2.0218\n",
      "[iter 26] loss=1.4556 val_loss=1.4925 scale=2.0000 norm=2.0198\n",
      "[iter 27] loss=1.4536 val_loss=1.4906 scale=2.0000 norm=2.0180\n",
      "[iter 28] loss=1.4517 val_loss=1.4889 scale=2.0000 norm=2.0166\n",
      "[iter 29] loss=1.4500 val_loss=1.4873 scale=2.0000 norm=2.0154\n",
      "[iter 30] loss=1.4484 val_loss=1.4859 scale=2.0000 norm=2.0145\n",
      "[iter 31] loss=1.4469 val_loss=1.4846 scale=2.0000 norm=2.0138\n",
      "[iter 32] loss=1.4455 val_loss=1.4835 scale=2.0000 norm=2.0133\n",
      "[iter 33] loss=1.4443 val_loss=1.4825 scale=2.0000 norm=2.0130\n",
      "[iter 34] loss=1.4431 val_loss=1.4816 scale=2.0000 norm=2.0128\n",
      "[iter 35] loss=1.4421 val_loss=1.4808 scale=2.0000 norm=2.0127\n",
      "[iter 36] loss=1.4411 val_loss=1.4801 scale=2.0000 norm=2.0128\n",
      "[iter 37] loss=1.4402 val_loss=1.4795 scale=2.0000 norm=2.0129\n",
      "[iter 38] loss=1.4394 val_loss=1.4790 scale=2.0000 norm=2.0131\n",
      "[iter 39] loss=1.4386 val_loss=1.4786 scale=2.0000 norm=2.0134\n",
      "[iter 40] loss=1.4379 val_loss=1.4782 scale=2.0000 norm=2.0137\n",
      "[iter 41] loss=1.4373 val_loss=1.4780 scale=2.0000 norm=2.0141\n",
      "[iter 42] loss=1.4367 val_loss=1.4777 scale=2.0000 norm=2.0145\n",
      "[iter 43] loss=1.4361 val_loss=1.4776 scale=2.0000 norm=2.0150\n",
      "[iter 44] loss=1.4356 val_loss=1.4774 scale=2.0000 norm=2.0155\n",
      "[iter 45] loss=1.4352 val_loss=1.4774 scale=2.0000 norm=2.0160\n",
      "[iter 46] loss=1.4347 val_loss=1.4773 scale=2.0000 norm=2.0165\n",
      "[iter 47] loss=1.4343 val_loss=1.4773 scale=2.0000 norm=2.0171\n",
      "[iter 48] loss=1.4340 val_loss=1.4773 scale=2.0000 norm=2.0176\n",
      "[iter 49] loss=1.4337 val_loss=1.4774 scale=2.0000 norm=2.0182\n",
      "[iter 50] loss=1.4334 val_loss=1.4774 scale=2.0000 norm=2.0187\n",
      "[iter 51] loss=1.4331 val_loss=1.4775 scale=2.0000 norm=2.0193\n",
      "[iter 52] loss=1.4329 val_loss=1.4776 scale=2.0000 norm=2.0198\n",
      "[iter 53] loss=1.4326 val_loss=1.4777 scale=2.0000 norm=2.0203\n",
      "[iter 54] loss=1.4324 val_loss=1.4779 scale=2.0000 norm=2.0208\n",
      "[iter 55] loss=1.4322 val_loss=1.4781 scale=2.0000 norm=2.0213\n",
      "[iter 56] loss=1.4320 val_loss=1.4782 scale=2.0000 norm=2.0218\n",
      "[iter 57] loss=1.4318 val_loss=1.4784 scale=2.0000 norm=2.0222\n",
      "[iter 58] loss=1.4317 val_loss=1.4787 scale=2.0000 norm=2.0227\n",
      "[iter 59] loss=1.4315 val_loss=1.4789 scale=2.0000 norm=2.0231\n",
      "[iter 60] loss=1.4314 val_loss=1.4791 scale=2.0000 norm=2.0235\n",
      "[iter 61] loss=1.4312 val_loss=1.4793 scale=2.0000 norm=2.0239\n",
      "[iter 62] loss=1.4311 val_loss=1.4796 scale=2.0000 norm=2.0243\n",
      "[iter 63] loss=1.4310 val_loss=1.4799 scale=2.0000 norm=2.0247\n",
      "[iter 64] loss=1.4309 val_loss=1.4802 scale=2.0000 norm=2.0251\n",
      "[iter 65] loss=1.4308 val_loss=1.4804 scale=2.0000 norm=2.0254\n",
      "[iter 66] loss=1.4307 val_loss=1.4806 scale=2.0000 norm=2.0257\n",
      "[iter 67] loss=1.4307 val_loss=1.4809 scale=2.0000 norm=2.0261\n",
      "[iter 68] loss=1.4306 val_loss=1.4812 scale=2.0000 norm=2.0263\n",
      "[iter 69] loss=1.4305 val_loss=1.4816 scale=2.0000 norm=2.0266\n",
      "[iter 70] loss=1.4305 val_loss=1.4818 scale=2.0000 norm=2.0269\n",
      "[iter 71] loss=1.4304 val_loss=1.4821 scale=2.0000 norm=2.0272\n",
      "[iter 72] loss=1.4303 val_loss=1.4823 scale=2.0000 norm=2.0274\n",
      "[iter 73] loss=1.4303 val_loss=1.4825 scale=2.0000 norm=2.0276\n",
      "[iter 74] loss=1.4302 val_loss=1.4828 scale=2.0000 norm=2.0279\n",
      "[iter 75] loss=1.4302 val_loss=1.4831 scale=2.0000 norm=2.0281\n",
      "[iter 76] loss=1.4301 val_loss=1.4833 scale=2.0000 norm=2.0283\n",
      "[iter 77] loss=1.4301 val_loss=1.4836 scale=2.0000 norm=2.0284\n",
      "[iter 78] loss=1.4300 val_loss=1.4838 scale=2.0000 norm=2.0286\n",
      "[iter 79] loss=1.4300 val_loss=1.4841 scale=2.0000 norm=2.0288\n",
      "[iter 80] loss=1.4300 val_loss=1.4843 scale=2.0000 norm=2.0290\n",
      "[iter 81] loss=1.4299 val_loss=1.4846 scale=2.0000 norm=2.0291\n",
      "[iter 82] loss=1.4299 val_loss=1.4849 scale=2.0000 norm=2.0293\n",
      "[iter 83] loss=1.4298 val_loss=1.4852 scale=2.0000 norm=2.0294\n",
      "[iter 84] loss=1.4298 val_loss=1.4853 scale=1.0000 norm=1.0148\n",
      "[iter 85] loss=1.4297 val_loss=1.4854 scale=2.0000 norm=2.0295\n",
      "[iter 86] loss=1.4297 val_loss=1.4856 scale=2.0000 norm=2.0296\n",
      "[iter 87] loss=1.4297 val_loss=1.4858 scale=2.0000 norm=2.0297\n",
      "[iter 88] loss=1.4297 val_loss=1.4860 scale=2.0000 norm=2.0298\n",
      "[iter 89] loss=1.4296 val_loss=1.4862 scale=2.0000 norm=2.0299\n",
      "[iter 90] loss=1.4296 val_loss=1.4862 scale=1.0000 norm=1.0150\n",
      "[iter 91] loss=1.4296 val_loss=1.4863 scale=1.0000 norm=1.0150\n",
      "[iter 92] loss=1.4296 val_loss=1.4864 scale=1.0000 norm=1.0150\n",
      "[iter 93] loss=1.4295 val_loss=1.4865 scale=2.0000 norm=2.0301\n",
      "[iter 94] loss=1.4295 val_loss=1.4866 scale=2.0000 norm=2.0301\n",
      "[iter 95] loss=1.4295 val_loss=1.4867 scale=1.0000 norm=1.0151\n",
      "[iter 96] loss=1.4295 val_loss=1.4870 scale=2.0000 norm=2.0302\n",
      "[iter 97] loss=1.4294 val_loss=1.4872 scale=2.0000 norm=2.0303\n",
      "[iter 98] loss=1.4294 val_loss=1.4873 scale=1.0000 norm=1.0152\n",
      "[iter 99] loss=1.4294 val_loss=1.4873 scale=1.0000 norm=1.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 2 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0961\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5835 val_loss=0.6085 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5815 scale=1.0000 norm=1.0242\n",
      "[iter 7] loss=0.5450 val_loss=0.5690 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5334 val_loss=0.5570 scale=1.0000 norm=1.0064\n",
      "[iter 9] loss=0.5223 val_loss=0.5457 scale=1.0000 norm=0.9993\n",
      "[iter 10] loss=0.5117 val_loss=0.5347 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5015 val_loss=0.5243 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4917 val_loss=0.5143 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4824 val_loss=0.5047 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4734 val_loss=0.4955 scale=1.0000 norm=0.9790\n",
      "[iter 15] loss=0.4647 val_loss=0.4866 scale=1.0000 norm=0.9776\n",
      "[iter 16] loss=0.4564 val_loss=0.4781 scale=1.0000 norm=0.9769\n",
      "[iter 17] loss=0.4484 val_loss=0.4700 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4407 val_loss=0.4621 scale=1.0000 norm=0.9779\n",
      "[iter 19] loss=0.4333 val_loss=0.4545 scale=1.0000 norm=0.9795\n",
      "[iter 20] loss=0.4261 val_loss=0.4472 scale=1.0000 norm=0.9817\n",
      "[iter 21] loss=0.4192 val_loss=0.4401 scale=1.0000 norm=0.9846\n",
      "[iter 22] loss=0.4126 val_loss=0.4333 scale=1.0000 norm=0.9881\n",
      "[iter 23] loss=0.4061 val_loss=0.4267 scale=1.0000 norm=0.9923\n",
      "[iter 24] loss=0.3999 val_loss=0.4204 scale=1.0000 norm=0.9971\n",
      "[iter 25] loss=0.3939 val_loss=0.4142 scale=1.0000 norm=1.0025\n",
      "[iter 26] loss=0.3882 val_loss=0.4083 scale=1.0000 norm=1.0084\n",
      "[iter 27] loss=0.3826 val_loss=0.4026 scale=1.0000 norm=1.0150\n",
      "[iter 28] loss=0.3772 val_loss=0.3971 scale=1.0000 norm=1.0221\n",
      "[iter 29] loss=0.3720 val_loss=0.3917 scale=1.0000 norm=1.0298\n",
      "[iter 30] loss=0.3669 val_loss=0.3866 scale=1.0000 norm=1.0381\n",
      "[iter 31] loss=0.3621 val_loss=0.3816 scale=1.0000 norm=1.0469\n",
      "[iter 32] loss=0.3574 val_loss=0.3768 scale=1.0000 norm=1.0562\n",
      "[iter 33] loss=0.3529 val_loss=0.3721 scale=1.0000 norm=1.0661\n",
      "[iter 34] loss=0.3485 val_loss=0.3676 scale=1.0000 norm=1.0766\n",
      "[iter 35] loss=0.3443 val_loss=0.3633 scale=1.0000 norm=1.0876\n",
      "[iter 36] loss=0.3402 val_loss=0.3591 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3363 val_loss=0.3551 scale=1.0000 norm=1.1112\n",
      "[iter 38] loss=0.3326 val_loss=0.3512 scale=1.0000 norm=1.1237\n",
      "[iter 39] loss=0.3289 val_loss=0.3475 scale=1.0000 norm=1.1369\n",
      "[iter 40] loss=0.3255 val_loss=0.3439 scale=1.0000 norm=1.1505\n",
      "[iter 41] loss=0.3221 val_loss=0.3404 scale=1.0000 norm=1.1646\n",
      "[iter 42] loss=0.3189 val_loss=0.3371 scale=1.0000 norm=1.1793\n",
      "[iter 43] loss=0.3158 val_loss=0.3339 scale=1.0000 norm=1.1945\n",
      "[iter 44] loss=0.3128 val_loss=0.3308 scale=1.0000 norm=1.2102\n",
      "[iter 45] loss=0.3099 val_loss=0.3278 scale=1.0000 norm=1.2264\n",
      "[iter 46] loss=0.3072 val_loss=0.3250 scale=1.0000 norm=1.2430\n",
      "[iter 47] loss=0.3045 val_loss=0.3222 scale=1.0000 norm=1.2602\n",
      "[iter 48] loss=0.3020 val_loss=0.3196 scale=1.0000 norm=1.2778\n",
      "[iter 49] loss=0.2996 val_loss=0.3171 scale=1.0000 norm=1.2958\n",
      "[iter 50] loss=0.2973 val_loss=0.3147 scale=1.0000 norm=1.3143\n",
      "[iter 51] loss=0.2951 val_loss=0.3124 scale=1.0000 norm=1.3332\n",
      "[iter 52] loss=0.2929 val_loss=0.3102 scale=1.0000 norm=1.3525\n",
      "[iter 53] loss=0.2909 val_loss=0.3081 scale=1.0000 norm=1.3723\n",
      "[iter 54] loss=0.2890 val_loss=0.3060 scale=1.0000 norm=1.3923\n",
      "[iter 55] loss=0.2871 val_loss=0.3041 scale=1.0000 norm=1.4128\n",
      "[iter 56] loss=0.2854 val_loss=0.3022 scale=1.0000 norm=1.4335\n",
      "[iter 57] loss=0.2837 val_loss=0.3004 scale=1.0000 norm=1.4545\n",
      "[iter 58] loss=0.2821 val_loss=0.2988 scale=1.0000 norm=1.4757\n",
      "[iter 59] loss=0.2805 val_loss=0.2972 scale=1.0000 norm=1.4972\n",
      "[iter 60] loss=0.2791 val_loss=0.2956 scale=1.0000 norm=1.5189\n",
      "[iter 61] loss=0.2777 val_loss=0.2942 scale=1.0000 norm=1.5407\n",
      "[iter 62] loss=0.2764 val_loss=0.2928 scale=1.0000 norm=1.5627\n",
      "[iter 63] loss=0.2751 val_loss=0.2915 scale=1.0000 norm=1.5848\n",
      "[iter 64] loss=0.2739 val_loss=0.2903 scale=1.0000 norm=1.6071\n",
      "[iter 65] loss=0.2728 val_loss=0.2891 scale=1.0000 norm=1.6295\n",
      "[iter 66] loss=0.2717 val_loss=0.2880 scale=1.0000 norm=1.6519\n",
      "[iter 67] loss=0.2707 val_loss=0.2869 scale=1.0000 norm=1.6744\n",
      "[iter 68] loss=0.2697 val_loss=0.2859 scale=1.0000 norm=1.6969\n",
      "[iter 69] loss=0.2688 val_loss=0.2850 scale=1.0000 norm=1.7195\n",
      "[iter 70] loss=0.2679 val_loss=0.2841 scale=1.0000 norm=1.7419\n",
      "[iter 71] loss=0.2671 val_loss=0.2832 scale=1.0000 norm=1.7643\n",
      "[iter 72] loss=0.2663 val_loss=0.2825 scale=1.0000 norm=1.7867\n",
      "[iter 73] loss=0.2656 val_loss=0.2817 scale=1.0000 norm=1.8089\n",
      "[iter 74] loss=0.2649 val_loss=0.2810 scale=1.0000 norm=1.8310\n",
      "[iter 75] loss=0.2643 val_loss=0.2804 scale=1.0000 norm=1.8528\n",
      "[iter 76] loss=0.2637 val_loss=0.2798 scale=1.0000 norm=1.8742\n",
      "[iter 77] loss=0.2631 val_loss=0.2792 scale=1.0000 norm=1.8954\n",
      "[iter 78] loss=0.2625 val_loss=0.2787 scale=1.0000 norm=1.9164\n",
      "[iter 79] loss=0.2620 val_loss=0.2782 scale=1.0000 norm=1.9371\n",
      "[iter 80] loss=0.2615 val_loss=0.2777 scale=1.0000 norm=1.9571\n",
      "[iter 81] loss=0.2611 val_loss=0.2773 scale=1.0000 norm=1.9771\n",
      "[iter 82] loss=0.2606 val_loss=0.2771 scale=0.5000 norm=0.9983\n",
      "[iter 83] loss=0.2604 val_loss=0.2769 scale=0.5000 norm=1.0028\n",
      "[iter 84] loss=0.2602 val_loss=0.2767 scale=0.5000 norm=1.0074\n",
      "[iter 85] loss=0.2600 val_loss=0.2763 scale=1.0000 norm=2.0237\n",
      "[iter 86] loss=0.2597 val_loss=0.2761 scale=0.5000 norm=1.0209\n",
      "[iter 87] loss=0.2595 val_loss=0.2758 scale=1.0000 norm=2.0507\n",
      "[iter 88] loss=0.2592 val_loss=0.2757 scale=0.5000 norm=1.0342\n",
      "[iter 89] loss=0.2590 val_loss=0.2755 scale=0.5000 norm=1.0386\n",
      "[iter 90] loss=0.2589 val_loss=0.2754 scale=0.5000 norm=1.0430\n",
      "[iter 91] loss=0.2587 val_loss=0.2753 scale=0.5000 norm=1.0473\n",
      "[iter 92] loss=0.2586 val_loss=0.2751 scale=0.5000 norm=1.0516\n",
      "[iter 93] loss=0.2585 val_loss=0.2750 scale=0.5000 norm=1.0559\n",
      "[iter 94] loss=0.2584 val_loss=0.2749 scale=0.5000 norm=1.0601\n",
      "[iter 95] loss=0.2582 val_loss=0.2748 scale=0.5000 norm=1.0644\n",
      "[iter 96] loss=0.2581 val_loss=0.2747 scale=0.5000 norm=1.0686\n",
      "[iter 97] loss=0.2580 val_loss=0.2746 scale=1.0000 norm=2.1455\n",
      "[iter 98] loss=0.2578 val_loss=0.2745 scale=0.5000 norm=1.0814\n",
      "[iter 99] loss=0.2577 val_loss=0.2744 scale=0.5000 norm=1.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 4 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5775 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5274 val_loss=1.5449 scale=1.0000 norm=1.0747\n",
      "[iter 2] loss=1.4952 val_loss=1.5160 scale=1.0000 norm=1.0446\n",
      "[iter 3] loss=1.4669 val_loss=1.4899 scale=1.0000 norm=1.0181\n",
      "[iter 4] loss=1.4414 val_loss=1.4430 scale=2.0000 norm=1.9884\n",
      "[iter 5] loss=1.3959 val_loss=1.4030 scale=2.0000 norm=1.9030\n",
      "[iter 6] loss=1.3565 val_loss=1.3672 scale=2.0000 norm=1.8300\n",
      "[iter 7] loss=1.3215 val_loss=1.3344 scale=2.0000 norm=1.7662\n",
      "[iter 8] loss=1.2893 val_loss=1.3043 scale=2.0000 norm=1.7097\n",
      "[iter 9] loss=1.2597 val_loss=1.2760 scale=2.0000 norm=1.6596\n",
      "[iter 10] loss=1.2316 val_loss=1.2494 scale=2.0000 norm=1.6145\n",
      "[iter 11] loss=1.2052 val_loss=1.2242 scale=2.0000 norm=1.5742\n",
      "[iter 12] loss=1.1800 val_loss=1.2000 scale=2.0000 norm=1.5380\n",
      "[iter 13] loss=1.1559 val_loss=1.1770 scale=2.0000 norm=1.5054\n",
      "[iter 14] loss=1.1327 val_loss=1.1546 scale=2.0000 norm=1.4762\n",
      "[iter 15] loss=1.1103 val_loss=1.1332 scale=2.0000 norm=1.4498\n",
      "[iter 16] loss=1.0887 val_loss=1.1125 scale=2.0000 norm=1.4263\n",
      "[iter 17] loss=1.0678 val_loss=1.0924 scale=2.0000 norm=1.4052\n",
      "[iter 18] loss=1.0474 val_loss=1.0730 scale=2.0000 norm=1.3861\n",
      "[iter 19] loss=1.0278 val_loss=1.0542 scale=2.0000 norm=1.3691\n",
      "[iter 20] loss=1.0086 val_loss=1.0359 scale=2.0000 norm=1.3538\n",
      "[iter 21] loss=0.9901 val_loss=1.0183 scale=2.0000 norm=1.3401\n",
      "[iter 22] loss=0.9721 val_loss=1.0011 scale=2.0000 norm=1.3279\n",
      "[iter 23] loss=0.9546 val_loss=0.9844 scale=2.0000 norm=1.3170\n",
      "[iter 24] loss=0.9376 val_loss=0.9682 scale=2.0000 norm=1.3073\n",
      "[iter 25] loss=0.9210 val_loss=0.9526 scale=2.0000 norm=1.2987\n",
      "[iter 26] loss=0.9050 val_loss=0.9374 scale=2.0000 norm=1.2911\n",
      "[iter 27] loss=0.8895 val_loss=0.9227 scale=2.0000 norm=1.2843\n",
      "[iter 28] loss=0.8744 val_loss=0.9084 scale=2.0000 norm=1.2784\n",
      "[iter 29] loss=0.8598 val_loss=0.8946 scale=2.0000 norm=1.2733\n",
      "[iter 30] loss=0.8456 val_loss=0.8813 scale=2.0000 norm=1.2688\n",
      "[iter 31] loss=0.8319 val_loss=0.8683 scale=2.0000 norm=1.2649\n",
      "[iter 32] loss=0.8186 val_loss=0.8558 scale=2.0000 norm=1.2616\n",
      "[iter 33] loss=0.8057 val_loss=0.8436 scale=2.0000 norm=1.2588\n",
      "[iter 34] loss=0.7933 val_loss=0.8319 scale=2.0000 norm=1.2564\n",
      "[iter 35] loss=0.7812 val_loss=0.8206 scale=2.0000 norm=1.2545\n",
      "[iter 36] loss=0.7696 val_loss=0.8096 scale=2.0000 norm=1.2529\n",
      "[iter 37] loss=0.7583 val_loss=0.7990 scale=2.0000 norm=1.2517\n",
      "[iter 38] loss=0.7474 val_loss=0.7888 scale=2.0000 norm=1.2508\n",
      "[iter 39] loss=0.7369 val_loss=0.7789 scale=2.0000 norm=1.2503\n",
      "[iter 40] loss=0.7268 val_loss=0.7694 scale=2.0000 norm=1.2499\n",
      "[iter 41] loss=0.7170 val_loss=0.7602 scale=2.0000 norm=1.2498\n",
      "[iter 42] loss=0.7076 val_loss=0.7514 scale=2.0000 norm=1.2500\n",
      "[iter 43] loss=0.6985 val_loss=0.7428 scale=2.0000 norm=1.2503\n",
      "[iter 44] loss=0.6897 val_loss=0.7346 scale=2.0000 norm=1.2508\n",
      "[iter 45] loss=0.6813 val_loss=0.7268 scale=2.0000 norm=1.2516\n",
      "[iter 46] loss=0.6731 val_loss=0.7191 scale=2.0000 norm=1.2524\n",
      "[iter 47] loss=0.6653 val_loss=0.7118 scale=2.0000 norm=1.2534\n",
      "[iter 48] loss=0.6578 val_loss=0.7048 scale=2.0000 norm=1.2545\n",
      "[iter 49] loss=0.6506 val_loss=0.6981 scale=2.0000 norm=1.2557\n",
      "[iter 50] loss=0.6436 val_loss=0.6916 scale=2.0000 norm=1.2571\n",
      "[iter 51] loss=0.6369 val_loss=0.6854 scale=2.0000 norm=1.2585\n",
      "[iter 52] loss=0.6305 val_loss=0.6795 scale=2.0000 norm=1.2600\n",
      "[iter 53] loss=0.6244 val_loss=0.6737 scale=2.0000 norm=1.2615\n",
      "[iter 54] loss=0.6185 val_loss=0.6682 scale=2.0000 norm=1.2632\n",
      "[iter 55] loss=0.6128 val_loss=0.6630 scale=2.0000 norm=1.2649\n",
      "[iter 56] loss=0.6074 val_loss=0.6579 scale=2.0000 norm=1.2667\n",
      "[iter 57] loss=0.6022 val_loss=0.6531 scale=2.0000 norm=1.2685\n",
      "[iter 58] loss=0.5972 val_loss=0.6486 scale=2.0000 norm=1.2704\n",
      "[iter 59] loss=0.5924 val_loss=0.6443 scale=2.0000 norm=1.2723\n",
      "[iter 60] loss=0.5879 val_loss=0.6402 scale=2.0000 norm=1.2741\n",
      "[iter 61] loss=0.5835 val_loss=0.6362 scale=2.0000 norm=1.2761\n",
      "[iter 62] loss=0.5793 val_loss=0.6324 scale=2.0000 norm=1.2780\n",
      "[iter 63] loss=0.5753 val_loss=0.6289 scale=2.0000 norm=1.2800\n",
      "[iter 64] loss=0.5715 val_loss=0.6255 scale=2.0000 norm=1.2820\n",
      "[iter 65] loss=0.5679 val_loss=0.6223 scale=2.0000 norm=1.2840\n",
      "[iter 66] loss=0.5644 val_loss=0.6192 scale=2.0000 norm=1.2859\n",
      "[iter 67] loss=0.5611 val_loss=0.6163 scale=2.0000 norm=1.2879\n",
      "[iter 68] loss=0.5579 val_loss=0.6136 scale=2.0000 norm=1.2899\n",
      "[iter 69] loss=0.5549 val_loss=0.6110 scale=2.0000 norm=1.2919\n",
      "[iter 70] loss=0.5520 val_loss=0.6086 scale=2.0000 norm=1.2938\n",
      "[iter 71] loss=0.5492 val_loss=0.6063 scale=2.0000 norm=1.2958\n",
      "[iter 72] loss=0.5467 val_loss=0.6042 scale=2.0000 norm=1.2978\n",
      "[iter 73] loss=0.5442 val_loss=0.6022 scale=2.0000 norm=1.2997\n",
      "[iter 74] loss=0.5419 val_loss=0.6004 scale=2.0000 norm=1.3016\n",
      "[iter 75] loss=0.5397 val_loss=0.5986 scale=2.0000 norm=1.3036\n",
      "[iter 76] loss=0.5375 val_loss=0.5971 scale=2.0000 norm=1.3054\n",
      "[iter 77] loss=0.5355 val_loss=0.5956 scale=2.0000 norm=1.3073\n",
      "[iter 78] loss=0.5336 val_loss=0.5943 scale=2.0000 norm=1.3092\n",
      "[iter 79] loss=0.5319 val_loss=0.5930 scale=2.0000 norm=1.3110\n",
      "[iter 80] loss=0.5302 val_loss=0.5918 scale=2.0000 norm=1.3128\n",
      "[iter 81] loss=0.5286 val_loss=0.5907 scale=2.0000 norm=1.3146\n",
      "[iter 82] loss=0.5270 val_loss=0.5897 scale=2.0000 norm=1.3163\n",
      "[iter 83] loss=0.5256 val_loss=0.5888 scale=2.0000 norm=1.3181\n",
      "[iter 84] loss=0.5242 val_loss=0.5878 scale=2.0000 norm=1.3197\n",
      "[iter 85] loss=0.5229 val_loss=0.5869 scale=2.0000 norm=1.3214\n",
      "[iter 86] loss=0.5217 val_loss=0.5862 scale=2.0000 norm=1.3230\n",
      "[iter 87] loss=0.5206 val_loss=0.5856 scale=2.0000 norm=1.3246\n",
      "[iter 88] loss=0.5195 val_loss=0.5853 scale=2.0000 norm=1.3261\n",
      "[iter 89] loss=0.5185 val_loss=0.5848 scale=2.0000 norm=1.3275\n",
      "[iter 90] loss=0.5176 val_loss=0.5843 scale=2.0000 norm=1.3290\n",
      "[iter 91] loss=0.5167 val_loss=0.5840 scale=2.0000 norm=1.3305\n",
      "[iter 92] loss=0.5159 val_loss=0.5837 scale=2.0000 norm=1.3318\n",
      "[iter 93] loss=0.5150 val_loss=0.5835 scale=2.0000 norm=1.3331\n",
      "[iter 94] loss=0.5143 val_loss=0.5832 scale=2.0000 norm=1.3345\n",
      "[iter 95] loss=0.5135 val_loss=0.5832 scale=2.0000 norm=1.3357\n",
      "[iter 96] loss=0.5129 val_loss=0.5832 scale=2.0000 norm=1.3369\n",
      "[iter 97] loss=0.5123 val_loss=0.5832 scale=2.0000 norm=1.3379\n",
      "[iter 98] loss=0.5116 val_loss=0.5831 scale=2.0000 norm=1.3389\n",
      "[iter 99] loss=0.5111 val_loss=0.5829 scale=2.0000 norm=1.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 4 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0960\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5834 val_loss=0.6084 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5814 scale=1.0000 norm=1.0241\n",
      "[iter 7] loss=0.5450 val_loss=0.5689 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5333 val_loss=0.5569 scale=1.0000 norm=1.0063\n",
      "[iter 9] loss=0.5222 val_loss=0.5455 scale=1.0000 norm=0.9992\n",
      "[iter 10] loss=0.5116 val_loss=0.5346 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5014 val_loss=0.5242 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4916 val_loss=0.5142 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4823 val_loss=0.5045 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4733 val_loss=0.4953 scale=1.0000 norm=0.9789\n",
      "[iter 15] loss=0.4646 val_loss=0.4865 scale=1.0000 norm=0.9775\n",
      "[iter 16] loss=0.4563 val_loss=0.4779 scale=1.0000 norm=0.9768\n",
      "[iter 17] loss=0.4483 val_loss=0.4698 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4406 val_loss=0.4619 scale=1.0000 norm=0.9778\n",
      "[iter 19] loss=0.4332 val_loss=0.4543 scale=1.0000 norm=0.9794\n",
      "[iter 20] loss=0.4260 val_loss=0.4469 scale=1.0000 norm=0.9816\n",
      "[iter 21] loss=0.4191 val_loss=0.4399 scale=1.0000 norm=0.9844\n",
      "[iter 22] loss=0.4124 val_loss=0.4330 scale=1.0000 norm=0.9879\n",
      "[iter 23] loss=0.4059 val_loss=0.4264 scale=1.0000 norm=0.9921\n",
      "[iter 24] loss=0.3997 val_loss=0.4200 scale=1.0000 norm=0.9969\n",
      "[iter 25] loss=0.3937 val_loss=0.4138 scale=1.0000 norm=1.0022\n",
      "[iter 26] loss=0.3878 val_loss=0.4078 scale=1.0000 norm=1.0082\n",
      "[iter 27] loss=0.3822 val_loss=0.4021 scale=1.0000 norm=1.0147\n",
      "[iter 28] loss=0.3767 val_loss=0.3965 scale=1.0000 norm=1.0218\n",
      "[iter 29] loss=0.3715 val_loss=0.3911 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3664 val_loss=0.3858 scale=1.0000 norm=1.0377\n",
      "[iter 31] loss=0.3614 val_loss=0.3808 scale=1.0000 norm=1.0465\n",
      "[iter 32] loss=0.3567 val_loss=0.3759 scale=1.0000 norm=1.0559\n",
      "[iter 33] loss=0.3521 val_loss=0.3711 scale=1.0000 norm=1.0658\n",
      "[iter 34] loss=0.3476 val_loss=0.3666 scale=1.0000 norm=1.0763\n",
      "[iter 35] loss=0.3433 val_loss=0.3622 scale=1.0000 norm=1.0874\n",
      "[iter 36] loss=0.3392 val_loss=0.3579 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3352 val_loss=0.3538 scale=1.0000 norm=1.1113\n",
      "[iter 38] loss=0.3314 val_loss=0.3498 scale=1.0000 norm=1.1240\n",
      "[iter 39] loss=0.3277 val_loss=0.3460 scale=1.0000 norm=1.1373\n",
      "[iter 40] loss=0.3241 val_loss=0.3423 scale=1.0000 norm=1.1511\n",
      "[iter 41] loss=0.3206 val_loss=0.3387 scale=1.0000 norm=1.1655\n",
      "[iter 42] loss=0.3173 val_loss=0.3352 scale=1.0000 norm=1.1804\n",
      "[iter 43] loss=0.3141 val_loss=0.3319 scale=1.0000 norm=1.1958\n",
      "[iter 44] loss=0.3110 val_loss=0.3288 scale=1.0000 norm=1.2118\n",
      "[iter 45] loss=0.3080 val_loss=0.3257 scale=1.0000 norm=1.2283\n",
      "[iter 46] loss=0.3052 val_loss=0.3227 scale=1.0000 norm=1.2454\n",
      "[iter 47] loss=0.3025 val_loss=0.3198 scale=1.0000 norm=1.2630\n",
      "[iter 48] loss=0.2998 val_loss=0.3171 scale=1.0000 norm=1.2809\n",
      "[iter 49] loss=0.2973 val_loss=0.3144 scale=1.0000 norm=1.2993\n",
      "[iter 50] loss=0.2949 val_loss=0.3119 scale=1.0000 norm=1.3181\n",
      "[iter 51] loss=0.2925 val_loss=0.3095 scale=1.0000 norm=1.3374\n",
      "[iter 52] loss=0.2903 val_loss=0.3072 scale=1.0000 norm=1.3575\n",
      "[iter 53] loss=0.2882 val_loss=0.3049 scale=1.0000 norm=1.3777\n",
      "[iter 54] loss=0.2861 val_loss=0.3028 scale=1.0000 norm=1.3983\n",
      "[iter 55] loss=0.2842 val_loss=0.3008 scale=1.0000 norm=1.4194\n",
      "[iter 56] loss=0.2823 val_loss=0.2988 scale=1.0000 norm=1.4408\n",
      "[iter 57] loss=0.2805 val_loss=0.2969 scale=1.0000 norm=1.4627\n",
      "[iter 58] loss=0.2788 val_loss=0.2952 scale=1.0000 norm=1.4846\n",
      "[iter 59] loss=0.2772 val_loss=0.2934 scale=1.0000 norm=1.5069\n",
      "[iter 60] loss=0.2756 val_loss=0.2918 scale=1.0000 norm=1.5293\n",
      "[iter 61] loss=0.2741 val_loss=0.2903 scale=1.0000 norm=1.5520\n",
      "[iter 62] loss=0.2727 val_loss=0.2888 scale=1.0000 norm=1.5751\n",
      "[iter 63] loss=0.2713 val_loss=0.2874 scale=1.0000 norm=1.5980\n",
      "[iter 64] loss=0.2700 val_loss=0.2861 scale=1.0000 norm=1.6211\n",
      "[iter 65] loss=0.2688 val_loss=0.2847 scale=1.0000 norm=1.6443\n",
      "[iter 66] loss=0.2676 val_loss=0.2835 scale=1.0000 norm=1.6677\n",
      "[iter 67] loss=0.2665 val_loss=0.2823 scale=1.0000 norm=1.6912\n",
      "[iter 68] loss=0.2654 val_loss=0.2813 scale=1.0000 norm=1.7147\n",
      "[iter 69] loss=0.2644 val_loss=0.2802 scale=1.0000 norm=1.7387\n",
      "[iter 70] loss=0.2635 val_loss=0.2792 scale=1.0000 norm=1.7623\n",
      "[iter 71] loss=0.2626 val_loss=0.2783 scale=1.0000 norm=1.7857\n",
      "[iter 72] loss=0.2617 val_loss=0.2774 scale=1.0000 norm=1.8095\n",
      "[iter 73] loss=0.2609 val_loss=0.2765 scale=1.0000 norm=1.8328\n",
      "[iter 74] loss=0.2601 val_loss=0.2757 scale=1.0000 norm=1.8561\n",
      "[iter 75] loss=0.2594 val_loss=0.2750 scale=1.0000 norm=1.8797\n",
      "[iter 76] loss=0.2587 val_loss=0.2742 scale=1.0000 norm=1.9026\n",
      "[iter 77] loss=0.2580 val_loss=0.2736 scale=1.0000 norm=1.9252\n",
      "[iter 78] loss=0.2574 val_loss=0.2729 scale=1.0000 norm=1.9479\n",
      "[iter 79] loss=0.2568 val_loss=0.2723 scale=1.0000 norm=1.9698\n",
      "[iter 80] loss=0.2562 val_loss=0.2718 scale=1.0000 norm=1.9922\n",
      "[iter 81] loss=0.2557 val_loss=0.2713 scale=1.0000 norm=2.0139\n",
      "[iter 82] loss=0.2552 val_loss=0.2707 scale=1.0000 norm=2.0354\n",
      "[iter 83] loss=0.2548 val_loss=0.2705 scale=0.5000 norm=1.0279\n",
      "[iter 84] loss=0.2546 val_loss=0.2703 scale=0.5000 norm=1.0330\n",
      "[iter 85] loss=0.2543 val_loss=0.2701 scale=0.5000 norm=1.0381\n",
      "[iter 86] loss=0.2541 val_loss=0.2699 scale=0.5000 norm=1.0430\n",
      "[iter 87] loss=0.2539 val_loss=0.2697 scale=0.5000 norm=1.0479\n",
      "[iter 88] loss=0.2537 val_loss=0.2695 scale=0.5000 norm=1.0526\n",
      "[iter 89] loss=0.2536 val_loss=0.2693 scale=0.5000 norm=1.0573\n",
      "[iter 90] loss=0.2534 val_loss=0.2691 scale=0.5000 norm=1.0622\n",
      "[iter 91] loss=0.2532 val_loss=0.2690 scale=0.5000 norm=1.0668\n",
      "[iter 92] loss=0.2530 val_loss=0.2688 scale=0.5000 norm=1.0713\n",
      "[iter 93] loss=0.2529 val_loss=0.2687 scale=0.5000 norm=1.0758\n",
      "[iter 94] loss=0.2527 val_loss=0.2686 scale=0.5000 norm=1.0805\n",
      "[iter 95] loss=0.2526 val_loss=0.2684 scale=0.5000 norm=1.0849\n",
      "[iter 96] loss=0.2524 val_loss=0.2683 scale=0.5000 norm=1.0895\n",
      "[iter 97] loss=0.2523 val_loss=0.2682 scale=0.5000 norm=1.0941\n",
      "[iter 98] loss=0.2522 val_loss=0.2681 scale=0.5000 norm=1.0985\n",
      "[iter 99] loss=0.2520 val_loss=0.2679 scale=0.5000 norm=1.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 5 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5773 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5268 val_loss=1.5446 scale=1.0000 norm=1.0742\n",
      "[iter 2] loss=1.4944 val_loss=1.5156 scale=1.0000 norm=1.0440\n",
      "[iter 3] loss=1.4660 val_loss=1.4894 scale=1.0000 norm=1.0173\n",
      "[iter 4] loss=1.4404 val_loss=1.4424 scale=2.0000 norm=1.9869\n",
      "[iter 5] loss=1.3948 val_loss=1.4023 scale=2.0000 norm=1.9015\n",
      "[iter 6] loss=1.3554 val_loss=1.3664 scale=2.0000 norm=1.8286\n",
      "[iter 7] loss=1.3203 val_loss=1.3333 scale=2.0000 norm=1.7648\n",
      "[iter 8] loss=1.2882 val_loss=1.3032 scale=2.0000 norm=1.7084\n",
      "[iter 9] loss=1.2584 val_loss=1.2746 scale=2.0000 norm=1.6583\n",
      "[iter 10] loss=1.2304 val_loss=1.2479 scale=2.0000 norm=1.6133\n",
      "[iter 11] loss=1.2039 val_loss=1.2225 scale=2.0000 norm=1.5729\n",
      "[iter 12] loss=1.1787 val_loss=1.1983 scale=2.0000 norm=1.5368\n",
      "[iter 13] loss=1.1545 val_loss=1.1750 scale=2.0000 norm=1.5042\n",
      "[iter 14] loss=1.1312 val_loss=1.1527 scale=2.0000 norm=1.4749\n",
      "[iter 15] loss=1.1088 val_loss=1.1311 scale=2.0000 norm=1.4485\n",
      "[iter 16] loss=1.0870 val_loss=1.1103 scale=2.0000 norm=1.4248\n",
      "[iter 17] loss=1.0660 val_loss=1.0901 scale=2.0000 norm=1.4035\n",
      "[iter 18] loss=1.0456 val_loss=1.0704 scale=2.0000 norm=1.3843\n",
      "[iter 19] loss=1.0258 val_loss=1.0515 scale=2.0000 norm=1.3670\n",
      "[iter 20] loss=1.0065 val_loss=1.0331 scale=2.0000 norm=1.3516\n",
      "[iter 21] loss=0.9877 val_loss=1.0152 scale=2.0000 norm=1.3375\n",
      "[iter 22] loss=0.9694 val_loss=0.9978 scale=2.0000 norm=1.3250\n",
      "[iter 23] loss=0.9516 val_loss=0.9810 scale=2.0000 norm=1.3138\n",
      "[iter 24] loss=0.9344 val_loss=0.9646 scale=2.0000 norm=1.3038\n",
      "[iter 25] loss=0.9175 val_loss=0.9485 scale=2.0000 norm=1.2947\n",
      "[iter 26] loss=0.9010 val_loss=0.9331 scale=2.0000 norm=1.2866\n",
      "[iter 27] loss=0.8851 val_loss=0.9183 scale=2.0000 norm=1.2795\n",
      "[iter 28] loss=0.8697 val_loss=0.9035 scale=2.0000 norm=1.2731\n",
      "[iter 29] loss=0.8546 val_loss=0.8894 scale=2.0000 norm=1.2675\n",
      "[iter 30] loss=0.8401 val_loss=0.8755 scale=2.0000 norm=1.2627\n",
      "[iter 31] loss=0.8258 val_loss=0.8620 scale=2.0000 norm=1.2583\n",
      "[iter 32] loss=0.8120 val_loss=0.8490 scale=2.0000 norm=1.2545\n",
      "[iter 33] loss=0.7987 val_loss=0.8362 scale=2.0000 norm=1.2512\n",
      "[iter 34] loss=0.7857 val_loss=0.8239 scale=2.0000 norm=1.2484\n",
      "[iter 35] loss=0.7731 val_loss=0.8120 scale=2.0000 norm=1.2460\n",
      "[iter 36] loss=0.7610 val_loss=0.8003 scale=2.0000 norm=1.2440\n",
      "[iter 37] loss=0.7492 val_loss=0.7891 scale=2.0000 norm=1.2423\n",
      "[iter 38] loss=0.7378 val_loss=0.7781 scale=2.0000 norm=1.2411\n",
      "[iter 39] loss=0.7267 val_loss=0.7677 scale=2.0000 norm=1.2400\n",
      "[iter 40] loss=0.7161 val_loss=0.7575 scale=2.0000 norm=1.2393\n",
      "[iter 41] loss=0.7058 val_loss=0.7479 scale=2.0000 norm=1.2388\n",
      "[iter 42] loss=0.6959 val_loss=0.7383 scale=2.0000 norm=1.2386\n",
      "[iter 43] loss=0.6862 val_loss=0.7293 scale=2.0000 norm=1.2385\n",
      "[iter 44] loss=0.6769 val_loss=0.7204 scale=2.0000 norm=1.2387\n",
      "[iter 45] loss=0.6679 val_loss=0.7120 scale=2.0000 norm=1.2390\n",
      "[iter 46] loss=0.6593 val_loss=0.7038 scale=2.0000 norm=1.2395\n",
      "[iter 47] loss=0.6509 val_loss=0.6960 scale=2.0000 norm=1.2401\n",
      "[iter 48] loss=0.6429 val_loss=0.6885 scale=2.0000 norm=1.2409\n",
      "[iter 49] loss=0.6352 val_loss=0.6810 scale=2.0000 norm=1.2419\n",
      "[iter 50] loss=0.6277 val_loss=0.6739 scale=2.0000 norm=1.2429\n",
      "[iter 51] loss=0.6205 val_loss=0.6671 scale=2.0000 norm=1.2440\n",
      "[iter 52] loss=0.6136 val_loss=0.6607 scale=2.0000 norm=1.2452\n",
      "[iter 53] loss=0.6070 val_loss=0.6543 scale=2.0000 norm=1.2465\n",
      "[iter 54] loss=0.6006 val_loss=0.6483 scale=2.0000 norm=1.2480\n",
      "[iter 55] loss=0.5945 val_loss=0.6422 scale=2.0000 norm=1.2494\n",
      "[iter 56] loss=0.5885 val_loss=0.6367 scale=2.0000 norm=1.2510\n",
      "[iter 57] loss=0.5829 val_loss=0.6313 scale=2.0000 norm=1.2526\n",
      "[iter 58] loss=0.5774 val_loss=0.6260 scale=2.0000 norm=1.2542\n",
      "[iter 59] loss=0.5722 val_loss=0.6211 scale=2.0000 norm=1.2558\n",
      "[iter 60] loss=0.5672 val_loss=0.6164 scale=2.0000 norm=1.2575\n",
      "[iter 61] loss=0.5623 val_loss=0.6119 scale=2.0000 norm=1.2593\n",
      "[iter 62] loss=0.5577 val_loss=0.6076 scale=2.0000 norm=1.2612\n",
      "[iter 63] loss=0.5533 val_loss=0.6035 scale=2.0000 norm=1.2629\n",
      "[iter 64] loss=0.5491 val_loss=0.5994 scale=2.0000 norm=1.2647\n",
      "[iter 65] loss=0.5450 val_loss=0.5958 scale=2.0000 norm=1.2666\n",
      "[iter 66] loss=0.5411 val_loss=0.5923 scale=2.0000 norm=1.2684\n",
      "[iter 67] loss=0.5374 val_loss=0.5888 scale=2.0000 norm=1.2702\n",
      "[iter 68] loss=0.5338 val_loss=0.5857 scale=2.0000 norm=1.2721\n",
      "[iter 69] loss=0.5305 val_loss=0.5827 scale=2.0000 norm=1.2738\n",
      "[iter 70] loss=0.5272 val_loss=0.5799 scale=2.0000 norm=1.2756\n",
      "[iter 71] loss=0.5241 val_loss=0.5772 scale=2.0000 norm=1.2775\n",
      "[iter 72] loss=0.5212 val_loss=0.5748 scale=2.0000 norm=1.2793\n",
      "[iter 73] loss=0.5184 val_loss=0.5724 scale=2.0000 norm=1.2811\n",
      "[iter 74] loss=0.5157 val_loss=0.5701 scale=2.0000 norm=1.2829\n",
      "[iter 75] loss=0.5131 val_loss=0.5678 scale=2.0000 norm=1.2848\n",
      "[iter 76] loss=0.5106 val_loss=0.5658 scale=2.0000 norm=1.2865\n",
      "[iter 77] loss=0.5083 val_loss=0.5638 scale=2.0000 norm=1.2882\n",
      "[iter 78] loss=0.5061 val_loss=0.5620 scale=2.0000 norm=1.2900\n",
      "[iter 79] loss=0.5040 val_loss=0.5601 scale=2.0000 norm=1.2917\n",
      "[iter 80] loss=0.5019 val_loss=0.5587 scale=2.0000 norm=1.2935\n",
      "[iter 81] loss=0.5000 val_loss=0.5573 scale=2.0000 norm=1.2951\n",
      "[iter 82] loss=0.4982 val_loss=0.5559 scale=2.0000 norm=1.2968\n",
      "[iter 83] loss=0.4964 val_loss=0.5545 scale=2.0000 norm=1.2984\n",
      "[iter 84] loss=0.4948 val_loss=0.5533 scale=2.0000 norm=1.3000\n",
      "[iter 85] loss=0.4932 val_loss=0.5522 scale=2.0000 norm=1.3015\n",
      "[iter 86] loss=0.4917 val_loss=0.5513 scale=2.0000 norm=1.3031\n",
      "[iter 87] loss=0.4903 val_loss=0.5502 scale=2.0000 norm=1.3046\n",
      "[iter 88] loss=0.4889 val_loss=0.5495 scale=2.0000 norm=1.3061\n",
      "[iter 89] loss=0.4877 val_loss=0.5491 scale=2.0000 norm=1.3075\n",
      "[iter 90] loss=0.4865 val_loss=0.5483 scale=2.0000 norm=1.3088\n",
      "[iter 91] loss=0.4854 val_loss=0.5477 scale=2.0000 norm=1.3102\n",
      "[iter 92] loss=0.4843 val_loss=0.5472 scale=2.0000 norm=1.3116\n",
      "[iter 93] loss=0.4833 val_loss=0.5468 scale=2.0000 norm=1.3129\n",
      "[iter 94] loss=0.4823 val_loss=0.5462 scale=2.0000 norm=1.3142\n",
      "[iter 95] loss=0.4814 val_loss=0.5459 scale=2.0000 norm=1.3155\n",
      "[iter 96] loss=0.4805 val_loss=0.5455 scale=2.0000 norm=1.3166\n",
      "[iter 97] loss=0.4797 val_loss=0.5452 scale=2.0000 norm=1.3178\n",
      "[iter 98] loss=0.4789 val_loss=0.5450 scale=2.0000 norm=1.3190\n",
      "[iter 99] loss=0.4782 val_loss=0.5445 scale=2.0000 norm=1.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 6 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0952\n",
      "[iter 2] loss=0.6111 val_loss=0.6360 scale=1.0000 norm=1.0760\n",
      "[iter 3] loss=0.5953 val_loss=0.6198 scale=1.0000 norm=1.0588\n",
      "[iter 4] loss=0.5803 val_loss=0.6043 scale=1.0000 norm=1.0438\n",
      "[iter 5] loss=0.5659 val_loss=0.5895 scale=1.0000 norm=1.0302\n",
      "[iter 6] loss=0.5522 val_loss=0.5753 scale=1.0000 norm=1.0183\n",
      "[iter 7] loss=0.5389 val_loss=0.5618 scale=1.0000 norm=1.0078\n",
      "[iter 8] loss=0.5262 val_loss=0.5488 scale=1.0000 norm=0.9986\n",
      "[iter 9] loss=0.5140 val_loss=0.5364 scale=1.0000 norm=0.9906\n",
      "[iter 10] loss=0.5022 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4800 val_loss=0.5015 scale=1.0000 norm=0.9735\n",
      "[iter 13] loss=0.4693 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9653\n",
      "[iter 16] loss=0.4395 val_loss=0.4603 scale=1.0000 norm=0.9644\n",
      "[iter 17] loss=0.4302 val_loss=0.4508 scale=1.0000 norm=0.9645\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9653\n",
      "[iter 19] loss=0.4123 val_loss=0.4326 scale=1.0000 norm=0.9671\n",
      "[iter 20] loss=0.4038 val_loss=0.4239 scale=1.0000 norm=0.9695\n",
      "[iter 21] loss=0.3955 val_loss=0.4154 scale=1.0000 norm=0.9730\n",
      "[iter 22] loss=0.3874 val_loss=0.4069 scale=1.0000 norm=0.9772\n",
      "[iter 23] loss=0.3794 val_loss=0.3989 scale=1.0000 norm=0.9822\n",
      "[iter 24] loss=0.3717 val_loss=0.3911 scale=1.0000 norm=0.9881\n",
      "[iter 25] loss=0.3643 val_loss=0.3834 scale=1.0000 norm=0.9948\n",
      "[iter 26] loss=0.3569 val_loss=0.3759 scale=1.0000 norm=1.0023\n",
      "[iter 27] loss=0.3499 val_loss=0.3687 scale=1.0000 norm=1.0107\n",
      "[iter 28] loss=0.3429 val_loss=0.3617 scale=1.0000 norm=1.0198\n",
      "[iter 29] loss=0.3362 val_loss=0.3547 scale=1.0000 norm=1.0299\n",
      "[iter 30] loss=0.3296 val_loss=0.3481 scale=1.0000 norm=1.0407\n",
      "[iter 31] loss=0.3232 val_loss=0.3416 scale=1.0000 norm=1.0523\n",
      "[iter 32] loss=0.3169 val_loss=0.3353 scale=1.0000 norm=1.0650\n",
      "[iter 33] loss=0.3108 val_loss=0.3290 scale=1.0000 norm=1.0785\n",
      "[iter 34] loss=0.3049 val_loss=0.3228 scale=1.0000 norm=1.0929\n",
      "[iter 35] loss=0.2991 val_loss=0.3170 scale=1.0000 norm=1.1080\n",
      "[iter 36] loss=0.2935 val_loss=0.3113 scale=1.0000 norm=1.1244\n",
      "[iter 37] loss=0.2881 val_loss=0.3058 scale=1.0000 norm=1.1416\n",
      "[iter 38] loss=0.2828 val_loss=0.3003 scale=1.0000 norm=1.1599\n",
      "[iter 39] loss=0.2776 val_loss=0.2951 scale=1.0000 norm=1.1790\n",
      "[iter 40] loss=0.2727 val_loss=0.2900 scale=1.0000 norm=1.1991\n",
      "[iter 41] loss=0.2678 val_loss=0.2851 scale=1.0000 norm=1.2205\n",
      "[iter 42] loss=0.2631 val_loss=0.2803 scale=1.0000 norm=1.2428\n",
      "[iter 43] loss=0.2585 val_loss=0.2757 scale=1.0000 norm=1.2664\n",
      "[iter 44] loss=0.2541 val_loss=0.2712 scale=1.0000 norm=1.2910\n",
      "[iter 45] loss=0.2499 val_loss=0.2669 scale=1.0000 norm=1.3170\n",
      "[iter 46] loss=0.2458 val_loss=0.2626 scale=1.0000 norm=1.3439\n",
      "[iter 47] loss=0.2418 val_loss=0.2586 scale=1.0000 norm=1.3722\n",
      "[iter 48] loss=0.2380 val_loss=0.2547 scale=1.0000 norm=1.4018\n",
      "[iter 49] loss=0.2343 val_loss=0.2510 scale=1.0000 norm=1.4329\n",
      "[iter 50] loss=0.2308 val_loss=0.2473 scale=1.0000 norm=1.4653\n",
      "[iter 51] loss=0.2274 val_loss=0.2439 scale=1.0000 norm=1.4991\n",
      "[iter 52] loss=0.2242 val_loss=0.2405 scale=1.0000 norm=1.5347\n",
      "[iter 53] loss=0.2211 val_loss=0.2374 scale=1.0000 norm=1.5716\n",
      "[iter 54] loss=0.2181 val_loss=0.2343 scale=1.0000 norm=1.6101\n",
      "[iter 55] loss=0.2153 val_loss=0.2313 scale=1.0000 norm=1.6502\n",
      "[iter 56] loss=0.2126 val_loss=0.2286 scale=1.0000 norm=1.6922\n",
      "[iter 57] loss=0.2101 val_loss=0.2260 scale=1.0000 norm=1.7354\n",
      "[iter 58] loss=0.2077 val_loss=0.2234 scale=1.0000 norm=1.7803\n",
      "[iter 59] loss=0.2054 val_loss=0.2211 scale=1.0000 norm=1.8259\n",
      "[iter 60] loss=0.2033 val_loss=0.2189 scale=1.0000 norm=1.8723\n",
      "[iter 61] loss=0.2012 val_loss=0.2167 scale=1.0000 norm=1.9201\n",
      "[iter 62] loss=0.1993 val_loss=0.2146 scale=1.0000 norm=1.9683\n",
      "[iter 63] loss=0.1974 val_loss=0.2125 scale=1.0000 norm=2.0175\n",
      "[iter 64] loss=0.1956 val_loss=0.2107 scale=1.0000 norm=2.0650\n",
      "[iter 65] loss=0.1940 val_loss=0.2088 scale=1.0000 norm=2.1148\n",
      "[iter 66] loss=0.1924 val_loss=0.2071 scale=1.0000 norm=2.1624\n",
      "[iter 67] loss=0.1908 val_loss=0.2055 scale=1.0000 norm=2.2089\n",
      "[iter 68] loss=0.1894 val_loss=0.2040 scale=1.0000 norm=2.2558\n",
      "[iter 69] loss=0.1880 val_loss=0.2024 scale=1.0000 norm=2.3004\n",
      "[iter 70] loss=0.1867 val_loss=0.2010 scale=1.0000 norm=2.3457\n",
      "[iter 71] loss=0.1855 val_loss=0.1997 scale=1.0000 norm=2.3889\n",
      "[iter 72] loss=0.1843 val_loss=0.1984 scale=1.0000 norm=2.4310\n",
      "[iter 73] loss=0.1832 val_loss=0.1972 scale=1.0000 norm=2.4721\n",
      "[iter 74] loss=0.1821 val_loss=0.1960 scale=1.0000 norm=2.5109\n",
      "[iter 75] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5502\n",
      "[iter 76] loss=0.1801 val_loss=0.1940 scale=1.0000 norm=2.5883\n",
      "[iter 77] loss=0.1792 val_loss=0.1930 scale=1.0000 norm=2.6249\n",
      "[iter 78] loss=0.1784 val_loss=0.1919 scale=1.0000 norm=2.6617\n",
      "[iter 79] loss=0.1775 val_loss=0.1911 scale=1.0000 norm=2.6959\n",
      "[iter 80] loss=0.1768 val_loss=0.1902 scale=1.0000 norm=2.7289\n",
      "[iter 81] loss=0.1760 val_loss=0.1895 scale=1.0000 norm=2.7603\n",
      "[iter 82] loss=0.1753 val_loss=0.1887 scale=1.0000 norm=2.7905\n",
      "[iter 83] loss=0.1746 val_loss=0.1883 scale=0.5000 norm=1.4094\n",
      "[iter 84] loss=0.1743 val_loss=0.1876 scale=1.0000 norm=2.8341\n",
      "[iter 85] loss=0.1737 val_loss=0.1870 scale=1.0000 norm=2.8618\n",
      "[iter 86] loss=0.1731 val_loss=0.1867 scale=0.5000 norm=1.4439\n",
      "[iter 87] loss=0.1728 val_loss=0.1865 scale=0.5000 norm=1.4502\n",
      "[iter 88] loss=0.1725 val_loss=0.1859 scale=1.0000 norm=2.9145\n",
      "[iter 89] loss=0.1720 val_loss=0.1854 scale=1.0000 norm=2.9379\n",
      "[iter 90] loss=0.1715 val_loss=0.1852 scale=0.5000 norm=1.4811\n",
      "[iter 91] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4876\n",
      "[iter 92] loss=0.1710 val_loss=0.1846 scale=1.0000 norm=2.9870\n",
      "[iter 93] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=3.0107\n",
      "[iter 94] loss=0.1702 val_loss=0.1839 scale=1.0000 norm=3.0335\n",
      "[iter 95] loss=0.1698 val_loss=0.1838 scale=0.5000 norm=1.5294\n",
      "[iter 96] loss=0.1696 val_loss=0.1836 scale=0.5000 norm=1.5356\n",
      "[iter 97] loss=0.1695 val_loss=0.1833 scale=1.0000 norm=3.0847\n",
      "[iter 98] loss=0.1691 val_loss=0.1830 scale=1.0000 norm=3.1097\n",
      "[iter 99] loss=0.1688 val_loss=0.1828 scale=1.0000 norm=3.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 7 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5738 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5229 val_loss=1.5375 scale=1.0000 norm=1.0710\n",
      "[iter 2] loss=1.4873 val_loss=1.5069 scale=1.0000 norm=1.0382\n",
      "[iter 3] loss=1.4571 val_loss=1.4780 scale=1.0000 norm=1.0104\n",
      "[iter 4] loss=1.4293 val_loss=1.4520 scale=1.0000 norm=0.9848\n",
      "[iter 5] loss=1.4045 val_loss=1.4280 scale=1.0000 norm=0.9621\n",
      "[iter 6] loss=1.3814 val_loss=1.4057 scale=1.0000 norm=0.9410\n",
      "[iter 7] loss=1.3598 val_loss=1.3847 scale=1.0000 norm=0.9214\n",
      "[iter 8] loss=1.3392 val_loss=1.3647 scale=1.0000 norm=0.9030\n",
      "[iter 9] loss=1.3197 val_loss=1.3457 scale=1.0000 norm=0.8857\n",
      "[iter 10] loss=1.3012 val_loss=1.3274 scale=1.0000 norm=0.8695\n",
      "[iter 11] loss=1.2833 val_loss=1.3098 scale=1.0000 norm=0.8541\n",
      "[iter 12] loss=1.2657 val_loss=1.2926 scale=1.0000 norm=0.8393\n",
      "[iter 13] loss=1.2488 val_loss=1.2757 scale=1.0000 norm=0.8252\n",
      "[iter 14] loss=1.2322 val_loss=1.2435 scale=2.0000 norm=1.6235\n",
      "[iter 15] loss=1.2005 val_loss=1.2119 scale=2.0000 norm=1.5735\n",
      "[iter 16] loss=1.1694 val_loss=1.1824 scale=2.0000 norm=1.5270\n",
      "[iter 17] loss=1.1400 val_loss=1.1535 scale=2.0000 norm=1.4855\n",
      "[iter 18] loss=1.1114 val_loss=1.1254 scale=2.0000 norm=1.4478\n",
      "[iter 19] loss=1.0833 val_loss=1.0979 scale=2.0000 norm=1.4129\n",
      "[iter 20] loss=1.0559 val_loss=1.0713 scale=2.0000 norm=1.3806\n",
      "[iter 21] loss=1.0294 val_loss=1.0452 scale=2.0000 norm=1.3519\n",
      "[iter 22] loss=1.0031 val_loss=1.0199 scale=2.0000 norm=1.3252\n",
      "[iter 23] loss=0.9772 val_loss=0.9952 scale=2.0000 norm=1.3006\n",
      "[iter 24] loss=0.9521 val_loss=0.9708 scale=2.0000 norm=1.2787\n",
      "[iter 25] loss=0.9272 val_loss=0.9466 scale=2.0000 norm=1.2586\n",
      "[iter 26] loss=0.9027 val_loss=0.9233 scale=2.0000 norm=1.2399\n",
      "[iter 27] loss=0.8787 val_loss=0.8998 scale=2.0000 norm=1.2231\n",
      "[iter 28] loss=0.8548 val_loss=0.8771 scale=2.0000 norm=1.2074\n",
      "[iter 29] loss=0.8315 val_loss=0.8549 scale=2.0000 norm=1.1933\n",
      "[iter 30] loss=0.8085 val_loss=0.8326 scale=2.0000 norm=1.1803\n",
      "[iter 31] loss=0.7857 val_loss=0.8107 scale=2.0000 norm=1.1681\n",
      "[iter 32] loss=0.7634 val_loss=0.7895 scale=2.0000 norm=1.1572\n",
      "[iter 33] loss=0.7415 val_loss=0.7685 scale=2.0000 norm=1.1471\n",
      "[iter 34] loss=0.7198 val_loss=0.7482 scale=2.0000 norm=1.1378\n",
      "[iter 35] loss=0.6987 val_loss=0.7279 scale=2.0000 norm=1.1294\n",
      "[iter 36] loss=0.6778 val_loss=0.7080 scale=2.0000 norm=1.1215\n",
      "[iter 37] loss=0.6573 val_loss=0.6886 scale=2.0000 norm=1.1144\n",
      "[iter 38] loss=0.6372 val_loss=0.6697 scale=2.0000 norm=1.1077\n",
      "[iter 39] loss=0.6176 val_loss=0.6511 scale=2.0000 norm=1.1016\n",
      "[iter 40] loss=0.5982 val_loss=0.6329 scale=2.0000 norm=1.0958\n",
      "[iter 41] loss=0.5793 val_loss=0.6152 scale=2.0000 norm=1.0907\n",
      "[iter 42] loss=0.5607 val_loss=0.5980 scale=2.0000 norm=1.0859\n",
      "[iter 43] loss=0.5426 val_loss=0.5812 scale=2.0000 norm=1.0816\n",
      "[iter 44] loss=0.5250 val_loss=0.5648 scale=2.0000 norm=1.0776\n",
      "[iter 45] loss=0.5077 val_loss=0.5486 scale=2.0000 norm=1.0739\n",
      "[iter 46] loss=0.4908 val_loss=0.5330 scale=2.0000 norm=1.0704\n",
      "[iter 47] loss=0.4743 val_loss=0.5178 scale=2.0000 norm=1.0673\n",
      "[iter 48] loss=0.4582 val_loss=0.5030 scale=2.0000 norm=1.0644\n",
      "[iter 49] loss=0.4426 val_loss=0.4885 scale=2.0000 norm=1.0619\n",
      "[iter 50] loss=0.4274 val_loss=0.4745 scale=2.0000 norm=1.0595\n",
      "[iter 51] loss=0.4125 val_loss=0.4608 scale=2.0000 norm=1.0575\n",
      "[iter 52] loss=0.3980 val_loss=0.4477 scale=2.0000 norm=1.0557\n",
      "[iter 53] loss=0.3840 val_loss=0.4351 scale=2.0000 norm=1.0541\n",
      "[iter 54] loss=0.3703 val_loss=0.4229 scale=2.0000 norm=1.0525\n",
      "[iter 55] loss=0.3571 val_loss=0.4110 scale=2.0000 norm=1.0514\n",
      "[iter 56] loss=0.3443 val_loss=0.3993 scale=2.0000 norm=1.0504\n",
      "[iter 57] loss=0.3318 val_loss=0.3882 scale=2.0000 norm=1.0496\n",
      "[iter 58] loss=0.3198 val_loss=0.3770 scale=2.0000 norm=1.0490\n",
      "[iter 59] loss=0.3080 val_loss=0.3664 scale=2.0000 norm=1.0484\n",
      "[iter 60] loss=0.2968 val_loss=0.3561 scale=2.0000 norm=1.0483\n",
      "[iter 61] loss=0.2859 val_loss=0.3467 scale=2.0000 norm=1.0482\n",
      "[iter 62] loss=0.2754 val_loss=0.3371 scale=2.0000 norm=1.0484\n",
      "[iter 63] loss=0.2653 val_loss=0.3282 scale=2.0000 norm=1.0487\n",
      "[iter 64] loss=0.2555 val_loss=0.3193 scale=2.0000 norm=1.0491\n",
      "[iter 65] loss=0.2460 val_loss=0.3110 scale=2.0000 norm=1.0496\n",
      "[iter 66] loss=0.2369 val_loss=0.3031 scale=2.0000 norm=1.0501\n",
      "[iter 67] loss=0.2282 val_loss=0.2955 scale=2.0000 norm=1.0510\n",
      "[iter 68] loss=0.2198 val_loss=0.2884 scale=2.0000 norm=1.0521\n",
      "[iter 69] loss=0.2117 val_loss=0.2811 scale=2.0000 norm=1.0532\n",
      "[iter 70] loss=0.2039 val_loss=0.2743 scale=2.0000 norm=1.0543\n",
      "[iter 71] loss=0.1964 val_loss=0.2676 scale=2.0000 norm=1.0556\n",
      "[iter 72] loss=0.1893 val_loss=0.2611 scale=2.0000 norm=1.0570\n",
      "[iter 73] loss=0.1825 val_loss=0.2550 scale=2.0000 norm=1.0585\n",
      "[iter 74] loss=0.1759 val_loss=0.2495 scale=2.0000 norm=1.0601\n",
      "[iter 75] loss=0.1696 val_loss=0.2440 scale=2.0000 norm=1.0618\n",
      "[iter 76] loss=0.1636 val_loss=0.2389 scale=2.0000 norm=1.0636\n",
      "[iter 77] loss=0.1579 val_loss=0.2342 scale=2.0000 norm=1.0655\n",
      "[iter 78] loss=0.1524 val_loss=0.2297 scale=2.0000 norm=1.0674\n",
      "[iter 79] loss=0.1471 val_loss=0.2253 scale=2.0000 norm=1.0693\n",
      "[iter 80] loss=0.1421 val_loss=0.2215 scale=2.0000 norm=1.0713\n",
      "[iter 81] loss=0.1374 val_loss=0.2171 scale=2.0000 norm=1.0733\n",
      "[iter 82] loss=0.1328 val_loss=0.2136 scale=2.0000 norm=1.0753\n",
      "[iter 83] loss=0.1285 val_loss=0.2102 scale=2.0000 norm=1.0775\n",
      "[iter 84] loss=0.1244 val_loss=0.2064 scale=2.0000 norm=1.0796\n",
      "[iter 85] loss=0.1202 val_loss=0.2035 scale=2.0000 norm=1.0817\n",
      "[iter 86] loss=0.1166 val_loss=0.2004 scale=2.0000 norm=1.0839\n",
      "[iter 87] loss=0.1129 val_loss=0.1976 scale=2.0000 norm=1.0860\n",
      "[iter 88] loss=0.1096 val_loss=0.1951 scale=2.0000 norm=1.0882\n",
      "[iter 89] loss=0.1063 val_loss=0.1923 scale=2.0000 norm=1.0904\n",
      "[iter 90] loss=0.1031 val_loss=0.1898 scale=2.0000 norm=1.0924\n",
      "[iter 91] loss=0.1001 val_loss=0.1878 scale=2.0000 norm=1.0945\n",
      "[iter 92] loss=0.0974 val_loss=0.1856 scale=2.0000 norm=1.0968\n",
      "[iter 93] loss=0.0948 val_loss=0.1836 scale=2.0000 norm=1.0990\n",
      "[iter 94] loss=0.0923 val_loss=0.1823 scale=2.0000 norm=1.1012\n",
      "[iter 95] loss=0.0901 val_loss=0.1806 scale=2.0000 norm=1.1034\n",
      "[iter 96] loss=0.0878 val_loss=0.1790 scale=2.0000 norm=1.1056\n",
      "[iter 97] loss=0.0857 val_loss=0.1778 scale=2.0000 norm=1.1078\n",
      "[iter 98] loss=0.0837 val_loss=0.1761 scale=2.0000 norm=1.1098\n",
      "[iter 99] loss=0.0817 val_loss=0.1749 scale=2.0000 norm=1.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 8 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2397 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2365 scale=1.0000 norm=1.5731\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6121\n",
      "[iter 55] loss=0.2148 val_loss=0.2305 scale=1.0000 norm=1.6527\n",
      "[iter 56] loss=0.2121 val_loss=0.2277 scale=1.0000 norm=1.6943\n",
      "[iter 57] loss=0.2096 val_loss=0.2251 scale=1.0000 norm=1.7379\n",
      "[iter 58] loss=0.2072 val_loss=0.2225 scale=1.0000 norm=1.7827\n",
      "[iter 59] loss=0.2049 val_loss=0.2202 scale=1.0000 norm=1.8285\n",
      "[iter 60] loss=0.2027 val_loss=0.2179 scale=1.0000 norm=1.8758\n",
      "[iter 61] loss=0.2006 val_loss=0.2157 scale=1.0000 norm=1.9236\n",
      "[iter 62] loss=0.1987 val_loss=0.2136 scale=1.0000 norm=1.9726\n",
      "[iter 63] loss=0.1968 val_loss=0.2117 scale=1.0000 norm=2.0222\n",
      "[iter 64] loss=0.1950 val_loss=0.2097 scale=1.0000 norm=2.0716\n",
      "[iter 65] loss=0.1934 val_loss=0.2079 scale=1.0000 norm=2.1198\n",
      "[iter 66] loss=0.1918 val_loss=0.2062 scale=1.0000 norm=2.1685\n",
      "[iter 67] loss=0.1903 val_loss=0.2045 scale=1.0000 norm=2.2166\n",
      "[iter 68] loss=0.1888 val_loss=0.2030 scale=1.0000 norm=2.2621\n",
      "[iter 69] loss=0.1874 val_loss=0.2016 scale=1.0000 norm=2.3092\n",
      "[iter 70] loss=0.1861 val_loss=0.2002 scale=1.0000 norm=2.3542\n",
      "[iter 71] loss=0.1849 val_loss=0.1988 scale=1.0000 norm=2.4003\n",
      "[iter 72] loss=0.1837 val_loss=0.1975 scale=1.0000 norm=2.4434\n",
      "[iter 73] loss=0.1826 val_loss=0.1964 scale=1.0000 norm=2.4850\n",
      "[iter 74] loss=0.1816 val_loss=0.1953 scale=1.0000 norm=2.5247\n",
      "[iter 75] loss=0.1806 val_loss=0.1942 scale=1.0000 norm=2.5634\n",
      "[iter 76] loss=0.1796 val_loss=0.1931 scale=1.0000 norm=2.6012\n",
      "[iter 77] loss=0.1787 val_loss=0.1921 scale=1.0000 norm=2.6392\n",
      "[iter 78] loss=0.1778 val_loss=0.1912 scale=1.0000 norm=2.6753\n",
      "[iter 79] loss=0.1770 val_loss=0.1908 scale=0.5000 norm=1.3554\n",
      "[iter 80] loss=0.1766 val_loss=0.1904 scale=0.5000 norm=1.3637\n",
      "[iter 81] loss=0.1762 val_loss=0.1896 scale=1.0000 norm=2.7448\n",
      "[iter 82] loss=0.1755 val_loss=0.1892 scale=0.5000 norm=1.3885\n",
      "[iter 83] loss=0.1752 val_loss=0.1885 scale=1.0000 norm=2.7917\n",
      "[iter 84] loss=0.1745 val_loss=0.1881 scale=0.5000 norm=1.4103\n",
      "[iter 85] loss=0.1741 val_loss=0.1874 scale=1.0000 norm=2.8352\n",
      "[iter 86] loss=0.1735 val_loss=0.1871 scale=0.5000 norm=1.4310\n",
      "[iter 87] loss=0.1732 val_loss=0.1868 scale=0.5000 norm=1.4379\n",
      "[iter 88] loss=0.1729 val_loss=0.1865 scale=0.5000 norm=1.4448\n",
      "[iter 89] loss=0.1726 val_loss=0.1859 scale=1.0000 norm=2.9025\n",
      "[iter 90] loss=0.1721 val_loss=0.1856 scale=0.5000 norm=1.4639\n",
      "[iter 91] loss=0.1718 val_loss=0.1852 scale=1.0000 norm=2.9406\n",
      "[iter 92] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4827\n",
      "[iter 93] loss=0.1711 val_loss=0.1848 scale=0.5000 norm=1.4891\n",
      "[iter 94] loss=0.1709 val_loss=0.1845 scale=0.5000 norm=1.4961\n",
      "[iter 95] loss=0.1706 val_loss=0.1844 scale=0.5000 norm=1.5023\n",
      "[iter 96] loss=0.1704 val_loss=0.1839 scale=1.0000 norm=3.0181\n",
      "[iter 97] loss=0.1700 val_loss=0.1837 scale=1.0000 norm=3.0428\n",
      "[iter 98] loss=0.1696 val_loss=0.1835 scale=0.5000 norm=1.5336\n",
      "[iter 99] loss=0.1695 val_loss=0.1834 scale=0.5000 norm=1.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 9 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5737 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5228 val_loss=1.5375 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=1.4874 val_loss=1.5067 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=1.4573 val_loss=1.4778 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=1.4295 val_loss=1.4522 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=1.4046 val_loss=1.4281 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=1.3813 val_loss=1.4058 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=1.3597 val_loss=1.3846 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=1.3391 val_loss=1.3648 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=1.3197 val_loss=1.3456 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=1.3010 val_loss=1.3093 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=1.2656 val_loss=1.2921 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=1.2487 val_loss=1.2583 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=1.2153 val_loss=1.2271 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=1.1843 val_loss=1.1972 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=1.1544 val_loss=1.1678 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=1.1252 val_loss=1.1396 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=1.0972 val_loss=1.1118 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=1.0696 val_loss=1.0847 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=1.0424 val_loss=1.0584 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=1.0159 val_loss=1.0326 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=0.9899 val_loss=1.0076 scale=2.0000 norm=1.3123\n",
      "[iter 22] loss=0.9646 val_loss=0.9832 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=0.9395 val_loss=0.9585 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=0.9145 val_loss=0.9347 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=0.8902 val_loss=0.9112 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=0.8663 val_loss=0.8882 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=0.8429 val_loss=0.8658 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=0.8197 val_loss=0.8437 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=0.7969 val_loss=0.8216 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=0.7743 val_loss=0.8002 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=0.7523 val_loss=0.7790 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=0.7306 val_loss=0.7582 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=0.7093 val_loss=0.7377 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=0.6881 val_loss=0.7178 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=0.6675 val_loss=0.6981 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=0.6472 val_loss=0.6788 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=0.6272 val_loss=0.6598 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=0.6076 val_loss=0.6414 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=0.5884 val_loss=0.6234 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=0.5697 val_loss=0.6059 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=0.5515 val_loss=0.5888 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=0.5336 val_loss=0.5720 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=0.5161 val_loss=0.5558 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=0.4990 val_loss=0.5399 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=0.4824 val_loss=0.5243 scale=2.0000 norm=1.0687\n",
      "[iter 46] loss=0.4660 val_loss=0.5093 scale=2.0000 norm=1.0657\n",
      "[iter 47] loss=0.4502 val_loss=0.4947 scale=2.0000 norm=1.0631\n",
      "[iter 48] loss=0.4347 val_loss=0.4805 scale=2.0000 norm=1.0606\n",
      "[iter 49] loss=0.4198 val_loss=0.4667 scale=2.0000 norm=1.0584\n",
      "[iter 50] loss=0.4051 val_loss=0.4532 scale=2.0000 norm=1.0565\n",
      "[iter 51] loss=0.3908 val_loss=0.4401 scale=2.0000 norm=1.0548\n",
      "[iter 52] loss=0.3770 val_loss=0.4277 scale=2.0000 norm=1.0533\n",
      "[iter 53] loss=0.3635 val_loss=0.4157 scale=2.0000 norm=1.0518\n",
      "[iter 54] loss=0.3505 val_loss=0.4038 scale=2.0000 norm=1.0508\n",
      "[iter 55] loss=0.3378 val_loss=0.3924 scale=2.0000 norm=1.0498\n",
      "[iter 56] loss=0.3255 val_loss=0.3814 scale=2.0000 norm=1.0491\n",
      "[iter 57] loss=0.3136 val_loss=0.3707 scale=2.0000 norm=1.0486\n",
      "[iter 58] loss=0.3023 val_loss=0.3604 scale=2.0000 norm=1.0483\n",
      "[iter 59] loss=0.2912 val_loss=0.3507 scale=2.0000 norm=1.0481\n",
      "[iter 60] loss=0.2805 val_loss=0.3411 scale=2.0000 norm=1.0482\n",
      "[iter 61] loss=0.2702 val_loss=0.3319 scale=2.0000 norm=1.0484\n",
      "[iter 62] loss=0.2602 val_loss=0.3231 scale=2.0000 norm=1.0487\n",
      "[iter 63] loss=0.2507 val_loss=0.3145 scale=2.0000 norm=1.0492\n",
      "[iter 64] loss=0.2414 val_loss=0.3061 scale=2.0000 norm=1.0499\n",
      "[iter 65] loss=0.2325 val_loss=0.2979 scale=2.0000 norm=1.0507\n",
      "[iter 66] loss=0.2238 val_loss=0.2902 scale=2.0000 norm=1.0515\n",
      "[iter 67] loss=0.2155 val_loss=0.2826 scale=2.0000 norm=1.0524\n",
      "[iter 68] loss=0.2075 val_loss=0.2759 scale=2.0000 norm=1.0534\n",
      "[iter 69] loss=0.2000 val_loss=0.2691 scale=2.0000 norm=1.0548\n",
      "[iter 70] loss=0.1927 val_loss=0.2632 scale=2.0000 norm=1.0562\n",
      "[iter 71] loss=0.1857 val_loss=0.2571 scale=2.0000 norm=1.0577\n",
      "[iter 72] loss=0.1790 val_loss=0.2513 scale=2.0000 norm=1.0593\n",
      "[iter 73] loss=0.1725 val_loss=0.2458 scale=2.0000 norm=1.0609\n",
      "[iter 74] loss=0.1664 val_loss=0.2406 scale=2.0000 norm=1.0626\n",
      "[iter 75] loss=0.1605 val_loss=0.2356 scale=2.0000 norm=1.0644\n",
      "[iter 76] loss=0.1549 val_loss=0.2304 scale=2.0000 norm=1.0665\n",
      "[iter 77] loss=0.1495 val_loss=0.2262 scale=2.0000 norm=1.0684\n",
      "[iter 78] loss=0.1445 val_loss=0.2221 scale=2.0000 norm=1.0704\n",
      "[iter 79] loss=0.1396 val_loss=0.2179 scale=2.0000 norm=1.0724\n",
      "[iter 80] loss=0.1349 val_loss=0.2141 scale=2.0000 norm=1.0744\n",
      "[iter 81] loss=0.1303 val_loss=0.2106 scale=2.0000 norm=1.0764\n",
      "[iter 82] loss=0.1261 val_loss=0.2069 scale=2.0000 norm=1.0786\n",
      "[iter 83] loss=0.1220 val_loss=0.2040 scale=2.0000 norm=1.0806\n",
      "[iter 84] loss=0.1182 val_loss=0.2011 scale=2.0000 norm=1.0827\n",
      "[iter 85] loss=0.1146 val_loss=0.1979 scale=2.0000 norm=1.0849\n",
      "[iter 86] loss=0.1111 val_loss=0.1952 scale=2.0000 norm=1.0869\n",
      "[iter 87] loss=0.1078 val_loss=0.1926 scale=2.0000 norm=1.0891\n",
      "[iter 88] loss=0.1047 val_loss=0.1900 scale=2.0000 norm=1.0913\n",
      "[iter 89] loss=0.1016 val_loss=0.1880 scale=2.0000 norm=1.0934\n",
      "[iter 90] loss=0.0987 val_loss=0.1859 scale=2.0000 norm=1.0956\n",
      "[iter 91] loss=0.0960 val_loss=0.1840 scale=2.0000 norm=1.0978\n",
      "[iter 92] loss=0.0935 val_loss=0.1827 scale=2.0000 norm=1.1000\n",
      "[iter 93] loss=0.0910 val_loss=0.1809 scale=2.0000 norm=1.1020\n",
      "[iter 94] loss=0.0887 val_loss=0.1790 scale=2.0000 norm=1.1041\n",
      "[iter 95] loss=0.0864 val_loss=0.1774 scale=2.0000 norm=1.1062\n",
      "[iter 96] loss=0.0843 val_loss=0.1761 scale=2.0000 norm=1.1084\n",
      "[iter 97] loss=0.0824 val_loss=0.1751 scale=2.0000 norm=1.1104\n",
      "[iter 98] loss=0.0806 val_loss=0.1737 scale=2.0000 norm=1.1124\n",
      "[iter 99] loss=0.0787 val_loss=0.1724 scale=2.0000 norm=1.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 10 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2398 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2366 scale=1.0000 norm=1.5728\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6117\n",
      "[iter 55] loss=0.2148 val_loss=0.2306 scale=1.0000 norm=1.6521\n",
      "[iter 56] loss=0.2121 val_loss=0.2279 scale=1.0000 norm=1.6938\n",
      "[iter 57] loss=0.2095 val_loss=0.2252 scale=1.0000 norm=1.7368\n",
      "[iter 58] loss=0.2071 val_loss=0.2226 scale=1.0000 norm=1.7815\n",
      "[iter 59] loss=0.2048 val_loss=0.2202 scale=1.0000 norm=1.8280\n",
      "[iter 60] loss=0.2025 val_loss=0.2179 scale=1.0000 norm=1.8747\n",
      "[iter 61] loss=0.2005 val_loss=0.2157 scale=1.0000 norm=1.9225\n",
      "[iter 62] loss=0.1985 val_loss=0.2136 scale=1.0000 norm=1.9715\n",
      "[iter 63] loss=0.1966 val_loss=0.2116 scale=1.0000 norm=2.0201\n",
      "[iter 64] loss=0.1948 val_loss=0.2097 scale=1.0000 norm=2.0695\n",
      "[iter 65] loss=0.1931 val_loss=0.2079 scale=1.0000 norm=2.1185\n",
      "[iter 66] loss=0.1915 val_loss=0.2061 scale=1.0000 norm=2.1670\n",
      "[iter 67] loss=0.1899 val_loss=0.2045 scale=1.0000 norm=2.2159\n",
      "[iter 68] loss=0.1885 val_loss=0.2029 scale=1.0000 norm=2.2634\n",
      "[iter 69] loss=0.1871 val_loss=0.2015 scale=1.0000 norm=2.3105\n",
      "[iter 70] loss=0.1858 val_loss=0.2000 scale=1.0000 norm=2.3566\n",
      "[iter 71] loss=0.1845 val_loss=0.1986 scale=1.0000 norm=2.4010\n",
      "[iter 72] loss=0.1833 val_loss=0.1972 scale=1.0000 norm=2.4445\n",
      "[iter 73] loss=0.1822 val_loss=0.1961 scale=1.0000 norm=2.4863\n",
      "[iter 74] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5263\n",
      "[iter 75] loss=0.1801 val_loss=0.1939 scale=1.0000 norm=2.5651\n",
      "[iter 76] loss=0.1791 val_loss=0.1934 scale=0.5000 norm=1.3018\n",
      "[iter 77] loss=0.1786 val_loss=0.1928 scale=0.5000 norm=1.3107\n",
      "[iter 78] loss=0.1781 val_loss=0.1919 scale=1.0000 norm=2.6394\n",
      "[iter 79] loss=0.1773 val_loss=0.1914 scale=0.5000 norm=1.3388\n",
      "[iter 80] loss=0.1768 val_loss=0.1904 scale=1.0000 norm=2.6951\n",
      "[iter 81] loss=0.1760 val_loss=0.1899 scale=0.5000 norm=1.3646\n",
      "[iter 82] loss=0.1756 val_loss=0.1895 scale=0.5000 norm=1.3732\n",
      "[iter 83] loss=0.1752 val_loss=0.1887 scale=1.0000 norm=2.7620\n",
      "[iter 84] loss=0.1745 val_loss=0.1884 scale=0.5000 norm=1.3976\n",
      "[iter 85] loss=0.1742 val_loss=0.1880 scale=0.5000 norm=1.4048\n",
      "[iter 86] loss=0.1738 val_loss=0.1877 scale=0.5000 norm=1.4127\n",
      "[iter 87] loss=0.1735 val_loss=0.1873 scale=0.5000 norm=1.4203\n",
      "[iter 88] loss=0.1732 val_loss=0.1870 scale=0.5000 norm=1.4272\n",
      "[iter 89] loss=0.1729 val_loss=0.1866 scale=0.5000 norm=1.4342\n",
      "[iter 90] loss=0.1726 val_loss=0.1863 scale=0.5000 norm=1.4411\n",
      "[iter 91] loss=0.1723 val_loss=0.1860 scale=0.5000 norm=1.4474\n",
      "[iter 92] loss=0.1720 val_loss=0.1857 scale=0.5000 norm=1.4536\n",
      "[iter 93] loss=0.1717 val_loss=0.1851 scale=1.0000 norm=2.9208\n",
      "[iter 94] loss=0.1711 val_loss=0.1849 scale=0.5000 norm=1.4734\n",
      "[iter 95] loss=0.1709 val_loss=0.1847 scale=0.5000 norm=1.4792\n",
      "[iter 96] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=2.9721\n",
      "[iter 97] loss=0.1701 val_loss=0.1840 scale=0.5000 norm=1.4982\n",
      "[iter 98] loss=0.1699 val_loss=0.1838 scale=0.5000 norm=1.5045\n",
      "[iter 99] loss=0.1697 val_loss=0.1836 scale=0.5000 norm=1.5113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 11 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5737 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5228 val_loss=1.5375 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=1.4874 val_loss=1.5067 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=1.4573 val_loss=1.4778 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=1.4295 val_loss=1.4522 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=1.4046 val_loss=1.4281 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=1.3813 val_loss=1.4058 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=1.3597 val_loss=1.3846 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=1.3391 val_loss=1.3648 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=1.3197 val_loss=1.3456 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=1.3010 val_loss=1.3093 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=1.2656 val_loss=1.2921 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=1.2487 val_loss=1.2583 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=1.2153 val_loss=1.2271 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=1.1843 val_loss=1.1972 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=1.1544 val_loss=1.1678 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=1.1252 val_loss=1.1396 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=1.0972 val_loss=1.1118 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=1.0696 val_loss=1.0847 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=1.0424 val_loss=1.0584 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=1.0159 val_loss=1.0326 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=0.9899 val_loss=1.0076 scale=2.0000 norm=1.3123\n",
      "[iter 22] loss=0.9646 val_loss=0.9832 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=0.9395 val_loss=0.9585 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=0.9145 val_loss=0.9347 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=0.8902 val_loss=0.9112 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=0.8663 val_loss=0.8882 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=0.8429 val_loss=0.8658 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=0.8197 val_loss=0.8437 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=0.7969 val_loss=0.8216 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=0.7743 val_loss=0.8002 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=0.7523 val_loss=0.7790 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=0.7306 val_loss=0.7582 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=0.7093 val_loss=0.7377 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=0.6881 val_loss=0.7178 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=0.6675 val_loss=0.6981 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=0.6472 val_loss=0.6788 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=0.6272 val_loss=0.6598 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=0.6076 val_loss=0.6414 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=0.5884 val_loss=0.6234 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=0.5697 val_loss=0.6059 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=0.5515 val_loss=0.5888 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=0.5336 val_loss=0.5720 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=0.5161 val_loss=0.5557 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=0.4990 val_loss=0.5399 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=0.4823 val_loss=0.5243 scale=2.0000 norm=1.0686\n",
      "[iter 46] loss=0.4659 val_loss=0.5093 scale=2.0000 norm=1.0656\n",
      "[iter 47] loss=0.4500 val_loss=0.4947 scale=2.0000 norm=1.0629\n",
      "[iter 48] loss=0.4345 val_loss=0.4804 scale=2.0000 norm=1.0604\n",
      "[iter 49] loss=0.4194 val_loss=0.4666 scale=2.0000 norm=1.0582\n",
      "[iter 50] loss=0.4047 val_loss=0.4529 scale=2.0000 norm=1.0562\n",
      "[iter 51] loss=0.3904 val_loss=0.4401 scale=2.0000 norm=1.0543\n",
      "[iter 52] loss=0.3764 val_loss=0.4274 scale=2.0000 norm=1.0526\n",
      "[iter 53] loss=0.3629 val_loss=0.4150 scale=2.0000 norm=1.0513\n",
      "[iter 54] loss=0.3497 val_loss=0.4033 scale=2.0000 norm=1.0501\n",
      "[iter 55] loss=0.3370 val_loss=0.3917 scale=2.0000 norm=1.0490\n",
      "[iter 56] loss=0.3247 val_loss=0.3807 scale=2.0000 norm=1.0482\n",
      "[iter 57] loss=0.3127 val_loss=0.3698 scale=2.0000 norm=1.0477\n",
      "[iter 58] loss=0.3011 val_loss=0.3595 scale=2.0000 norm=1.0471\n",
      "[iter 59] loss=0.2899 val_loss=0.3493 scale=2.0000 norm=1.0469\n",
      "[iter 60] loss=0.2790 val_loss=0.3395 scale=2.0000 norm=1.0467\n",
      "[iter 61] loss=0.2685 val_loss=0.3302 scale=2.0000 norm=1.0468\n",
      "[iter 62] loss=0.2584 val_loss=0.3211 scale=2.0000 norm=1.0470\n",
      "[iter 63] loss=0.2486 val_loss=0.3126 scale=2.0000 norm=1.0474\n",
      "[iter 64] loss=0.2393 val_loss=0.3044 scale=2.0000 norm=1.0481\n",
      "[iter 65] loss=0.2302 val_loss=0.2966 scale=2.0000 norm=1.0487\n",
      "[iter 66] loss=0.2216 val_loss=0.2887 scale=2.0000 norm=1.0496\n",
      "[iter 67] loss=0.2132 val_loss=0.2812 scale=2.0000 norm=1.0503\n",
      "[iter 68] loss=0.2051 val_loss=0.2740 scale=2.0000 norm=1.0512\n",
      "[iter 69] loss=0.1974 val_loss=0.2674 scale=2.0000 norm=1.0525\n",
      "[iter 70] loss=0.1899 val_loss=0.2605 scale=2.0000 norm=1.0537\n",
      "[iter 71] loss=0.1828 val_loss=0.2544 scale=2.0000 norm=1.0550\n",
      "[iter 72] loss=0.1759 val_loss=0.2485 scale=2.0000 norm=1.0563\n",
      "[iter 73] loss=0.1694 val_loss=0.2430 scale=2.0000 norm=1.0579\n",
      "[iter 74] loss=0.1631 val_loss=0.2378 scale=2.0000 norm=1.0595\n",
      "[iter 75] loss=0.1571 val_loss=0.2333 scale=2.0000 norm=1.0612\n",
      "[iter 76] loss=0.1514 val_loss=0.2282 scale=2.0000 norm=1.0629\n",
      "[iter 77] loss=0.1459 val_loss=0.2232 scale=2.0000 norm=1.0648\n",
      "[iter 78] loss=0.1406 val_loss=0.2192 scale=2.0000 norm=1.0667\n",
      "[iter 79] loss=0.1357 val_loss=0.2153 scale=2.0000 norm=1.0687\n",
      "[iter 80] loss=0.1310 val_loss=0.2106 scale=2.0000 norm=1.0707\n",
      "[iter 81] loss=0.1262 val_loss=0.2072 scale=2.0000 norm=1.0727\n",
      "[iter 82] loss=0.1219 val_loss=0.2041 scale=2.0000 norm=1.0748\n",
      "[iter 83] loss=0.1179 val_loss=0.2008 scale=2.0000 norm=1.0769\n",
      "[iter 84] loss=0.1139 val_loss=0.1979 scale=2.0000 norm=1.0790\n",
      "[iter 85] loss=0.1103 val_loss=0.1950 scale=2.0000 norm=1.0812\n",
      "[iter 86] loss=0.1068 val_loss=0.1921 scale=2.0000 norm=1.0834\n",
      "[iter 87] loss=0.1034 val_loss=0.1895 scale=2.0000 norm=1.0856\n",
      "[iter 88] loss=0.1002 val_loss=0.1867 scale=2.0000 norm=1.0878\n",
      "[iter 89] loss=0.0970 val_loss=0.1844 scale=2.0000 norm=1.0897\n",
      "[iter 90] loss=0.0940 val_loss=0.1828 scale=2.0000 norm=1.0919\n",
      "[iter 91] loss=0.0913 val_loss=0.1809 scale=2.0000 norm=1.0939\n",
      "[iter 92] loss=0.0887 val_loss=0.1793 scale=2.0000 norm=1.0962\n",
      "[iter 93] loss=0.0862 val_loss=0.1776 scale=2.0000 norm=1.0983\n",
      "[iter 94] loss=0.0839 val_loss=0.1761 scale=2.0000 norm=1.1005\n",
      "[iter 95] loss=0.0817 val_loss=0.1737 scale=2.0000 norm=1.1025\n",
      "[iter 96] loss=0.0792 val_loss=0.1726 scale=2.0000 norm=1.1044\n",
      "[iter 97] loss=0.0773 val_loss=0.1713 scale=2.0000 norm=1.1064\n",
      "[iter 98] loss=0.0753 val_loss=0.1707 scale=2.0000 norm=1.1084\n",
      "[iter 99] loss=0.0735 val_loss=0.1695 scale=2.0000 norm=1.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 12 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6806 scale=2.0000 norm=2.2332\n",
      "[iter 1] loss=0.6374 val_loss=0.6721 scale=2.0000 norm=2.2169\n",
      "[iter 2] loss=0.6306 val_loss=0.6645 scale=2.0000 norm=2.2040\n",
      "[iter 3] loss=0.6245 val_loss=0.6577 scale=2.0000 norm=2.1939\n",
      "[iter 4] loss=0.6189 val_loss=0.6515 scale=2.0000 norm=2.1860\n",
      "[iter 5] loss=0.6139 val_loss=0.6459 scale=2.0000 norm=2.1802\n",
      "[iter 6] loss=0.6094 val_loss=0.6409 scale=2.0000 norm=2.1761\n",
      "[iter 7] loss=0.6052 val_loss=0.6363 scale=2.0000 norm=2.1736\n",
      "[iter 8] loss=0.6015 val_loss=0.6321 scale=2.0000 norm=2.1724\n",
      "[iter 9] loss=0.5981 val_loss=0.6283 scale=2.0000 norm=2.1723\n",
      "[iter 10] loss=0.5950 val_loss=0.6248 scale=2.0000 norm=2.1732\n",
      "[iter 11] loss=0.5922 val_loss=0.6218 scale=2.0000 norm=2.1750\n",
      "[iter 12] loss=0.5896 val_loss=0.6189 scale=2.0000 norm=2.1776\n",
      "[iter 13] loss=0.5872 val_loss=0.6163 scale=2.0000 norm=2.1807\n",
      "[iter 14] loss=0.5851 val_loss=0.6139 scale=2.0000 norm=2.1844\n",
      "[iter 15] loss=0.5831 val_loss=0.6118 scale=2.0000 norm=2.1885\n",
      "[iter 16] loss=0.5813 val_loss=0.6097 scale=2.0000 norm=2.1931\n",
      "[iter 17] loss=0.5797 val_loss=0.6079 scale=2.0000 norm=2.1980\n",
      "[iter 18] loss=0.5782 val_loss=0.6062 scale=2.0000 norm=2.2032\n",
      "[iter 19] loss=0.5768 val_loss=0.6047 scale=2.0000 norm=2.2087\n",
      "[iter 20] loss=0.5755 val_loss=0.6033 scale=2.0000 norm=2.2142\n",
      "[iter 21] loss=0.5743 val_loss=0.6019 scale=2.0000 norm=2.2200\n",
      "[iter 22] loss=0.5732 val_loss=0.6008 scale=2.0000 norm=2.2258\n",
      "[iter 23] loss=0.5722 val_loss=0.5997 scale=2.0000 norm=2.2318\n",
      "[iter 24] loss=0.5713 val_loss=0.5988 scale=2.0000 norm=2.2379\n",
      "[iter 25] loss=0.5705 val_loss=0.5978 scale=2.0000 norm=2.2440\n",
      "[iter 26] loss=0.5697 val_loss=0.5970 scale=2.0000 norm=2.2502\n",
      "[iter 27] loss=0.5690 val_loss=0.5963 scale=2.0000 norm=2.2563\n",
      "[iter 28] loss=0.5683 val_loss=0.5956 scale=2.0000 norm=2.2625\n",
      "[iter 29] loss=0.5677 val_loss=0.5949 scale=2.0000 norm=2.2686\n",
      "[iter 30] loss=0.5671 val_loss=0.5943 scale=2.0000 norm=2.2747\n",
      "[iter 31] loss=0.5666 val_loss=0.5938 scale=2.0000 norm=2.2806\n",
      "[iter 32] loss=0.5661 val_loss=0.5933 scale=2.0000 norm=2.2867\n",
      "[iter 33] loss=0.5656 val_loss=0.5930 scale=1.0000 norm=1.1462\n",
      "[iter 34] loss=0.5654 val_loss=0.5927 scale=2.0000 norm=2.2954\n",
      "[iter 35] loss=0.5650 val_loss=0.5925 scale=1.0000 norm=1.1506\n",
      "[iter 36] loss=0.5648 val_loss=0.5921 scale=2.0000 norm=2.3041\n",
      "[iter 37] loss=0.5644 val_loss=0.5917 scale=2.0000 norm=2.3096\n",
      "[iter 38] loss=0.5641 val_loss=0.5913 scale=2.0000 norm=2.3152\n",
      "[iter 39] loss=0.5637 val_loss=0.5911 scale=2.0000 norm=2.3206\n",
      "[iter 40] loss=0.5635 val_loss=0.5909 scale=2.0000 norm=2.3259\n",
      "[iter 41] loss=0.5632 val_loss=0.5906 scale=2.0000 norm=2.3310\n",
      "[iter 42] loss=0.5630 val_loss=0.5905 scale=1.0000 norm=1.1681\n",
      "[iter 43] loss=0.5628 val_loss=0.5903 scale=2.0000 norm=2.3386\n",
      "[iter 44] loss=0.5626 val_loss=0.5902 scale=1.0000 norm=1.1717\n",
      "[iter 45] loss=0.5625 val_loss=0.5900 scale=2.0000 norm=2.3458\n",
      "[iter 46] loss=0.5623 val_loss=0.5899 scale=1.0000 norm=1.1752\n",
      "[iter 47] loss=0.5622 val_loss=0.5897 scale=2.0000 norm=2.3527\n",
      "[iter 48] loss=0.5620 val_loss=0.5897 scale=1.0000 norm=1.1786\n",
      "[iter 49] loss=0.5620 val_loss=0.5895 scale=2.0000 norm=2.3593\n",
      "[iter 50] loss=0.5618 val_loss=0.5895 scale=1.0000 norm=1.1818\n",
      "[iter 51] loss=0.5617 val_loss=0.5893 scale=2.0000 norm=2.3656\n",
      "[iter 52] loss=0.5616 val_loss=0.5893 scale=1.0000 norm=1.1848\n",
      "[iter 53] loss=0.5615 val_loss=0.5892 scale=1.0000 norm=1.1858\n",
      "[iter 54] loss=0.5615 val_loss=0.5891 scale=1.0000 norm=1.1867\n",
      "[iter 55] loss=0.5614 val_loss=0.5890 scale=2.0000 norm=2.3753\n",
      "[iter 56] loss=0.5613 val_loss=0.5889 scale=1.0000 norm=1.1895\n",
      "[iter 57] loss=0.5612 val_loss=0.5889 scale=1.0000 norm=1.1904\n",
      "[iter 58] loss=0.5612 val_loss=0.5888 scale=2.0000 norm=2.3825\n",
      "[iter 59] loss=0.5610 val_loss=0.5888 scale=1.0000 norm=1.1929\n",
      "[iter 60] loss=0.5610 val_loss=0.5887 scale=1.0000 norm=1.1937\n",
      "[iter 61] loss=0.5609 val_loss=0.5886 scale=2.0000 norm=2.3890\n",
      "[iter 62] loss=0.5608 val_loss=0.5886 scale=1.0000 norm=1.1960\n",
      "[iter 63] loss=0.5608 val_loss=0.5885 scale=2.0000 norm=2.3936\n",
      "[iter 64] loss=0.5607 val_loss=0.5885 scale=2.0000 norm=2.3964\n",
      "[iter 65] loss=0.5606 val_loss=0.5884 scale=1.0000 norm=1.1996\n",
      "[iter 66] loss=0.5606 val_loss=0.5883 scale=2.0000 norm=2.4005\n",
      "[iter 67] loss=0.5605 val_loss=0.5883 scale=1.0000 norm=1.2016\n",
      "[iter 68] loss=0.5604 val_loss=0.5883 scale=2.0000 norm=2.4044\n",
      "[iter 69] loss=0.5604 val_loss=0.5883 scale=2.0000 norm=2.4067\n",
      "[iter 70] loss=0.5603 val_loss=0.5883 scale=2.0000 norm=2.4089\n",
      "[iter 71] loss=0.5602 val_loss=0.5883 scale=1.0000 norm=1.2056\n",
      "[iter 72] loss=0.5602 val_loss=0.5883 scale=1.0000 norm=1.2061\n",
      "[iter 73] loss=0.5602 val_loss=0.5883 scale=2.0000 norm=2.4131\n",
      "[iter 74] loss=0.5601 val_loss=0.5883 scale=1.0000 norm=1.2075\n",
      "[iter 75] loss=0.5601 val_loss=0.5883 scale=1.0000 norm=1.2080\n",
      "[iter 76] loss=0.5600 val_loss=0.5883 scale=1.0000 norm=1.2085\n",
      "[iter 77] loss=0.5600 val_loss=0.5883 scale=2.0000 norm=2.4178\n",
      "[iter 78] loss=0.5600 val_loss=0.5883 scale=1.0000 norm=1.2097\n",
      "[iter 79] loss=0.5599 val_loss=0.5882 scale=2.0000 norm=2.4202\n",
      "[iter 80] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2109\n",
      "[iter 81] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2113\n",
      "[iter 82] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2116\n",
      "[iter 83] loss=0.5598 val_loss=0.5883 scale=2.0000 norm=2.4240\n",
      "[iter 84] loss=0.5598 val_loss=0.5883 scale=1.0000 norm=1.2127\n",
      "[iter 85] loss=0.5598 val_loss=0.5883 scale=2.0000 norm=2.4261\n",
      "[iter 86] loss=0.5597 val_loss=0.5882 scale=1.0000 norm=1.2137\n",
      "[iter 87] loss=0.5597 val_loss=0.5883 scale=2.0000 norm=2.4279\n",
      "[iter 88] loss=0.5597 val_loss=0.5883 scale=1.0000 norm=1.2145\n",
      "[iter 89] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2148\n",
      "[iter 90] loss=0.5596 val_loss=0.5883 scale=2.0000 norm=2.4302\n",
      "[iter 91] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2156\n",
      "[iter 92] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2158\n",
      "[iter 93] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2161\n",
      "[iter 94] loss=0.5596 val_loss=0.5883 scale=2.0000 norm=2.4327\n",
      "[iter 95] loss=0.5595 val_loss=0.5884 scale=2.0000 norm=2.4337\n",
      "[iter 96] loss=0.5595 val_loss=0.5883 scale=2.0000 norm=2.4346\n",
      "[iter 97] loss=0.5595 val_loss=0.5883 scale=1.0000 norm=1.2178\n",
      "[iter 98] loss=0.5595 val_loss=0.5883 scale=1.0000 norm=1.2179\n",
      "[iter 99] loss=0.5594 val_loss=0.5883 scale=1.0000 norm=1.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 13 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.6072 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5577 val_loss=1.5997 scale=1.0000 norm=1.1022\n",
      "[iter 2] loss=1.5508 val_loss=1.5927 scale=1.0000 norm=1.0951\n",
      "[iter 3] loss=1.5444 val_loss=1.5862 scale=1.0000 norm=1.0886\n",
      "[iter 4] loss=1.5385 val_loss=1.5801 scale=1.0000 norm=1.0825\n",
      "[iter 5] loss=1.5329 val_loss=1.5743 scale=1.0000 norm=1.0769\n",
      "[iter 6] loss=1.5277 val_loss=1.5689 scale=1.0000 norm=1.0716\n",
      "[iter 7] loss=1.5228 val_loss=1.5638 scale=1.0000 norm=1.0668\n",
      "[iter 8] loss=1.5181 val_loss=1.5590 scale=1.0000 norm=1.0622\n",
      "[iter 9] loss=1.5137 val_loss=1.5545 scale=1.0000 norm=1.0579\n",
      "[iter 10] loss=1.5095 val_loss=1.5501 scale=1.0000 norm=1.0539\n",
      "[iter 11] loss=1.5056 val_loss=1.5459 scale=1.0000 norm=1.0501\n",
      "[iter 12] loss=1.5019 val_loss=1.5419 scale=1.0000 norm=1.0466\n",
      "[iter 13] loss=1.4984 val_loss=1.5382 scale=1.0000 norm=1.0434\n",
      "[iter 14] loss=1.4950 val_loss=1.5347 scale=1.0000 norm=1.0403\n",
      "[iter 15] loss=1.4918 val_loss=1.5313 scale=1.0000 norm=1.0375\n",
      "[iter 16] loss=1.4888 val_loss=1.5281 scale=1.0000 norm=1.0348\n",
      "[iter 17] loss=1.4859 val_loss=1.5251 scale=1.0000 norm=1.0323\n",
      "[iter 18] loss=1.4831 val_loss=1.5222 scale=1.0000 norm=1.0299\n",
      "[iter 19] loss=1.4805 val_loss=1.5194 scale=1.0000 norm=1.0277\n",
      "[iter 20] loss=1.4779 val_loss=1.5168 scale=1.0000 norm=1.0256\n",
      "[iter 21] loss=1.4755 val_loss=1.5142 scale=1.0000 norm=1.0237\n",
      "[iter 22] loss=1.4732 val_loss=1.5118 scale=1.0000 norm=1.0218\n",
      "[iter 23] loss=1.4710 val_loss=1.5096 scale=1.0000 norm=1.0202\n",
      "[iter 24] loss=1.4688 val_loss=1.5074 scale=1.0000 norm=1.0186\n",
      "[iter 25] loss=1.4668 val_loss=1.5053 scale=1.0000 norm=1.0171\n",
      "[iter 26] loss=1.4648 val_loss=1.5033 scale=1.0000 norm=1.0157\n",
      "[iter 27] loss=1.4630 val_loss=1.4995 scale=2.0000 norm=2.0288\n",
      "[iter 28] loss=1.4594 val_loss=1.4978 scale=1.0000 norm=1.0121\n",
      "[iter 29] loss=1.4578 val_loss=1.4944 scale=2.0000 norm=2.0221\n",
      "[iter 30] loss=1.4546 val_loss=1.4914 scale=2.0000 norm=2.0182\n",
      "[iter 31] loss=1.4517 val_loss=1.4888 scale=2.0000 norm=2.0149\n",
      "[iter 32] loss=1.4490 val_loss=1.4862 scale=2.0000 norm=2.0121\n",
      "[iter 33] loss=1.4465 val_loss=1.4838 scale=2.0000 norm=2.0096\n",
      "[iter 34] loss=1.4440 val_loss=1.4816 scale=2.0000 norm=2.0073\n",
      "[iter 35] loss=1.4419 val_loss=1.4796 scale=2.0000 norm=2.0056\n",
      "[iter 36] loss=1.4398 val_loss=1.4779 scale=2.0000 norm=2.0039\n",
      "[iter 37] loss=1.4380 val_loss=1.4761 scale=2.0000 norm=2.0027\n",
      "[iter 38] loss=1.4362 val_loss=1.4748 scale=2.0000 norm=2.0017\n",
      "[iter 39] loss=1.4346 val_loss=1.4734 scale=2.0000 norm=2.0009\n",
      "[iter 40] loss=1.4330 val_loss=1.4722 scale=2.0000 norm=2.0000\n",
      "[iter 41] loss=1.4316 val_loss=1.4712 scale=2.0000 norm=1.9995\n",
      "[iter 42] loss=1.4303 val_loss=1.4702 scale=2.0000 norm=1.9993\n",
      "[iter 43] loss=1.4291 val_loss=1.4694 scale=2.0000 norm=1.9990\n",
      "[iter 44] loss=1.4279 val_loss=1.4686 scale=2.0000 norm=1.9988\n",
      "[iter 45] loss=1.4269 val_loss=1.4678 scale=2.0000 norm=1.9989\n",
      "[iter 46] loss=1.4259 val_loss=1.4671 scale=2.0000 norm=1.9988\n",
      "[iter 47] loss=1.4249 val_loss=1.4665 scale=2.0000 norm=1.9988\n",
      "[iter 48] loss=1.4241 val_loss=1.4661 scale=2.0000 norm=1.9989\n",
      "[iter 49] loss=1.4233 val_loss=1.4656 scale=2.0000 norm=1.9992\n",
      "[iter 50] loss=1.4226 val_loss=1.4653 scale=2.0000 norm=1.9994\n",
      "[iter 51] loss=1.4219 val_loss=1.4650 scale=2.0000 norm=1.9997\n",
      "[iter 52] loss=1.4212 val_loss=1.4648 scale=2.0000 norm=1.9999\n",
      "[iter 53] loss=1.4206 val_loss=1.4645 scale=2.0000 norm=2.0003\n",
      "[iter 54] loss=1.4200 val_loss=1.4643 scale=2.0000 norm=2.0006\n",
      "[iter 55] loss=1.4195 val_loss=1.4641 scale=2.0000 norm=2.0010\n",
      "[iter 56] loss=1.4190 val_loss=1.4640 scale=2.0000 norm=2.0014\n",
      "[iter 57] loss=1.4185 val_loss=1.4639 scale=2.0000 norm=2.0017\n",
      "[iter 58] loss=1.4181 val_loss=1.4639 scale=2.0000 norm=2.0021\n",
      "[iter 59] loss=1.4176 val_loss=1.4638 scale=2.0000 norm=2.0024\n",
      "[iter 60] loss=1.4172 val_loss=1.4638 scale=2.0000 norm=2.0028\n",
      "[iter 61] loss=1.4169 val_loss=1.4639 scale=2.0000 norm=2.0032\n",
      "[iter 62] loss=1.4165 val_loss=1.4639 scale=2.0000 norm=2.0036\n",
      "[iter 63] loss=1.4162 val_loss=1.4639 scale=2.0000 norm=2.0039\n",
      "[iter 64] loss=1.4159 val_loss=1.4641 scale=2.0000 norm=2.0043\n",
      "[iter 65] loss=1.4156 val_loss=1.4641 scale=1.0000 norm=1.0024\n",
      "[iter 66] loss=1.4155 val_loss=1.4642 scale=2.0000 norm=2.0049\n",
      "[iter 67] loss=1.4152 val_loss=1.4642 scale=2.0000 norm=2.0053\n",
      "[iter 68] loss=1.4150 val_loss=1.4643 scale=2.0000 norm=2.0056\n",
      "[iter 69] loss=1.4147 val_loss=1.4645 scale=2.0000 norm=2.0059\n",
      "[iter 70] loss=1.4145 val_loss=1.4647 scale=2.0000 norm=2.0063\n",
      "[iter 71] loss=1.4143 val_loss=1.4648 scale=2.0000 norm=2.0066\n",
      "[iter 72] loss=1.4141 val_loss=1.4648 scale=1.0000 norm=1.0034\n",
      "[iter 73] loss=1.4140 val_loss=1.4650 scale=1.0000 norm=1.0035\n",
      "[iter 74] loss=1.4139 val_loss=1.4650 scale=1.0000 norm=1.0036\n",
      "[iter 75] loss=1.4138 val_loss=1.4653 scale=2.0000 norm=2.0073\n",
      "[iter 76] loss=1.4136 val_loss=1.4654 scale=2.0000 norm=2.0076\n",
      "[iter 77] loss=1.4135 val_loss=1.4657 scale=2.0000 norm=2.0079\n",
      "[iter 78] loss=1.4133 val_loss=1.4659 scale=2.0000 norm=2.0081\n",
      "[iter 79] loss=1.4132 val_loss=1.4661 scale=2.0000 norm=2.0084\n",
      "[iter 80] loss=1.4131 val_loss=1.4665 scale=2.0000 norm=2.0087\n",
      "[iter 81] loss=1.4129 val_loss=1.4666 scale=2.0000 norm=2.0089\n",
      "[iter 82] loss=1.4128 val_loss=1.4669 scale=2.0000 norm=2.0092\n",
      "[iter 83] loss=1.4127 val_loss=1.4671 scale=2.0000 norm=2.0094\n",
      "[iter 84] loss=1.4126 val_loss=1.4673 scale=2.0000 norm=2.0096\n",
      "[iter 85] loss=1.4125 val_loss=1.4677 scale=2.0000 norm=2.0098\n",
      "[iter 86] loss=1.4124 val_loss=1.4679 scale=2.0000 norm=2.0100\n",
      "[iter 87] loss=1.4123 val_loss=1.4683 scale=2.0000 norm=2.0102\n",
      "[iter 88] loss=1.4122 val_loss=1.4686 scale=2.0000 norm=2.0103\n",
      "[iter 89] loss=1.4120 val_loss=1.4688 scale=2.0000 norm=2.0104\n",
      "[iter 90] loss=1.4119 val_loss=1.4692 scale=2.0000 norm=2.0105\n",
      "[iter 91] loss=1.4118 val_loss=1.4693 scale=1.0000 norm=1.0054\n",
      "[iter 92] loss=1.4118 val_loss=1.4697 scale=2.0000 norm=2.0107\n",
      "[iter 93] loss=1.4117 val_loss=1.4698 scale=2.0000 norm=2.0108\n",
      "[iter 94] loss=1.4116 val_loss=1.4700 scale=2.0000 norm=2.0109\n",
      "[iter 95] loss=1.4115 val_loss=1.4703 scale=2.0000 norm=2.0110\n",
      "[iter 96] loss=1.4114 val_loss=1.4707 scale=2.0000 norm=2.0111\n",
      "[iter 97] loss=1.4114 val_loss=1.4708 scale=1.0000 norm=1.0056\n",
      "[iter 98] loss=1.4113 val_loss=1.4710 scale=2.0000 norm=2.0111\n",
      "[iter 99] loss=1.4112 val_loss=1.4711 scale=1.0000 norm=1.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 14 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0960\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5835 val_loss=0.6084 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5814 scale=1.0000 norm=1.0242\n",
      "[iter 7] loss=0.5450 val_loss=0.5689 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5334 val_loss=0.5569 scale=1.0000 norm=1.0063\n",
      "[iter 9] loss=0.5222 val_loss=0.5455 scale=1.0000 norm=0.9993\n",
      "[iter 10] loss=0.5116 val_loss=0.5346 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5014 val_loss=0.5242 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4917 val_loss=0.5142 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4823 val_loss=0.5045 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4733 val_loss=0.4953 scale=1.0000 norm=0.9789\n",
      "[iter 15] loss=0.4647 val_loss=0.4864 scale=1.0000 norm=0.9775\n",
      "[iter 16] loss=0.4564 val_loss=0.4779 scale=1.0000 norm=0.9768\n",
      "[iter 17] loss=0.4483 val_loss=0.4698 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4406 val_loss=0.4619 scale=1.0000 norm=0.9778\n",
      "[iter 19] loss=0.4332 val_loss=0.4543 scale=1.0000 norm=0.9794\n",
      "[iter 20] loss=0.4260 val_loss=0.4469 scale=1.0000 norm=0.9816\n",
      "[iter 21] loss=0.4191 val_loss=0.4399 scale=1.0000 norm=0.9845\n",
      "[iter 22] loss=0.4125 val_loss=0.4330 scale=1.0000 norm=0.9880\n",
      "[iter 23] loss=0.4060 val_loss=0.4265 scale=1.0000 norm=0.9922\n",
      "[iter 24] loss=0.3998 val_loss=0.4201 scale=1.0000 norm=0.9970\n",
      "[iter 25] loss=0.3938 val_loss=0.4140 scale=1.0000 norm=1.0024\n",
      "[iter 26] loss=0.3880 val_loss=0.4081 scale=1.0000 norm=1.0084\n",
      "[iter 27] loss=0.3825 val_loss=0.4023 scale=1.0000 norm=1.0149\n",
      "[iter 28] loss=0.3771 val_loss=0.3968 scale=1.0000 norm=1.0220\n",
      "[iter 29] loss=0.3718 val_loss=0.3914 scale=1.0000 norm=1.0297\n",
      "[iter 30] loss=0.3668 val_loss=0.3863 scale=1.0000 norm=1.0380\n",
      "[iter 31] loss=0.3619 val_loss=0.3813 scale=1.0000 norm=1.0468\n",
      "[iter 32] loss=0.3573 val_loss=0.3765 scale=1.0000 norm=1.0562\n",
      "[iter 33] loss=0.3527 val_loss=0.3719 scale=1.0000 norm=1.0661\n",
      "[iter 34] loss=0.3484 val_loss=0.3674 scale=1.0000 norm=1.0766\n",
      "[iter 35] loss=0.3442 val_loss=0.3630 scale=1.0000 norm=1.0877\n",
      "[iter 36] loss=0.3401 val_loss=0.3589 scale=1.0000 norm=1.0992\n",
      "[iter 37] loss=0.3362 val_loss=0.3548 scale=1.0000 norm=1.1113\n",
      "[iter 38] loss=0.3324 val_loss=0.3509 scale=1.0000 norm=1.1238\n",
      "[iter 39] loss=0.3288 val_loss=0.3472 scale=1.0000 norm=1.1370\n",
      "[iter 40] loss=0.3253 val_loss=0.3436 scale=1.0000 norm=1.1506\n",
      "[iter 41] loss=0.3219 val_loss=0.3401 scale=1.0000 norm=1.1648\n",
      "[iter 42] loss=0.3187 val_loss=0.3368 scale=1.0000 norm=1.1795\n",
      "[iter 43] loss=0.3156 val_loss=0.3336 scale=1.0000 norm=1.1946\n",
      "[iter 44] loss=0.3126 val_loss=0.3305 scale=1.0000 norm=1.2102\n",
      "[iter 45] loss=0.3097 val_loss=0.3275 scale=1.0000 norm=1.2264\n",
      "[iter 46] loss=0.3070 val_loss=0.3246 scale=1.0000 norm=1.2431\n",
      "[iter 47] loss=0.3043 val_loss=0.3218 scale=1.0000 norm=1.2603\n",
      "[iter 48] loss=0.3018 val_loss=0.3191 scale=1.0000 norm=1.2778\n",
      "[iter 49] loss=0.2994 val_loss=0.3166 scale=1.0000 norm=1.2958\n",
      "[iter 50] loss=0.2970 val_loss=0.3141 scale=1.0000 norm=1.3143\n",
      "[iter 51] loss=0.2948 val_loss=0.3118 scale=1.0000 norm=1.3332\n",
      "[iter 52] loss=0.2927 val_loss=0.3096 scale=1.0000 norm=1.3526\n",
      "[iter 53] loss=0.2906 val_loss=0.3074 scale=1.0000 norm=1.3723\n",
      "[iter 54] loss=0.2887 val_loss=0.3054 scale=1.0000 norm=1.3925\n",
      "[iter 55] loss=0.2868 val_loss=0.3034 scale=1.0000 norm=1.4129\n",
      "[iter 56] loss=0.2850 val_loss=0.3015 scale=1.0000 norm=1.4336\n",
      "[iter 57] loss=0.2833 val_loss=0.2997 scale=1.0000 norm=1.4546\n",
      "[iter 58] loss=0.2817 val_loss=0.2981 scale=1.0000 norm=1.4759\n",
      "[iter 59] loss=0.2801 val_loss=0.2964 scale=1.0000 norm=1.4973\n",
      "[iter 60] loss=0.2786 val_loss=0.2949 scale=1.0000 norm=1.5191\n",
      "[iter 61] loss=0.2772 val_loss=0.2934 scale=1.0000 norm=1.5410\n",
      "[iter 62] loss=0.2759 val_loss=0.2920 scale=1.0000 norm=1.5630\n",
      "[iter 63] loss=0.2746 val_loss=0.2907 scale=1.0000 norm=1.5851\n",
      "[iter 64] loss=0.2733 val_loss=0.2895 scale=1.0000 norm=1.6073\n",
      "[iter 65] loss=0.2722 val_loss=0.2883 scale=1.0000 norm=1.6297\n",
      "[iter 66] loss=0.2711 val_loss=0.2871 scale=1.0000 norm=1.6521\n",
      "[iter 67] loss=0.2700 val_loss=0.2861 scale=1.0000 norm=1.6747\n",
      "[iter 68] loss=0.2690 val_loss=0.2851 scale=1.0000 norm=1.6972\n",
      "[iter 69] loss=0.2681 val_loss=0.2841 scale=1.0000 norm=1.7197\n",
      "[iter 70] loss=0.2672 val_loss=0.2832 scale=1.0000 norm=1.7420\n",
      "[iter 71] loss=0.2664 val_loss=0.2823 scale=1.0000 norm=1.7645\n",
      "[iter 72] loss=0.2656 val_loss=0.2815 scale=1.0000 norm=1.7865\n",
      "[iter 73] loss=0.2648 val_loss=0.2808 scale=1.0000 norm=1.8088\n",
      "[iter 74] loss=0.2641 val_loss=0.2801 scale=1.0000 norm=1.8311\n",
      "[iter 75] loss=0.2634 val_loss=0.2794 scale=1.0000 norm=1.8530\n",
      "[iter 76] loss=0.2628 val_loss=0.2787 scale=1.0000 norm=1.8744\n",
      "[iter 77] loss=0.2621 val_loss=0.2781 scale=1.0000 norm=1.8955\n",
      "[iter 78] loss=0.2615 val_loss=0.2776 scale=1.0000 norm=1.9166\n",
      "[iter 79] loss=0.2610 val_loss=0.2770 scale=1.0000 norm=1.9365\n",
      "[iter 80] loss=0.2604 val_loss=0.2765 scale=1.0000 norm=1.9567\n",
      "[iter 81] loss=0.2599 val_loss=0.2760 scale=1.0000 norm=1.9760\n",
      "[iter 82] loss=0.2595 val_loss=0.2756 scale=1.0000 norm=1.9956\n",
      "[iter 83] loss=0.2590 val_loss=0.2751 scale=1.0000 norm=2.0143\n",
      "[iter 84] loss=0.2586 val_loss=0.2747 scale=1.0000 norm=2.0327\n",
      "[iter 85] loss=0.2582 val_loss=0.2743 scale=1.0000 norm=2.0514\n",
      "[iter 86] loss=0.2578 val_loss=0.2741 scale=0.5000 norm=1.0347\n",
      "[iter 87] loss=0.2576 val_loss=0.2738 scale=1.0000 norm=2.0781\n",
      "[iter 88] loss=0.2573 val_loss=0.2735 scale=1.0000 norm=2.0957\n",
      "[iter 89] loss=0.2570 val_loss=0.2732 scale=1.0000 norm=2.1127\n",
      "[iter 90] loss=0.2567 val_loss=0.2731 scale=0.5000 norm=1.0637\n",
      "[iter 91] loss=0.2566 val_loss=0.2729 scale=1.0000 norm=2.1355\n",
      "[iter 92] loss=0.2563 val_loss=0.2728 scale=0.5000 norm=1.0756\n",
      "[iter 93] loss=0.2562 val_loss=0.2727 scale=0.5000 norm=1.0795\n",
      "[iter 94] loss=0.2561 val_loss=0.2725 scale=1.0000 norm=2.1665\n",
      "[iter 95] loss=0.2559 val_loss=0.2724 scale=0.5000 norm=1.0909\n",
      "[iter 96] loss=0.2558 val_loss=0.2723 scale=1.0000 norm=2.1901\n",
      "[iter 97] loss=0.2556 val_loss=0.2722 scale=1.0000 norm=2.2045\n",
      "[iter 98] loss=0.2554 val_loss=0.2721 scale=0.5000 norm=1.1093\n",
      "[iter 99] loss=0.2553 val_loss=0.2721 scale=0.5000 norm=1.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 16 Excel files, but found 15 files. Skipping the merge step.\n",
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=1.5650 val_loss=1.5774 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=1.5271 val_loss=1.5447 scale=1.0000 norm=1.0745\n",
      "[iter 2] loss=1.4948 val_loss=1.5157 scale=1.0000 norm=1.0443\n",
      "[iter 3] loss=1.4665 val_loss=1.4896 scale=1.0000 norm=1.0178\n",
      "[iter 4] loss=1.4409 val_loss=1.4425 scale=2.0000 norm=1.9878\n",
      "[iter 5] loss=1.3953 val_loss=1.4024 scale=2.0000 norm=1.9023\n",
      "[iter 6] loss=1.3559 val_loss=1.3665 scale=2.0000 norm=1.8293\n",
      "[iter 7] loss=1.3208 val_loss=1.3334 scale=2.0000 norm=1.7655\n",
      "[iter 8] loss=1.2887 val_loss=1.3033 scale=2.0000 norm=1.7090\n",
      "[iter 9] loss=1.2590 val_loss=1.2748 scale=2.0000 norm=1.6589\n",
      "[iter 10] loss=1.2309 val_loss=1.2482 scale=2.0000 norm=1.6139\n",
      "[iter 11] loss=1.2044 val_loss=1.2230 scale=2.0000 norm=1.5735\n",
      "[iter 12] loss=1.1792 val_loss=1.1986 scale=2.0000 norm=1.5373\n",
      "[iter 13] loss=1.1550 val_loss=1.1753 scale=2.0000 norm=1.5048\n",
      "[iter 14] loss=1.1318 val_loss=1.1529 scale=2.0000 norm=1.4755\n",
      "[iter 15] loss=1.1093 val_loss=1.1314 scale=2.0000 norm=1.4490\n",
      "[iter 16] loss=1.0876 val_loss=1.1106 scale=2.0000 norm=1.4253\n",
      "[iter 17] loss=1.0666 val_loss=1.0905 scale=2.0000 norm=1.4041\n",
      "[iter 18] loss=1.0463 val_loss=1.0710 scale=2.0000 norm=1.3850\n",
      "[iter 19] loss=1.0265 val_loss=1.0521 scale=2.0000 norm=1.3679\n",
      "[iter 20] loss=1.0074 val_loss=1.0338 scale=2.0000 norm=1.3525\n",
      "[iter 21] loss=0.9888 val_loss=1.0161 scale=2.0000 norm=1.3388\n",
      "[iter 22] loss=0.9707 val_loss=0.9989 scale=2.0000 norm=1.3265\n",
      "[iter 23] loss=0.9532 val_loss=0.9822 scale=2.0000 norm=1.3155\n",
      "[iter 24] loss=0.9361 val_loss=0.9661 scale=2.0000 norm=1.3057\n",
      "[iter 25] loss=0.9196 val_loss=0.9503 scale=2.0000 norm=1.2971\n",
      "[iter 26] loss=0.9035 val_loss=0.9351 scale=2.0000 norm=1.2893\n",
      "[iter 27] loss=0.8879 val_loss=0.9203 scale=2.0000 norm=1.2825\n",
      "[iter 28] loss=0.8727 val_loss=0.9059 scale=2.0000 norm=1.2764\n",
      "[iter 29] loss=0.8580 val_loss=0.8920 scale=2.0000 norm=1.2711\n",
      "[iter 30] loss=0.8437 val_loss=0.8785 scale=2.0000 norm=1.2664\n",
      "[iter 31] loss=0.8299 val_loss=0.8655 scale=2.0000 norm=1.2623\n",
      "[iter 32] loss=0.8166 val_loss=0.8528 scale=2.0000 norm=1.2589\n",
      "[iter 33] loss=0.8036 val_loss=0.8406 scale=2.0000 norm=1.2559\n",
      "[iter 34] loss=0.7910 val_loss=0.8288 scale=2.0000 norm=1.2533\n",
      "[iter 35] loss=0.7789 val_loss=0.8173 scale=2.0000 norm=1.2513\n",
      "[iter 36] loss=0.7671 val_loss=0.8062 scale=2.0000 norm=1.2495\n",
      "[iter 37] loss=0.7557 val_loss=0.7956 scale=2.0000 norm=1.2481\n",
      "[iter 38] loss=0.7448 val_loss=0.7853 scale=2.0000 norm=1.2471\n",
      "[iter 39] loss=0.7342 val_loss=0.7753 scale=2.0000 norm=1.2463\n",
      "[iter 40] loss=0.7239 val_loss=0.7656 scale=2.0000 norm=1.2458\n",
      "[iter 41] loss=0.7140 val_loss=0.7564 scale=2.0000 norm=1.2455\n",
      "[iter 42] loss=0.7044 val_loss=0.7474 scale=2.0000 norm=1.2454\n",
      "[iter 43] loss=0.6952 val_loss=0.7387 scale=2.0000 norm=1.2456\n",
      "[iter 44] loss=0.6863 val_loss=0.7304 scale=2.0000 norm=1.2458\n",
      "[iter 45] loss=0.6778 val_loss=0.7223 scale=2.0000 norm=1.2463\n",
      "[iter 46] loss=0.6695 val_loss=0.7147 scale=2.0000 norm=1.2470\n",
      "[iter 47] loss=0.6616 val_loss=0.7073 scale=2.0000 norm=1.2477\n",
      "[iter 48] loss=0.6539 val_loss=0.7003 scale=2.0000 norm=1.2487\n",
      "[iter 49] loss=0.6466 val_loss=0.6936 scale=2.0000 norm=1.2497\n",
      "[iter 50] loss=0.6395 val_loss=0.6869 scale=2.0000 norm=1.2509\n",
      "[iter 51] loss=0.6327 val_loss=0.6806 scale=2.0000 norm=1.2521\n",
      "[iter 52] loss=0.6262 val_loss=0.6745 scale=2.0000 norm=1.2534\n",
      "[iter 53] loss=0.6199 val_loss=0.6687 scale=2.0000 norm=1.2549\n",
      "[iter 54] loss=0.6138 val_loss=0.6632 scale=2.0000 norm=1.2563\n",
      "[iter 55] loss=0.6081 val_loss=0.6579 scale=2.0000 norm=1.2579\n",
      "[iter 56] loss=0.6025 val_loss=0.6528 scale=2.0000 norm=1.2595\n",
      "[iter 57] loss=0.5972 val_loss=0.6479 scale=2.0000 norm=1.2612\n",
      "[iter 58] loss=0.5921 val_loss=0.6433 scale=2.0000 norm=1.2629\n",
      "[iter 59] loss=0.5872 val_loss=0.6389 scale=2.0000 norm=1.2647\n",
      "[iter 60] loss=0.5825 val_loss=0.6346 scale=2.0000 norm=1.2665\n",
      "[iter 61] loss=0.5780 val_loss=0.6306 scale=2.0000 norm=1.2683\n",
      "[iter 62] loss=0.5738 val_loss=0.6266 scale=2.0000 norm=1.2702\n",
      "[iter 63] loss=0.5696 val_loss=0.6229 scale=2.0000 norm=1.2720\n",
      "[iter 64] loss=0.5657 val_loss=0.6196 scale=2.0000 norm=1.2739\n",
      "[iter 65] loss=0.5620 val_loss=0.6163 scale=2.0000 norm=1.2757\n",
      "[iter 66] loss=0.5584 val_loss=0.6132 scale=2.0000 norm=1.2777\n",
      "[iter 67] loss=0.5550 val_loss=0.6102 scale=2.0000 norm=1.2795\n",
      "[iter 68] loss=0.5518 val_loss=0.6074 scale=2.0000 norm=1.2815\n",
      "[iter 69] loss=0.5487 val_loss=0.6047 scale=2.0000 norm=1.2833\n",
      "[iter 70] loss=0.5458 val_loss=0.6022 scale=2.0000 norm=1.2851\n",
      "[iter 71] loss=0.5429 val_loss=0.6000 scale=2.0000 norm=1.2870\n",
      "[iter 72] loss=0.5402 val_loss=0.5978 scale=2.0000 norm=1.2888\n",
      "[iter 73] loss=0.5377 val_loss=0.5958 scale=2.0000 norm=1.2906\n",
      "[iter 74] loss=0.5353 val_loss=0.5940 scale=2.0000 norm=1.2925\n",
      "[iter 75] loss=0.5330 val_loss=0.5925 scale=2.0000 norm=1.2941\n",
      "[iter 76] loss=0.5308 val_loss=0.5909 scale=2.0000 norm=1.2958\n",
      "[iter 77] loss=0.5288 val_loss=0.5894 scale=2.0000 norm=1.2975\n",
      "[iter 78] loss=0.5269 val_loss=0.5882 scale=2.0000 norm=1.2993\n",
      "[iter 79] loss=0.5250 val_loss=0.5869 scale=2.0000 norm=1.3009\n",
      "[iter 80] loss=0.5233 val_loss=0.5858 scale=2.0000 norm=1.3027\n",
      "[iter 81] loss=0.5216 val_loss=0.5847 scale=2.0000 norm=1.3043\n",
      "[iter 82] loss=0.5200 val_loss=0.5839 scale=2.0000 norm=1.3061\n",
      "[iter 83] loss=0.5186 val_loss=0.5831 scale=2.0000 norm=1.3076\n",
      "[iter 84] loss=0.5172 val_loss=0.5824 scale=2.0000 norm=1.3092\n",
      "[iter 85] loss=0.5159 val_loss=0.5818 scale=2.0000 norm=1.3107\n",
      "[iter 86] loss=0.5147 val_loss=0.5813 scale=2.0000 norm=1.3123\n",
      "[iter 87] loss=0.5135 val_loss=0.5806 scale=2.0000 norm=1.3137\n",
      "[iter 88] loss=0.5123 val_loss=0.5800 scale=2.0000 norm=1.3152\n",
      "[iter 89] loss=0.5112 val_loss=0.5796 scale=2.0000 norm=1.3167\n",
      "[iter 90] loss=0.5102 val_loss=0.5791 scale=2.0000 norm=1.3182\n",
      "[iter 91] loss=0.5092 val_loss=0.5787 scale=2.0000 norm=1.3197\n",
      "[iter 92] loss=0.5084 val_loss=0.5784 scale=2.0000 norm=1.3212\n",
      "[iter 93] loss=0.5075 val_loss=0.5781 scale=2.0000 norm=1.3225\n",
      "[iter 94] loss=0.5066 val_loss=0.5780 scale=2.0000 norm=1.3237\n",
      "[iter 95] loss=0.5059 val_loss=0.5780 scale=1.0000 norm=0.6624\n",
      "[iter 96] loss=0.5056 val_loss=0.5777 scale=2.0000 norm=1.3254\n",
      "[iter 97] loss=0.5049 val_loss=0.5775 scale=2.0000 norm=1.3267\n",
      "[iter 98] loss=0.5042 val_loss=0.5773 scale=2.0000 norm=1.3279\n",
      "[iter 99] loss=0.5036 val_loss=0.5774 scale=1.0000 norm=0.6645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed! The final file is 'Merged_Sheet.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,17):\n",
    "    entsoe = load_entsoe()\n",
    "    results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=i, dist=Normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\ngboost\\distns\\lognormal.py:124: RuntimeWarning: invalid value encountered in log\n",
      "  m, s = sp.stats.norm.fit(np.log(Y))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The data contains non-finite values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12240\\3438102754.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mentsoe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_entsoe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mresults_per_time_interval_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_summary_stats_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_per_row_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparameters_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_ngboost_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentsoe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12240\\2075205226.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(entsoe, target_column, dist, case, n_estimators, learning_rate, random_state, output_file)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mDist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# Split validation data into 96 intervals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mX_validation_sub_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\ngboost\\ngboost.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         return self.partial_fit(\n\u001b[0m\u001b[0;32m    255\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\ngboost\\ngboost.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mloss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_init_params_to_marginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\ngboost\\ngboost.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, Y, sample_weight, iters)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_init_params_to_marginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         self.init_params = self.Manifold.fit(\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;33m)\u001b[0m  \u001b[1;31m# would be best to put sample weights here too\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\ngboost\\distns\\lognormal.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(Y)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;31m# data is an instance of CensoredData, but actually holds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;31m# no censored values, so replace it with the array of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m# uncensored values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uncensored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Minu\\Documents\\master-thesis\\.venv\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, **kwds)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The data contains non-finite values.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfloc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The data contains non-finite values."
     ]
    }
   ],
   "source": [
    "for i in range(1, 17):\n",
    "    entsoe = load_entsoe()\n",
    "    results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6806 scale=2.0000 norm=2.2332\n",
      "[iter 1] loss=0.6375 val_loss=0.6722 scale=2.0000 norm=2.2170\n",
      "[iter 2] loss=0.6307 val_loss=0.6647 scale=2.0000 norm=2.2042\n",
      "[iter 3] loss=0.6246 val_loss=0.6579 scale=2.0000 norm=2.1944\n",
      "[iter 4] loss=0.6192 val_loss=0.6519 scale=2.0000 norm=2.1869\n",
      "[iter 5] loss=0.6143 val_loss=0.6464 scale=2.0000 norm=2.1814\n",
      "[iter 6] loss=0.6099 val_loss=0.6415 scale=2.0000 norm=2.1775\n",
      "[iter 7] loss=0.6059 val_loss=0.6370 scale=2.0000 norm=2.1751\n",
      "[iter 8] loss=0.6022 val_loss=0.6330 scale=2.0000 norm=2.1740\n",
      "[iter 9] loss=0.5989 val_loss=0.6293 scale=2.0000 norm=2.1739\n",
      "[iter 10] loss=0.5959 val_loss=0.6259 scale=2.0000 norm=2.1747\n",
      "[iter 11] loss=0.5932 val_loss=0.6228 scale=2.0000 norm=2.1763\n",
      "[iter 12] loss=0.5907 val_loss=0.6200 scale=2.0000 norm=2.1787\n",
      "[iter 13] loss=0.5884 val_loss=0.6175 scale=2.0000 norm=2.1816\n",
      "[iter 14] loss=0.5863 val_loss=0.6152 scale=2.0000 norm=2.1851\n",
      "[iter 15] loss=0.5844 val_loss=0.6131 scale=2.0000 norm=2.1890\n",
      "[iter 16] loss=0.5826 val_loss=0.6112 scale=2.0000 norm=2.1933\n",
      "[iter 17] loss=0.5811 val_loss=0.6094 scale=2.0000 norm=2.1980\n",
      "[iter 18] loss=0.5796 val_loss=0.6078 scale=2.0000 norm=2.2029\n",
      "[iter 19] loss=0.5783 val_loss=0.6063 scale=2.0000 norm=2.2081\n",
      "[iter 20] loss=0.5771 val_loss=0.6050 scale=2.0000 norm=2.2135\n",
      "[iter 21] loss=0.5759 val_loss=0.6038 scale=2.0000 norm=2.2190\n",
      "[iter 22] loss=0.5749 val_loss=0.6027 scale=2.0000 norm=2.2247\n",
      "[iter 23] loss=0.5740 val_loss=0.6017 scale=2.0000 norm=2.2305\n",
      "[iter 24] loss=0.5731 val_loss=0.6008 scale=2.0000 norm=2.2363\n",
      "[iter 25] loss=0.5724 val_loss=0.5999 scale=2.0000 norm=2.2422\n",
      "[iter 26] loss=0.5717 val_loss=0.5992 scale=2.0000 norm=2.2482\n",
      "[iter 27] loss=0.5710 val_loss=0.5985 scale=2.0000 norm=2.2541\n",
      "[iter 28] loss=0.5704 val_loss=0.5979 scale=2.0000 norm=2.2601\n",
      "[iter 29] loss=0.5699 val_loss=0.5974 scale=2.0000 norm=2.2660\n",
      "[iter 30] loss=0.5694 val_loss=0.5969 scale=2.0000 norm=2.2720\n",
      "[iter 31] loss=0.5690 val_loss=0.5964 scale=2.0000 norm=2.2778\n",
      "[iter 32] loss=0.5686 val_loss=0.5960 scale=2.0000 norm=2.2836\n",
      "[iter 33] loss=0.5682 val_loss=0.5957 scale=2.0000 norm=2.2894\n",
      "[iter 34] loss=0.5679 val_loss=0.5953 scale=2.0000 norm=2.2951\n",
      "[iter 35] loss=0.5676 val_loss=0.5951 scale=2.0000 norm=2.3007\n",
      "[iter 36] loss=0.5673 val_loss=0.5948 scale=2.0000 norm=2.3061\n",
      "[iter 37] loss=0.5671 val_loss=0.5947 scale=1.0000 norm=1.1558\n",
      "[iter 38] loss=0.5670 val_loss=0.5945 scale=2.0000 norm=2.3141\n",
      "[iter 39] loss=0.5667 val_loss=0.5944 scale=1.0000 norm=1.1597\n",
      "[iter 40] loss=0.5667 val_loss=0.5943 scale=1.0000 norm=1.1610\n",
      "[iter 41] loss=0.5666 val_loss=0.5942 scale=1.0000 norm=1.1622\n",
      "[iter 42] loss=0.5665 val_loss=0.5941 scale=1.0000 norm=1.1634\n",
      "[iter 43] loss=0.5664 val_loss=0.5940 scale=1.0000 norm=1.1647\n",
      "[iter 44] loss=0.5663 val_loss=0.5940 scale=1.0000 norm=1.1659\n",
      "[iter 45] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1671\n",
      "[iter 46] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1682\n",
      "[iter 47] loss=0.5661 val_loss=0.5939 scale=1.0000 norm=1.1694\n",
      "[iter 48] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1705\n",
      "[iter 49] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1717\n",
      "[iter 50] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1728\n",
      "[iter 51] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1739\n",
      "[iter 52] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1749\n",
      "[iter 53] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1760\n",
      "[iter 54] loss=0.5657 val_loss=0.5937 scale=1.0000 norm=1.1770\n",
      "[iter 55] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1780\n",
      "[iter 56] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1790\n",
      "[iter 57] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1800\n",
      "[iter 58] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1810\n",
      "[iter 59] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1819\n",
      "[iter 60] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1828\n",
      "[iter 61] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1837\n",
      "[iter 62] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1846\n",
      "[iter 63] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1855\n",
      "[iter 64] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1863\n",
      "[iter 65] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1872\n",
      "[iter 66] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1880\n",
      "[iter 67] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1888\n",
      "[iter 68] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1896\n",
      "[iter 69] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1903\n",
      "[iter 70] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1911\n",
      "[iter 71] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1918\n",
      "[iter 72] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1925\n",
      "[iter 73] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1932\n",
      "[iter 74] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1939\n",
      "[iter 75] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1945\n",
      "[iter 76] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1952\n",
      "[iter 77] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1958\n",
      "[iter 78] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1964\n",
      "[iter 79] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1970\n",
      "[iter 80] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1976\n",
      "[iter 81] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1982\n",
      "[iter 82] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1987\n",
      "[iter 83] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1993\n",
      "[iter 84] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.1998\n",
      "[iter 85] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2003\n",
      "[iter 86] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2008\n",
      "[iter 87] loss=0.5651 val_loss=0.5940 scale=1.0000 norm=1.2013\n",
      "[iter 88] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2017\n",
      "[iter 89] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2022\n",
      "[iter 90] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2026\n",
      "[iter 91] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2031\n",
      "[iter 92] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2035\n",
      "[iter 93] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2039\n",
      "[iter 94] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2043\n",
      "[iter 95] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2047\n",
      "[iter 96] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2050\n",
      "[iter 97] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2054\n",
      "[iter 98] loss=0.5650 val_loss=0.5942 scale=2.0000 norm=2.4115\n",
      "[iter 99] loss=0.5650 val_loss=0.5942 scale=1.0000 norm=1.2065\n",
      "Expected 12 Excel files, but found 1 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.2717 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.4931 val_loss=-0.2789 scale=1.0000 norm=1.1025\n",
      "[iter 2] loss=-0.4995 val_loss=-0.2856 scale=1.0000 norm=1.0957\n",
      "[iter 3] loss=-0.5054 val_loss=-0.2918 scale=1.0000 norm=1.0895\n",
      "[iter 4] loss=-0.5109 val_loss=-0.2976 scale=1.0000 norm=1.0837\n",
      "[iter 5] loss=-0.5161 val_loss=-0.3031 scale=1.0000 norm=1.0783\n",
      "[iter 6] loss=-0.5209 val_loss=-0.3082 scale=1.0000 norm=1.0733\n",
      "[iter 7] loss=-0.5255 val_loss=-0.3130 scale=1.0000 norm=1.0686\n",
      "[iter 8] loss=-0.5297 val_loss=-0.3175 scale=1.0000 norm=1.0642\n",
      "[iter 9] loss=-0.5338 val_loss=-0.3217 scale=1.0000 norm=1.0602\n",
      "[iter 10] loss=-0.5376 val_loss=-0.3258 scale=1.0000 norm=1.0563\n",
      "[iter 11] loss=-0.5413 val_loss=-0.3296 scale=1.0000 norm=1.0527\n",
      "[iter 12] loss=-0.5447 val_loss=-0.3332 scale=1.0000 norm=1.0493\n",
      "[iter 13] loss=-0.5480 val_loss=-0.3366 scale=1.0000 norm=1.0462\n",
      "[iter 14] loss=-0.5511 val_loss=-0.3431 scale=2.0000 norm=2.0866\n",
      "[iter 15] loss=-0.5570 val_loss=-0.3489 scale=2.0000 norm=2.0757\n",
      "[iter 16] loss=-0.5622 val_loss=-0.3542 scale=2.0000 norm=2.0663\n",
      "[iter 17] loss=-0.5670 val_loss=-0.3590 scale=2.0000 norm=2.0581\n",
      "[iter 18] loss=-0.5714 val_loss=-0.3634 scale=2.0000 norm=2.0510\n",
      "[iter 19] loss=-0.5754 val_loss=-0.3674 scale=2.0000 norm=2.0448\n",
      "[iter 20] loss=-0.5790 val_loss=-0.3709 scale=2.0000 norm=2.0394\n",
      "[iter 21] loss=-0.5824 val_loss=-0.3742 scale=2.0000 norm=2.0347\n",
      "[iter 22] loss=-0.5855 val_loss=-0.3772 scale=2.0000 norm=2.0307\n",
      "[iter 23] loss=-0.5883 val_loss=-0.3799 scale=2.0000 norm=2.0272\n",
      "[iter 24] loss=-0.5909 val_loss=-0.3824 scale=2.0000 norm=2.0243\n",
      "[iter 25] loss=-0.5933 val_loss=-0.3847 scale=2.0000 norm=2.0218\n",
      "[iter 26] loss=-0.5955 val_loss=-0.3868 scale=2.0000 norm=2.0197\n",
      "[iter 27] loss=-0.5976 val_loss=-0.3887 scale=2.0000 norm=2.0180\n",
      "[iter 28] loss=-0.5995 val_loss=-0.3904 scale=2.0000 norm=2.0166\n",
      "[iter 29] loss=-0.6012 val_loss=-0.3919 scale=2.0000 norm=2.0154\n",
      "[iter 30] loss=-0.6028 val_loss=-0.3933 scale=2.0000 norm=2.0145\n",
      "[iter 31] loss=-0.6043 val_loss=-0.3946 scale=2.0000 norm=2.0138\n",
      "[iter 32] loss=-0.6056 val_loss=-0.3957 scale=2.0000 norm=2.0133\n",
      "[iter 33] loss=-0.6069 val_loss=-0.3968 scale=2.0000 norm=2.0130\n",
      "[iter 34] loss=-0.6080 val_loss=-0.3976 scale=2.0000 norm=2.0128\n",
      "[iter 35] loss=-0.6091 val_loss=-0.3985 scale=2.0000 norm=2.0127\n",
      "[iter 36] loss=-0.6101 val_loss=-0.3991 scale=2.0000 norm=2.0127\n",
      "[iter 37] loss=-0.6110 val_loss=-0.3997 scale=2.0000 norm=2.0129\n",
      "[iter 38] loss=-0.6118 val_loss=-0.4002 scale=2.0000 norm=2.0131\n",
      "[iter 39] loss=-0.6126 val_loss=-0.4007 scale=2.0000 norm=2.0134\n",
      "[iter 40] loss=-0.6133 val_loss=-0.4010 scale=2.0000 norm=2.0137\n",
      "[iter 41] loss=-0.6139 val_loss=-0.4013 scale=2.0000 norm=2.0141\n",
      "[iter 42] loss=-0.6145 val_loss=-0.4015 scale=2.0000 norm=2.0145\n",
      "[iter 43] loss=-0.6151 val_loss=-0.4017 scale=2.0000 norm=2.0150\n",
      "[iter 44] loss=-0.6156 val_loss=-0.4018 scale=2.0000 norm=2.0155\n",
      "[iter 45] loss=-0.6160 val_loss=-0.4019 scale=2.0000 norm=2.0160\n",
      "[iter 46] loss=-0.6164 val_loss=-0.4019 scale=2.0000 norm=2.0165\n",
      "[iter 47] loss=-0.6168 val_loss=-0.4020 scale=2.0000 norm=2.0171\n",
      "[iter 48] loss=-0.6172 val_loss=-0.4019 scale=2.0000 norm=2.0176\n",
      "[iter 49] loss=-0.6175 val_loss=-0.4018 scale=2.0000 norm=2.0182\n",
      "[iter 50] loss=-0.6178 val_loss=-0.4018 scale=2.0000 norm=2.0187\n",
      "[iter 51] loss=-0.6181 val_loss=-0.4018 scale=2.0000 norm=2.0193\n",
      "[iter 52] loss=-0.6183 val_loss=-0.4017 scale=2.0000 norm=2.0198\n",
      "[iter 53] loss=-0.6186 val_loss=-0.4015 scale=2.0000 norm=2.0203\n",
      "[iter 54] loss=-0.6188 val_loss=-0.4014 scale=2.0000 norm=2.0208\n",
      "[iter 55] loss=-0.6190 val_loss=-0.4011 scale=2.0000 norm=2.0213\n",
      "[iter 56] loss=-0.6192 val_loss=-0.4010 scale=2.0000 norm=2.0218\n",
      "[iter 57] loss=-0.6193 val_loss=-0.4008 scale=2.0000 norm=2.0222\n",
      "[iter 58] loss=-0.6195 val_loss=-0.4006 scale=2.0000 norm=2.0226\n",
      "[iter 59] loss=-0.6197 val_loss=-0.4004 scale=2.0000 norm=2.0231\n",
      "[iter 60] loss=-0.6198 val_loss=-0.4001 scale=2.0000 norm=2.0235\n",
      "[iter 61] loss=-0.6199 val_loss=-0.3999 scale=2.0000 norm=2.0239\n",
      "[iter 62] loss=-0.6200 val_loss=-0.3996 scale=2.0000 norm=2.0243\n",
      "[iter 63] loss=-0.6202 val_loss=-0.3994 scale=2.0000 norm=2.0247\n",
      "[iter 64] loss=-0.6203 val_loss=-0.3991 scale=2.0000 norm=2.0250\n",
      "[iter 65] loss=-0.6203 val_loss=-0.3988 scale=2.0000 norm=2.0254\n",
      "[iter 66] loss=-0.6204 val_loss=-0.3986 scale=2.0000 norm=2.0257\n",
      "[iter 67] loss=-0.6205 val_loss=-0.3983 scale=2.0000 norm=2.0260\n",
      "[iter 68] loss=-0.6206 val_loss=-0.3980 scale=2.0000 norm=2.0263\n",
      "[iter 69] loss=-0.6207 val_loss=-0.3977 scale=2.0000 norm=2.0266\n",
      "[iter 70] loss=-0.6207 val_loss=-0.3974 scale=2.0000 norm=2.0269\n",
      "[iter 71] loss=-0.6208 val_loss=-0.3972 scale=2.0000 norm=2.0271\n",
      "[iter 72] loss=-0.6208 val_loss=-0.3969 scale=2.0000 norm=2.0274\n",
      "[iter 73] loss=-0.6209 val_loss=-0.3967 scale=2.0000 norm=2.0276\n",
      "[iter 74] loss=-0.6210 val_loss=-0.3964 scale=2.0000 norm=2.0278\n",
      "[iter 75] loss=-0.6210 val_loss=-0.3962 scale=2.0000 norm=2.0281\n",
      "[iter 76] loss=-0.6211 val_loss=-0.3959 scale=2.0000 norm=2.0283\n",
      "[iter 77] loss=-0.6211 val_loss=-0.3956 scale=2.0000 norm=2.0284\n",
      "[iter 78] loss=-0.6211 val_loss=-0.3954 scale=2.0000 norm=2.0286\n",
      "[iter 79] loss=-0.6212 val_loss=-0.3952 scale=2.0000 norm=2.0288\n",
      "[iter 80] loss=-0.6212 val_loss=-0.3949 scale=2.0000 norm=2.0290\n",
      "[iter 81] loss=-0.6213 val_loss=-0.3946 scale=2.0000 norm=2.0291\n",
      "[iter 82] loss=-0.6213 val_loss=-0.3943 scale=2.0000 norm=2.0292\n",
      "[iter 83] loss=-0.6213 val_loss=-0.3941 scale=2.0000 norm=2.0294\n",
      "[iter 84] loss=-0.6214 val_loss=-0.3940 scale=1.0000 norm=1.0147\n",
      "[iter 85] loss=-0.6214 val_loss=-0.3938 scale=2.0000 norm=2.0294\n",
      "[iter 86] loss=-0.6215 val_loss=-0.3936 scale=2.0000 norm=2.0296\n",
      "[iter 87] loss=-0.6215 val_loss=-0.3934 scale=2.0000 norm=2.0297\n",
      "[iter 88] loss=-0.6215 val_loss=-0.3932 scale=2.0000 norm=2.0298\n",
      "[iter 89] loss=-0.6215 val_loss=-0.3931 scale=2.0000 norm=2.0299\n",
      "[iter 90] loss=-0.6216 val_loss=-0.3930 scale=1.0000 norm=1.0150\n",
      "[iter 91] loss=-0.6216 val_loss=-0.3929 scale=1.0000 norm=1.0150\n",
      "[iter 92] loss=-0.6216 val_loss=-0.3929 scale=1.0000 norm=1.0150\n",
      "[iter 93] loss=-0.6217 val_loss=-0.3927 scale=2.0000 norm=2.0300\n",
      "[iter 94] loss=-0.6217 val_loss=-0.3926 scale=2.0000 norm=2.0301\n",
      "[iter 95] loss=-0.6217 val_loss=-0.3925 scale=1.0000 norm=1.0151\n",
      "[iter 96] loss=-0.6217 val_loss=-0.3923 scale=2.0000 norm=2.0302\n",
      "[iter 97] loss=-0.6217 val_loss=-0.3921 scale=2.0000 norm=2.0303\n",
      "[iter 98] loss=-0.6218 val_loss=-0.3920 scale=1.0000 norm=1.0152\n",
      "[iter 99] loss=-0.6218 val_loss=-0.3919 scale=1.0000 norm=1.0152\n",
      "Expected 12 Excel files, but found 2 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0961\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5835 val_loss=0.6085 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5815 scale=1.0000 norm=1.0242\n",
      "[iter 7] loss=0.5450 val_loss=0.5690 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5334 val_loss=0.5570 scale=1.0000 norm=1.0064\n",
      "[iter 9] loss=0.5223 val_loss=0.5457 scale=1.0000 norm=0.9993\n",
      "[iter 10] loss=0.5117 val_loss=0.5347 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5015 val_loss=0.5243 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4917 val_loss=0.5143 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4824 val_loss=0.5047 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4734 val_loss=0.4955 scale=1.0000 norm=0.9790\n",
      "[iter 15] loss=0.4647 val_loss=0.4866 scale=1.0000 norm=0.9776\n",
      "[iter 16] loss=0.4564 val_loss=0.4781 scale=1.0000 norm=0.9769\n",
      "[iter 17] loss=0.4484 val_loss=0.4700 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4407 val_loss=0.4621 scale=1.0000 norm=0.9779\n",
      "[iter 19] loss=0.4333 val_loss=0.4545 scale=1.0000 norm=0.9795\n",
      "[iter 20] loss=0.4261 val_loss=0.4472 scale=1.0000 norm=0.9817\n",
      "[iter 21] loss=0.4192 val_loss=0.4401 scale=1.0000 norm=0.9846\n",
      "[iter 22] loss=0.4126 val_loss=0.4333 scale=1.0000 norm=0.9881\n",
      "[iter 23] loss=0.4061 val_loss=0.4267 scale=1.0000 norm=0.9923\n",
      "[iter 24] loss=0.3999 val_loss=0.4204 scale=1.0000 norm=0.9971\n",
      "[iter 25] loss=0.3939 val_loss=0.4142 scale=1.0000 norm=1.0025\n",
      "[iter 26] loss=0.3882 val_loss=0.4083 scale=1.0000 norm=1.0084\n",
      "[iter 27] loss=0.3826 val_loss=0.4026 scale=1.0000 norm=1.0150\n",
      "[iter 28] loss=0.3772 val_loss=0.3971 scale=1.0000 norm=1.0221\n",
      "[iter 29] loss=0.3720 val_loss=0.3917 scale=1.0000 norm=1.0298\n",
      "[iter 30] loss=0.3669 val_loss=0.3866 scale=1.0000 norm=1.0381\n",
      "[iter 31] loss=0.3621 val_loss=0.3816 scale=1.0000 norm=1.0469\n",
      "[iter 32] loss=0.3574 val_loss=0.3768 scale=1.0000 norm=1.0562\n",
      "[iter 33] loss=0.3529 val_loss=0.3721 scale=1.0000 norm=1.0661\n",
      "[iter 34] loss=0.3485 val_loss=0.3676 scale=1.0000 norm=1.0766\n",
      "[iter 35] loss=0.3443 val_loss=0.3633 scale=1.0000 norm=1.0876\n",
      "[iter 36] loss=0.3402 val_loss=0.3591 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3363 val_loss=0.3551 scale=1.0000 norm=1.1112\n",
      "[iter 38] loss=0.3326 val_loss=0.3512 scale=1.0000 norm=1.1237\n",
      "[iter 39] loss=0.3289 val_loss=0.3475 scale=1.0000 norm=1.1369\n",
      "[iter 40] loss=0.3255 val_loss=0.3439 scale=1.0000 norm=1.1505\n",
      "[iter 41] loss=0.3221 val_loss=0.3404 scale=1.0000 norm=1.1646\n",
      "[iter 42] loss=0.3189 val_loss=0.3371 scale=1.0000 norm=1.1793\n",
      "[iter 43] loss=0.3158 val_loss=0.3339 scale=1.0000 norm=1.1945\n",
      "[iter 44] loss=0.3128 val_loss=0.3308 scale=1.0000 norm=1.2102\n",
      "[iter 45] loss=0.3099 val_loss=0.3278 scale=1.0000 norm=1.2264\n",
      "[iter 46] loss=0.3072 val_loss=0.3250 scale=1.0000 norm=1.2430\n",
      "[iter 47] loss=0.3045 val_loss=0.3222 scale=1.0000 norm=1.2602\n",
      "[iter 48] loss=0.3020 val_loss=0.3196 scale=1.0000 norm=1.2778\n",
      "[iter 49] loss=0.2996 val_loss=0.3171 scale=1.0000 norm=1.2958\n",
      "[iter 50] loss=0.2973 val_loss=0.3147 scale=1.0000 norm=1.3143\n",
      "[iter 51] loss=0.2951 val_loss=0.3124 scale=1.0000 norm=1.3332\n",
      "[iter 52] loss=0.2929 val_loss=0.3102 scale=1.0000 norm=1.3525\n",
      "[iter 53] loss=0.2909 val_loss=0.3081 scale=1.0000 norm=1.3723\n",
      "[iter 54] loss=0.2890 val_loss=0.3060 scale=1.0000 norm=1.3923\n",
      "[iter 55] loss=0.2871 val_loss=0.3041 scale=1.0000 norm=1.4128\n",
      "[iter 56] loss=0.2854 val_loss=0.3022 scale=1.0000 norm=1.4335\n",
      "[iter 57] loss=0.2837 val_loss=0.3004 scale=1.0000 norm=1.4545\n",
      "[iter 58] loss=0.2821 val_loss=0.2988 scale=1.0000 norm=1.4757\n",
      "[iter 59] loss=0.2805 val_loss=0.2972 scale=1.0000 norm=1.4972\n",
      "[iter 60] loss=0.2791 val_loss=0.2956 scale=1.0000 norm=1.5189\n",
      "[iter 61] loss=0.2777 val_loss=0.2942 scale=1.0000 norm=1.5407\n",
      "[iter 62] loss=0.2764 val_loss=0.2928 scale=1.0000 norm=1.5627\n",
      "[iter 63] loss=0.2751 val_loss=0.2915 scale=1.0000 norm=1.5848\n",
      "[iter 64] loss=0.2739 val_loss=0.2903 scale=1.0000 norm=1.6071\n",
      "[iter 65] loss=0.2728 val_loss=0.2891 scale=1.0000 norm=1.6295\n",
      "[iter 66] loss=0.2717 val_loss=0.2880 scale=1.0000 norm=1.6519\n",
      "[iter 67] loss=0.2707 val_loss=0.2869 scale=1.0000 norm=1.6744\n",
      "[iter 68] loss=0.2697 val_loss=0.2859 scale=1.0000 norm=1.6969\n",
      "[iter 69] loss=0.2688 val_loss=0.2850 scale=1.0000 norm=1.7195\n",
      "[iter 70] loss=0.2679 val_loss=0.2841 scale=1.0000 norm=1.7419\n",
      "[iter 71] loss=0.2671 val_loss=0.2832 scale=1.0000 norm=1.7643\n",
      "[iter 72] loss=0.2663 val_loss=0.2825 scale=1.0000 norm=1.7867\n",
      "[iter 73] loss=0.2656 val_loss=0.2817 scale=1.0000 norm=1.8089\n",
      "[iter 74] loss=0.2649 val_loss=0.2810 scale=1.0000 norm=1.8310\n",
      "[iter 75] loss=0.2643 val_loss=0.2804 scale=1.0000 norm=1.8528\n",
      "[iter 76] loss=0.2637 val_loss=0.2798 scale=1.0000 norm=1.8742\n",
      "[iter 77] loss=0.2631 val_loss=0.2792 scale=1.0000 norm=1.8954\n",
      "[iter 78] loss=0.2625 val_loss=0.2787 scale=1.0000 norm=1.9164\n",
      "[iter 79] loss=0.2620 val_loss=0.2782 scale=1.0000 norm=1.9371\n",
      "[iter 80] loss=0.2615 val_loss=0.2777 scale=1.0000 norm=1.9571\n",
      "[iter 81] loss=0.2611 val_loss=0.2773 scale=1.0000 norm=1.9771\n",
      "[iter 82] loss=0.2606 val_loss=0.2771 scale=0.5000 norm=0.9983\n",
      "[iter 83] loss=0.2604 val_loss=0.2769 scale=0.5000 norm=1.0028\n",
      "[iter 84] loss=0.2602 val_loss=0.2767 scale=0.5000 norm=1.0074\n",
      "[iter 85] loss=0.2600 val_loss=0.2763 scale=1.0000 norm=2.0237\n",
      "[iter 86] loss=0.2597 val_loss=0.2761 scale=0.5000 norm=1.0209\n",
      "[iter 87] loss=0.2595 val_loss=0.2758 scale=1.0000 norm=2.0507\n",
      "[iter 88] loss=0.2592 val_loss=0.2757 scale=0.5000 norm=1.0342\n",
      "[iter 89] loss=0.2590 val_loss=0.2755 scale=0.5000 norm=1.0386\n",
      "[iter 90] loss=0.2589 val_loss=0.2754 scale=0.5000 norm=1.0430\n",
      "[iter 91] loss=0.2587 val_loss=0.2753 scale=0.5000 norm=1.0473\n",
      "[iter 92] loss=0.2586 val_loss=0.2751 scale=0.5000 norm=1.0516\n",
      "[iter 93] loss=0.2585 val_loss=0.2750 scale=0.5000 norm=1.0559\n",
      "[iter 94] loss=0.2584 val_loss=0.2749 scale=0.5000 norm=1.0601\n",
      "[iter 95] loss=0.2582 val_loss=0.2748 scale=0.5000 norm=1.0644\n",
      "[iter 96] loss=0.2581 val_loss=0.2747 scale=0.5000 norm=1.0686\n",
      "[iter 97] loss=0.2580 val_loss=0.2746 scale=1.0000 norm=2.1455\n",
      "[iter 98] loss=0.2578 val_loss=0.2745 scale=0.5000 norm=1.0814\n",
      "[iter 99] loss=0.2577 val_loss=0.2744 scale=0.5000 norm=1.0852\n",
      "Expected 12 Excel files, but found 3 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3017 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5238 val_loss=-0.3343 scale=1.0000 norm=1.0747\n",
      "[iter 2] loss=-0.5560 val_loss=-0.3633 scale=1.0000 norm=1.0446\n",
      "[iter 3] loss=-0.5843 val_loss=-0.3893 scale=1.0000 norm=1.0181\n",
      "[iter 4] loss=-0.6097 val_loss=-0.4362 scale=2.0000 norm=1.9884\n",
      "[iter 5] loss=-0.6553 val_loss=-0.4763 scale=2.0000 norm=1.9030\n",
      "[iter 6] loss=-0.6946 val_loss=-0.5120 scale=2.0000 norm=1.8300\n",
      "[iter 7] loss=-0.7297 val_loss=-0.5448 scale=2.0000 norm=1.7662\n",
      "[iter 8] loss=-0.7618 val_loss=-0.5749 scale=2.0000 norm=1.7097\n",
      "[iter 9] loss=-0.7915 val_loss=-0.6032 scale=2.0000 norm=1.6596\n",
      "[iter 10] loss=-0.8195 val_loss=-0.6298 scale=2.0000 norm=1.6145\n",
      "[iter 11] loss=-0.8460 val_loss=-0.6550 scale=2.0000 norm=1.5742\n",
      "[iter 12] loss=-0.8712 val_loss=-0.6792 scale=2.0000 norm=1.5380\n",
      "[iter 13] loss=-0.8953 val_loss=-0.7023 scale=2.0000 norm=1.5054\n",
      "[iter 14] loss=-0.9184 val_loss=-0.7246 scale=2.0000 norm=1.4762\n",
      "[iter 15] loss=-0.9409 val_loss=-0.7460 scale=2.0000 norm=1.4498\n",
      "[iter 16] loss=-0.9625 val_loss=-0.7667 scale=2.0000 norm=1.4263\n",
      "[iter 17] loss=-0.9834 val_loss=-0.7868 scale=2.0000 norm=1.4052\n",
      "[iter 18] loss=-1.0037 val_loss=-0.8062 scale=2.0000 norm=1.3861\n",
      "[iter 19] loss=-1.0234 val_loss=-0.8251 scale=2.0000 norm=1.3691\n",
      "[iter 20] loss=-1.0425 val_loss=-0.8433 scale=2.0000 norm=1.3538\n",
      "[iter 21] loss=-1.0611 val_loss=-0.8610 scale=2.0000 norm=1.3401\n",
      "[iter 22] loss=-1.0791 val_loss=-0.8782 scale=2.0000 norm=1.3279\n",
      "[iter 23] loss=-1.0966 val_loss=-0.8948 scale=2.0000 norm=1.3170\n",
      "[iter 24] loss=-1.1136 val_loss=-0.9110 scale=2.0000 norm=1.3073\n",
      "[iter 25] loss=-1.1301 val_loss=-0.9266 scale=2.0000 norm=1.2987\n",
      "[iter 26] loss=-1.1461 val_loss=-0.9419 scale=2.0000 norm=1.2911\n",
      "[iter 27] loss=-1.1617 val_loss=-0.9566 scale=2.0000 norm=1.2843\n",
      "[iter 28] loss=-1.1768 val_loss=-0.9708 scale=2.0000 norm=1.2784\n",
      "[iter 29] loss=-1.1914 val_loss=-0.9846 scale=2.0000 norm=1.2733\n",
      "[iter 30] loss=-1.2056 val_loss=-0.9980 scale=2.0000 norm=1.2688\n",
      "[iter 31] loss=-1.2193 val_loss=-1.0109 scale=2.0000 norm=1.2649\n",
      "[iter 32] loss=-1.2326 val_loss=-1.0235 scale=2.0000 norm=1.2616\n",
      "[iter 33] loss=-1.2455 val_loss=-1.0356 scale=2.0000 norm=1.2588\n",
      "[iter 34] loss=-1.2579 val_loss=-1.0473 scale=2.0000 norm=1.2564\n",
      "[iter 35] loss=-1.2699 val_loss=-1.0587 scale=2.0000 norm=1.2545\n",
      "[iter 36] loss=-1.2816 val_loss=-1.0697 scale=2.0000 norm=1.2529\n",
      "[iter 37] loss=-1.2929 val_loss=-1.0802 scale=2.0000 norm=1.2517\n",
      "[iter 38] loss=-1.3038 val_loss=-1.0905 scale=2.0000 norm=1.2508\n",
      "[iter 39] loss=-1.3143 val_loss=-1.1003 scale=2.0000 norm=1.2503\n",
      "[iter 40] loss=-1.3244 val_loss=-1.1098 scale=2.0000 norm=1.2499\n",
      "[iter 41] loss=-1.3342 val_loss=-1.1190 scale=2.0000 norm=1.2498\n",
      "[iter 42] loss=-1.3436 val_loss=-1.1279 scale=2.0000 norm=1.2500\n",
      "[iter 43] loss=-1.3527 val_loss=-1.1364 scale=2.0000 norm=1.2503\n",
      "[iter 44] loss=-1.3615 val_loss=-1.1446 scale=2.0000 norm=1.2508\n",
      "[iter 45] loss=-1.3699 val_loss=-1.1525 scale=2.0000 norm=1.2516\n",
      "[iter 46] loss=-1.3780 val_loss=-1.1601 scale=2.0000 norm=1.2524\n",
      "[iter 47] loss=-1.3859 val_loss=-1.1674 scale=2.0000 norm=1.2534\n",
      "[iter 48] loss=-1.3934 val_loss=-1.1744 scale=2.0000 norm=1.2545\n",
      "[iter 49] loss=-1.4006 val_loss=-1.1812 scale=2.0000 norm=1.2557\n",
      "[iter 50] loss=-1.4076 val_loss=-1.1876 scale=2.0000 norm=1.2570\n",
      "[iter 51] loss=-1.4142 val_loss=-1.1938 scale=2.0000 norm=1.2585\n",
      "[iter 52] loss=-1.4207 val_loss=-1.1998 scale=2.0000 norm=1.2600\n",
      "[iter 53] loss=-1.4268 val_loss=-1.2055 scale=2.0000 norm=1.2615\n",
      "[iter 54] loss=-1.4327 val_loss=-1.2110 scale=2.0000 norm=1.2632\n",
      "[iter 55] loss=-1.4384 val_loss=-1.2163 scale=2.0000 norm=1.2649\n",
      "[iter 56] loss=-1.4438 val_loss=-1.2213 scale=2.0000 norm=1.2667\n",
      "[iter 57] loss=-1.4490 val_loss=-1.2261 scale=2.0000 norm=1.2685\n",
      "[iter 58] loss=-1.4540 val_loss=-1.2306 scale=2.0000 norm=1.2704\n",
      "[iter 59] loss=-1.4587 val_loss=-1.2350 scale=2.0000 norm=1.2723\n",
      "[iter 60] loss=-1.4633 val_loss=-1.2391 scale=2.0000 norm=1.2741\n",
      "[iter 61] loss=-1.4677 val_loss=-1.2431 scale=2.0000 norm=1.2761\n",
      "[iter 62] loss=-1.4719 val_loss=-1.2469 scale=2.0000 norm=1.2780\n",
      "[iter 63] loss=-1.4758 val_loss=-1.2504 scale=2.0000 norm=1.2800\n",
      "[iter 64] loss=-1.4797 val_loss=-1.2537 scale=2.0000 norm=1.2820\n",
      "[iter 65] loss=-1.4833 val_loss=-1.2569 scale=2.0000 norm=1.2840\n",
      "[iter 66] loss=-1.4868 val_loss=-1.2600 scale=2.0000 norm=1.2859\n",
      "[iter 67] loss=-1.4901 val_loss=-1.2629 scale=2.0000 norm=1.2879\n",
      "[iter 68] loss=-1.4933 val_loss=-1.2657 scale=2.0000 norm=1.2899\n",
      "[iter 69] loss=-1.4963 val_loss=-1.2683 scale=2.0000 norm=1.2919\n",
      "[iter 70] loss=-1.4992 val_loss=-1.2707 scale=2.0000 norm=1.2938\n",
      "[iter 71] loss=-1.5019 val_loss=-1.2730 scale=2.0000 norm=1.2958\n",
      "[iter 72] loss=-1.5045 val_loss=-1.2751 scale=2.0000 norm=1.2978\n",
      "[iter 73] loss=-1.5070 val_loss=-1.2770 scale=2.0000 norm=1.2997\n",
      "[iter 74] loss=-1.5093 val_loss=-1.2789 scale=2.0000 norm=1.3016\n",
      "[iter 75] loss=-1.5115 val_loss=-1.2806 scale=2.0000 norm=1.3036\n",
      "[iter 76] loss=-1.5136 val_loss=-1.2822 scale=2.0000 norm=1.3054\n",
      "[iter 77] loss=-1.5156 val_loss=-1.2836 scale=2.0000 norm=1.3073\n",
      "[iter 78] loss=-1.5175 val_loss=-1.2850 scale=2.0000 norm=1.3092\n",
      "[iter 79] loss=-1.5193 val_loss=-1.2863 scale=2.0000 norm=1.3110\n",
      "[iter 80] loss=-1.5210 val_loss=-1.2875 scale=2.0000 norm=1.3128\n",
      "[iter 81] loss=-1.5226 val_loss=-1.2886 scale=2.0000 norm=1.3146\n",
      "[iter 82] loss=-1.5242 val_loss=-1.2896 scale=2.0000 norm=1.3163\n",
      "[iter 83] loss=-1.5256 val_loss=-1.2905 scale=2.0000 norm=1.3180\n",
      "[iter 84] loss=-1.5269 val_loss=-1.2915 scale=2.0000 norm=1.3197\n",
      "[iter 85] loss=-1.5282 val_loss=-1.2924 scale=2.0000 norm=1.3214\n",
      "[iter 86] loss=-1.5295 val_loss=-1.2931 scale=2.0000 norm=1.3230\n",
      "[iter 87] loss=-1.5306 val_loss=-1.2936 scale=2.0000 norm=1.3246\n",
      "[iter 88] loss=-1.5317 val_loss=-1.2940 scale=2.0000 norm=1.3261\n",
      "[iter 89] loss=-1.5326 val_loss=-1.2945 scale=2.0000 norm=1.3275\n",
      "[iter 90] loss=-1.5336 val_loss=-1.2949 scale=2.0000 norm=1.3290\n",
      "[iter 91] loss=-1.5345 val_loss=-1.2952 scale=2.0000 norm=1.3305\n",
      "[iter 92] loss=-1.5353 val_loss=-1.2956 scale=2.0000 norm=1.3318\n",
      "[iter 93] loss=-1.5362 val_loss=-1.2958 scale=2.0000 norm=1.3331\n",
      "[iter 94] loss=-1.5369 val_loss=-1.2960 scale=2.0000 norm=1.3345\n",
      "[iter 95] loss=-1.5376 val_loss=-1.2961 scale=2.0000 norm=1.3357\n",
      "[iter 96] loss=-1.5383 val_loss=-1.2960 scale=2.0000 norm=1.3369\n",
      "[iter 97] loss=-1.5389 val_loss=-1.2961 scale=2.0000 norm=1.3379\n",
      "[iter 98] loss=-1.5396 val_loss=-1.2962 scale=2.0000 norm=1.3389\n",
      "[iter 99] loss=-1.5401 val_loss=-1.2964 scale=2.0000 norm=1.3399\n",
      "Expected 12 Excel files, but found 4 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0960\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5834 val_loss=0.6084 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5814 scale=1.0000 norm=1.0241\n",
      "[iter 7] loss=0.5450 val_loss=0.5689 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5333 val_loss=0.5569 scale=1.0000 norm=1.0063\n",
      "[iter 9] loss=0.5222 val_loss=0.5455 scale=1.0000 norm=0.9992\n",
      "[iter 10] loss=0.5116 val_loss=0.5346 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5014 val_loss=0.5242 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4916 val_loss=0.5142 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4823 val_loss=0.5045 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4733 val_loss=0.4953 scale=1.0000 norm=0.9789\n",
      "[iter 15] loss=0.4646 val_loss=0.4865 scale=1.0000 norm=0.9775\n",
      "[iter 16] loss=0.4563 val_loss=0.4779 scale=1.0000 norm=0.9768\n",
      "[iter 17] loss=0.4483 val_loss=0.4698 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4406 val_loss=0.4619 scale=1.0000 norm=0.9778\n",
      "[iter 19] loss=0.4332 val_loss=0.4543 scale=1.0000 norm=0.9794\n",
      "[iter 20] loss=0.4260 val_loss=0.4469 scale=1.0000 norm=0.9816\n",
      "[iter 21] loss=0.4191 val_loss=0.4399 scale=1.0000 norm=0.9844\n",
      "[iter 22] loss=0.4124 val_loss=0.4330 scale=1.0000 norm=0.9879\n",
      "[iter 23] loss=0.4059 val_loss=0.4264 scale=1.0000 norm=0.9921\n",
      "[iter 24] loss=0.3997 val_loss=0.4200 scale=1.0000 norm=0.9969\n",
      "[iter 25] loss=0.3937 val_loss=0.4138 scale=1.0000 norm=1.0022\n",
      "[iter 26] loss=0.3878 val_loss=0.4078 scale=1.0000 norm=1.0082\n",
      "[iter 27] loss=0.3822 val_loss=0.4021 scale=1.0000 norm=1.0147\n",
      "[iter 28] loss=0.3767 val_loss=0.3965 scale=1.0000 norm=1.0218\n",
      "[iter 29] loss=0.3715 val_loss=0.3911 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3664 val_loss=0.3858 scale=1.0000 norm=1.0377\n",
      "[iter 31] loss=0.3614 val_loss=0.3808 scale=1.0000 norm=1.0465\n",
      "[iter 32] loss=0.3567 val_loss=0.3759 scale=1.0000 norm=1.0559\n",
      "[iter 33] loss=0.3521 val_loss=0.3711 scale=1.0000 norm=1.0658\n",
      "[iter 34] loss=0.3476 val_loss=0.3666 scale=1.0000 norm=1.0763\n",
      "[iter 35] loss=0.3433 val_loss=0.3622 scale=1.0000 norm=1.0874\n",
      "[iter 36] loss=0.3392 val_loss=0.3579 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3352 val_loss=0.3538 scale=1.0000 norm=1.1113\n",
      "[iter 38] loss=0.3314 val_loss=0.3498 scale=1.0000 norm=1.1240\n",
      "[iter 39] loss=0.3277 val_loss=0.3460 scale=1.0000 norm=1.1373\n",
      "[iter 40] loss=0.3241 val_loss=0.3423 scale=1.0000 norm=1.1511\n",
      "[iter 41] loss=0.3206 val_loss=0.3387 scale=1.0000 norm=1.1655\n",
      "[iter 42] loss=0.3173 val_loss=0.3352 scale=1.0000 norm=1.1804\n",
      "[iter 43] loss=0.3141 val_loss=0.3319 scale=1.0000 norm=1.1958\n",
      "[iter 44] loss=0.3110 val_loss=0.3288 scale=1.0000 norm=1.2118\n",
      "[iter 45] loss=0.3080 val_loss=0.3257 scale=1.0000 norm=1.2283\n",
      "[iter 46] loss=0.3052 val_loss=0.3227 scale=1.0000 norm=1.2454\n",
      "[iter 47] loss=0.3025 val_loss=0.3198 scale=1.0000 norm=1.2630\n",
      "[iter 48] loss=0.2998 val_loss=0.3171 scale=1.0000 norm=1.2809\n",
      "[iter 49] loss=0.2973 val_loss=0.3144 scale=1.0000 norm=1.2993\n",
      "[iter 50] loss=0.2949 val_loss=0.3119 scale=1.0000 norm=1.3181\n",
      "[iter 51] loss=0.2925 val_loss=0.3095 scale=1.0000 norm=1.3374\n",
      "[iter 52] loss=0.2903 val_loss=0.3072 scale=1.0000 norm=1.3575\n",
      "[iter 53] loss=0.2882 val_loss=0.3049 scale=1.0000 norm=1.3777\n",
      "[iter 54] loss=0.2861 val_loss=0.3028 scale=1.0000 norm=1.3983\n",
      "[iter 55] loss=0.2842 val_loss=0.3008 scale=1.0000 norm=1.4194\n",
      "[iter 56] loss=0.2823 val_loss=0.2988 scale=1.0000 norm=1.4408\n",
      "[iter 57] loss=0.2805 val_loss=0.2969 scale=1.0000 norm=1.4627\n",
      "[iter 58] loss=0.2788 val_loss=0.2952 scale=1.0000 norm=1.4846\n",
      "[iter 59] loss=0.2772 val_loss=0.2934 scale=1.0000 norm=1.5069\n",
      "[iter 60] loss=0.2756 val_loss=0.2918 scale=1.0000 norm=1.5293\n",
      "[iter 61] loss=0.2741 val_loss=0.2903 scale=1.0000 norm=1.5520\n",
      "[iter 62] loss=0.2727 val_loss=0.2888 scale=1.0000 norm=1.5751\n",
      "[iter 63] loss=0.2713 val_loss=0.2874 scale=1.0000 norm=1.5980\n",
      "[iter 64] loss=0.2700 val_loss=0.2861 scale=1.0000 norm=1.6211\n",
      "[iter 65] loss=0.2688 val_loss=0.2847 scale=1.0000 norm=1.6443\n",
      "[iter 66] loss=0.2676 val_loss=0.2835 scale=1.0000 norm=1.6677\n",
      "[iter 67] loss=0.2665 val_loss=0.2823 scale=1.0000 norm=1.6912\n",
      "[iter 68] loss=0.2654 val_loss=0.2813 scale=1.0000 norm=1.7147\n",
      "[iter 69] loss=0.2644 val_loss=0.2802 scale=1.0000 norm=1.7387\n",
      "[iter 70] loss=0.2635 val_loss=0.2792 scale=1.0000 norm=1.7623\n",
      "[iter 71] loss=0.2626 val_loss=0.2783 scale=1.0000 norm=1.7857\n",
      "[iter 72] loss=0.2617 val_loss=0.2774 scale=1.0000 norm=1.8095\n",
      "[iter 73] loss=0.2609 val_loss=0.2765 scale=1.0000 norm=1.8328\n",
      "[iter 74] loss=0.2601 val_loss=0.2757 scale=1.0000 norm=1.8561\n",
      "[iter 75] loss=0.2594 val_loss=0.2750 scale=1.0000 norm=1.8797\n",
      "[iter 76] loss=0.2587 val_loss=0.2742 scale=1.0000 norm=1.9026\n",
      "[iter 77] loss=0.2580 val_loss=0.2736 scale=1.0000 norm=1.9252\n",
      "[iter 78] loss=0.2574 val_loss=0.2729 scale=1.0000 norm=1.9479\n",
      "[iter 79] loss=0.2568 val_loss=0.2723 scale=1.0000 norm=1.9698\n",
      "[iter 80] loss=0.2562 val_loss=0.2718 scale=1.0000 norm=1.9922\n",
      "[iter 81] loss=0.2557 val_loss=0.2713 scale=1.0000 norm=2.0139\n",
      "[iter 82] loss=0.2552 val_loss=0.2707 scale=1.0000 norm=2.0354\n",
      "[iter 83] loss=0.2548 val_loss=0.2705 scale=0.5000 norm=1.0279\n",
      "[iter 84] loss=0.2546 val_loss=0.2703 scale=0.5000 norm=1.0330\n",
      "[iter 85] loss=0.2543 val_loss=0.2701 scale=0.5000 norm=1.0381\n",
      "[iter 86] loss=0.2541 val_loss=0.2699 scale=0.5000 norm=1.0430\n",
      "[iter 87] loss=0.2539 val_loss=0.2697 scale=0.5000 norm=1.0479\n",
      "[iter 88] loss=0.2537 val_loss=0.2695 scale=0.5000 norm=1.0526\n",
      "[iter 89] loss=0.2536 val_loss=0.2693 scale=0.5000 norm=1.0573\n",
      "[iter 90] loss=0.2534 val_loss=0.2691 scale=0.5000 norm=1.0622\n",
      "[iter 91] loss=0.2532 val_loss=0.2690 scale=0.5000 norm=1.0668\n",
      "[iter 92] loss=0.2530 val_loss=0.2688 scale=0.5000 norm=1.0713\n",
      "[iter 93] loss=0.2529 val_loss=0.2687 scale=0.5000 norm=1.0758\n",
      "[iter 94] loss=0.2527 val_loss=0.2686 scale=0.5000 norm=1.0805\n",
      "[iter 95] loss=0.2526 val_loss=0.2684 scale=0.5000 norm=1.0849\n",
      "[iter 96] loss=0.2524 val_loss=0.2683 scale=0.5000 norm=1.0895\n",
      "[iter 97] loss=0.2523 val_loss=0.2682 scale=0.5000 norm=1.0941\n",
      "[iter 98] loss=0.2522 val_loss=0.2681 scale=0.5000 norm=1.0985\n",
      "[iter 99] loss=0.2520 val_loss=0.2679 scale=0.5000 norm=1.1029\n",
      "Expected 12 Excel files, but found 5 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3020 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5244 val_loss=-0.3346 scale=1.0000 norm=1.0742\n",
      "[iter 2] loss=-0.5567 val_loss=-0.3637 scale=1.0000 norm=1.0440\n",
      "[iter 3] loss=-0.5852 val_loss=-0.3899 scale=1.0000 norm=1.0173\n",
      "[iter 4] loss=-0.6108 val_loss=-0.4368 scale=2.0000 norm=1.9869\n",
      "[iter 5] loss=-0.6564 val_loss=-0.4769 scale=2.0000 norm=1.9015\n",
      "[iter 6] loss=-0.6957 val_loss=-0.5129 scale=2.0000 norm=1.8285\n",
      "[iter 7] loss=-0.7308 val_loss=-0.5459 scale=2.0000 norm=1.7648\n",
      "[iter 8] loss=-0.7630 val_loss=-0.5761 scale=2.0000 norm=1.7084\n",
      "[iter 9] loss=-0.7927 val_loss=-0.6046 scale=2.0000 norm=1.6583\n",
      "[iter 10] loss=-0.8208 val_loss=-0.6313 scale=2.0000 norm=1.6132\n",
      "[iter 11] loss=-0.8473 val_loss=-0.6567 scale=2.0000 norm=1.5729\n",
      "[iter 12] loss=-0.8725 val_loss=-0.6809 scale=2.0000 norm=1.5368\n",
      "[iter 13] loss=-0.8967 val_loss=-0.7042 scale=2.0000 norm=1.5042\n",
      "[iter 14] loss=-0.9199 val_loss=-0.7265 scale=2.0000 norm=1.4749\n",
      "[iter 15] loss=-0.9424 val_loss=-0.7481 scale=2.0000 norm=1.4485\n",
      "[iter 16] loss=-0.9641 val_loss=-0.7690 scale=2.0000 norm=1.4248\n",
      "[iter 17] loss=-0.9852 val_loss=-0.7892 scale=2.0000 norm=1.4035\n",
      "[iter 18] loss=-1.0055 val_loss=-0.8088 scale=2.0000 norm=1.3843\n",
      "[iter 19] loss=-1.0254 val_loss=-0.8277 scale=2.0000 norm=1.3670\n",
      "[iter 20] loss=-1.0447 val_loss=-0.8461 scale=2.0000 norm=1.3515\n",
      "[iter 21] loss=-1.0635 val_loss=-0.8640 scale=2.0000 norm=1.3375\n",
      "[iter 22] loss=-1.0818 val_loss=-0.8814 scale=2.0000 norm=1.3250\n",
      "[iter 23] loss=-1.0995 val_loss=-0.8983 scale=2.0000 norm=1.3138\n",
      "[iter 24] loss=-1.1168 val_loss=-0.9146 scale=2.0000 norm=1.3038\n",
      "[iter 25] loss=-1.1337 val_loss=-0.9308 scale=2.0000 norm=1.2947\n",
      "[iter 26] loss=-1.1501 val_loss=-0.9461 scale=2.0000 norm=1.2866\n",
      "[iter 27] loss=-1.1661 val_loss=-0.9610 scale=2.0000 norm=1.2795\n",
      "[iter 28] loss=-1.1815 val_loss=-0.9757 scale=2.0000 norm=1.2731\n",
      "[iter 29] loss=-1.1965 val_loss=-0.9899 scale=2.0000 norm=1.2675\n",
      "[iter 30] loss=-1.2111 val_loss=-1.0038 scale=2.0000 norm=1.2627\n",
      "[iter 31] loss=-1.2253 val_loss=-1.0172 scale=2.0000 norm=1.2583\n",
      "[iter 32] loss=-1.2392 val_loss=-1.0302 scale=2.0000 norm=1.2545\n",
      "[iter 33] loss=-1.2525 val_loss=-1.0431 scale=2.0000 norm=1.2512\n",
      "[iter 34] loss=-1.2655 val_loss=-1.0554 scale=2.0000 norm=1.2484\n",
      "[iter 35] loss=-1.2780 val_loss=-1.0672 scale=2.0000 norm=1.2460\n",
      "[iter 36] loss=-1.2902 val_loss=-1.0789 scale=2.0000 norm=1.2440\n",
      "[iter 37] loss=-1.3020 val_loss=-1.0902 scale=2.0000 norm=1.2423\n",
      "[iter 38] loss=-1.3134 val_loss=-1.1011 scale=2.0000 norm=1.2411\n",
      "[iter 39] loss=-1.3245 val_loss=-1.1116 scale=2.0000 norm=1.2400\n",
      "[iter 40] loss=-1.3351 val_loss=-1.1217 scale=2.0000 norm=1.2393\n",
      "[iter 41] loss=-1.3454 val_loss=-1.1314 scale=2.0000 norm=1.2388\n",
      "[iter 42] loss=-1.3553 val_loss=-1.1410 scale=2.0000 norm=1.2386\n",
      "[iter 43] loss=-1.3650 val_loss=-1.1500 scale=2.0000 norm=1.2385\n",
      "[iter 44] loss=-1.3743 val_loss=-1.1589 scale=2.0000 norm=1.2386\n",
      "[iter 45] loss=-1.3832 val_loss=-1.1672 scale=2.0000 norm=1.2390\n",
      "[iter 46] loss=-1.3919 val_loss=-1.1755 scale=2.0000 norm=1.2395\n",
      "[iter 47] loss=-1.4002 val_loss=-1.1833 scale=2.0000 norm=1.2401\n",
      "[iter 48] loss=-1.4083 val_loss=-1.1908 scale=2.0000 norm=1.2409\n",
      "[iter 49] loss=-1.4160 val_loss=-1.1982 scale=2.0000 norm=1.2419\n",
      "[iter 50] loss=-1.4234 val_loss=-1.2053 scale=2.0000 norm=1.2429\n",
      "[iter 51] loss=-1.4306 val_loss=-1.2121 scale=2.0000 norm=1.2440\n",
      "[iter 52] loss=-1.4376 val_loss=-1.2186 scale=2.0000 norm=1.2452\n",
      "[iter 53] loss=-1.4442 val_loss=-1.2250 scale=2.0000 norm=1.2465\n",
      "[iter 54] loss=-1.4506 val_loss=-1.2310 scale=2.0000 norm=1.2480\n",
      "[iter 55] loss=-1.4567 val_loss=-1.2370 scale=2.0000 norm=1.2494\n",
      "[iter 56] loss=-1.4626 val_loss=-1.2425 scale=2.0000 norm=1.2510\n",
      "[iter 57] loss=-1.4683 val_loss=-1.2479 scale=2.0000 norm=1.2526\n",
      "[iter 58] loss=-1.4738 val_loss=-1.2532 scale=2.0000 norm=1.2542\n",
      "[iter 59] loss=-1.4790 val_loss=-1.2582 scale=2.0000 norm=1.2558\n",
      "[iter 60] loss=-1.4840 val_loss=-1.2629 scale=2.0000 norm=1.2575\n",
      "[iter 61] loss=-1.4888 val_loss=-1.2674 scale=2.0000 norm=1.2593\n",
      "[iter 62] loss=-1.4934 val_loss=-1.2717 scale=2.0000 norm=1.2612\n",
      "[iter 63] loss=-1.4979 val_loss=-1.2758 scale=2.0000 norm=1.2629\n",
      "[iter 64] loss=-1.5021 val_loss=-1.2798 scale=2.0000 norm=1.2647\n",
      "[iter 65] loss=-1.5062 val_loss=-1.2834 scale=2.0000 norm=1.2666\n",
      "[iter 66] loss=-1.5100 val_loss=-1.2869 scale=2.0000 norm=1.2684\n",
      "[iter 67] loss=-1.5138 val_loss=-1.2904 scale=2.0000 norm=1.2702\n",
      "[iter 68] loss=-1.5173 val_loss=-1.2935 scale=2.0000 norm=1.2721\n",
      "[iter 69] loss=-1.5207 val_loss=-1.2965 scale=2.0000 norm=1.2738\n",
      "[iter 70] loss=-1.5240 val_loss=-1.2994 scale=2.0000 norm=1.2756\n",
      "[iter 71] loss=-1.5271 val_loss=-1.3020 scale=2.0000 norm=1.2775\n",
      "[iter 72] loss=-1.5300 val_loss=-1.3045 scale=2.0000 norm=1.2793\n",
      "[iter 73] loss=-1.5328 val_loss=-1.3068 scale=2.0000 norm=1.2811\n",
      "[iter 74] loss=-1.5355 val_loss=-1.3092 scale=2.0000 norm=1.2829\n",
      "[iter 75] loss=-1.5381 val_loss=-1.3114 scale=2.0000 norm=1.2848\n",
      "[iter 76] loss=-1.5405 val_loss=-1.3134 scale=2.0000 norm=1.2865\n",
      "[iter 77] loss=-1.5428 val_loss=-1.3155 scale=2.0000 norm=1.2882\n",
      "[iter 78] loss=-1.5451 val_loss=-1.3173 scale=2.0000 norm=1.2900\n",
      "[iter 79] loss=-1.5472 val_loss=-1.3191 scale=2.0000 norm=1.2917\n",
      "[iter 80] loss=-1.5493 val_loss=-1.3205 scale=2.0000 norm=1.2935\n",
      "[iter 81] loss=-1.5512 val_loss=-1.3219 scale=2.0000 norm=1.2951\n",
      "[iter 82] loss=-1.5530 val_loss=-1.3233 scale=2.0000 norm=1.2968\n",
      "[iter 83] loss=-1.5547 val_loss=-1.3247 scale=2.0000 norm=1.2984\n",
      "[iter 84] loss=-1.5564 val_loss=-1.3260 scale=2.0000 norm=1.3000\n",
      "[iter 85] loss=-1.5580 val_loss=-1.3271 scale=2.0000 norm=1.3015\n",
      "[iter 86] loss=-1.5595 val_loss=-1.3280 scale=2.0000 norm=1.3031\n",
      "[iter 87] loss=-1.5609 val_loss=-1.3290 scale=2.0000 norm=1.3046\n",
      "[iter 88] loss=-1.5622 val_loss=-1.3297 scale=2.0000 norm=1.3061\n",
      "[iter 89] loss=-1.5635 val_loss=-1.3301 scale=2.0000 norm=1.3075\n",
      "[iter 90] loss=-1.5647 val_loss=-1.3309 scale=2.0000 norm=1.3088\n",
      "[iter 91] loss=-1.5658 val_loss=-1.3316 scale=2.0000 norm=1.3102\n",
      "[iter 92] loss=-1.5669 val_loss=-1.3321 scale=2.0000 norm=1.3116\n",
      "[iter 93] loss=-1.5679 val_loss=-1.3325 scale=2.0000 norm=1.3129\n",
      "[iter 94] loss=-1.5689 val_loss=-1.3331 scale=2.0000 norm=1.3142\n",
      "[iter 95] loss=-1.5698 val_loss=-1.3333 scale=2.0000 norm=1.3155\n",
      "[iter 96] loss=-1.5707 val_loss=-1.3337 scale=2.0000 norm=1.3166\n",
      "[iter 97] loss=-1.5715 val_loss=-1.3341 scale=2.0000 norm=1.3178\n",
      "[iter 98] loss=-1.5723 val_loss=-1.3342 scale=2.0000 norm=1.3190\n",
      "[iter 99] loss=-1.5730 val_loss=-1.3347 scale=2.0000 norm=1.3200\n",
      "Expected 12 Excel files, but found 6 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0952\n",
      "[iter 2] loss=0.6111 val_loss=0.6360 scale=1.0000 norm=1.0760\n",
      "[iter 3] loss=0.5953 val_loss=0.6198 scale=1.0000 norm=1.0588\n",
      "[iter 4] loss=0.5803 val_loss=0.6043 scale=1.0000 norm=1.0438\n",
      "[iter 5] loss=0.5659 val_loss=0.5895 scale=1.0000 norm=1.0302\n",
      "[iter 6] loss=0.5522 val_loss=0.5753 scale=1.0000 norm=1.0183\n",
      "[iter 7] loss=0.5389 val_loss=0.5618 scale=1.0000 norm=1.0078\n",
      "[iter 8] loss=0.5262 val_loss=0.5488 scale=1.0000 norm=0.9986\n",
      "[iter 9] loss=0.5140 val_loss=0.5364 scale=1.0000 norm=0.9906\n",
      "[iter 10] loss=0.5022 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4800 val_loss=0.5015 scale=1.0000 norm=0.9735\n",
      "[iter 13] loss=0.4693 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9653\n",
      "[iter 16] loss=0.4395 val_loss=0.4603 scale=1.0000 norm=0.9644\n",
      "[iter 17] loss=0.4302 val_loss=0.4508 scale=1.0000 norm=0.9645\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9653\n",
      "[iter 19] loss=0.4123 val_loss=0.4326 scale=1.0000 norm=0.9671\n",
      "[iter 20] loss=0.4038 val_loss=0.4239 scale=1.0000 norm=0.9695\n",
      "[iter 21] loss=0.3955 val_loss=0.4154 scale=1.0000 norm=0.9730\n",
      "[iter 22] loss=0.3874 val_loss=0.4069 scale=1.0000 norm=0.9772\n",
      "[iter 23] loss=0.3794 val_loss=0.3989 scale=1.0000 norm=0.9822\n",
      "[iter 24] loss=0.3717 val_loss=0.3911 scale=1.0000 norm=0.9881\n",
      "[iter 25] loss=0.3643 val_loss=0.3834 scale=1.0000 norm=0.9948\n",
      "[iter 26] loss=0.3569 val_loss=0.3759 scale=1.0000 norm=1.0023\n",
      "[iter 27] loss=0.3499 val_loss=0.3687 scale=1.0000 norm=1.0107\n",
      "[iter 28] loss=0.3429 val_loss=0.3617 scale=1.0000 norm=1.0198\n",
      "[iter 29] loss=0.3362 val_loss=0.3547 scale=1.0000 norm=1.0299\n",
      "[iter 30] loss=0.3296 val_loss=0.3481 scale=1.0000 norm=1.0407\n",
      "[iter 31] loss=0.3232 val_loss=0.3416 scale=1.0000 norm=1.0523\n",
      "[iter 32] loss=0.3169 val_loss=0.3353 scale=1.0000 norm=1.0650\n",
      "[iter 33] loss=0.3108 val_loss=0.3290 scale=1.0000 norm=1.0785\n",
      "[iter 34] loss=0.3049 val_loss=0.3228 scale=1.0000 norm=1.0929\n",
      "[iter 35] loss=0.2991 val_loss=0.3170 scale=1.0000 norm=1.1080\n",
      "[iter 36] loss=0.2935 val_loss=0.3113 scale=1.0000 norm=1.1244\n",
      "[iter 37] loss=0.2881 val_loss=0.3058 scale=1.0000 norm=1.1416\n",
      "[iter 38] loss=0.2828 val_loss=0.3003 scale=1.0000 norm=1.1599\n",
      "[iter 39] loss=0.2776 val_loss=0.2951 scale=1.0000 norm=1.1790\n",
      "[iter 40] loss=0.2727 val_loss=0.2900 scale=1.0000 norm=1.1991\n",
      "[iter 41] loss=0.2678 val_loss=0.2851 scale=1.0000 norm=1.2205\n",
      "[iter 42] loss=0.2631 val_loss=0.2803 scale=1.0000 norm=1.2428\n",
      "[iter 43] loss=0.2585 val_loss=0.2757 scale=1.0000 norm=1.2664\n",
      "[iter 44] loss=0.2541 val_loss=0.2712 scale=1.0000 norm=1.2910\n",
      "[iter 45] loss=0.2499 val_loss=0.2669 scale=1.0000 norm=1.3170\n",
      "[iter 46] loss=0.2458 val_loss=0.2626 scale=1.0000 norm=1.3439\n",
      "[iter 47] loss=0.2418 val_loss=0.2586 scale=1.0000 norm=1.3722\n",
      "[iter 48] loss=0.2380 val_loss=0.2547 scale=1.0000 norm=1.4018\n",
      "[iter 49] loss=0.2343 val_loss=0.2510 scale=1.0000 norm=1.4329\n",
      "[iter 50] loss=0.2308 val_loss=0.2473 scale=1.0000 norm=1.4653\n",
      "[iter 51] loss=0.2274 val_loss=0.2439 scale=1.0000 norm=1.4991\n",
      "[iter 52] loss=0.2242 val_loss=0.2405 scale=1.0000 norm=1.5347\n",
      "[iter 53] loss=0.2211 val_loss=0.2374 scale=1.0000 norm=1.5716\n",
      "[iter 54] loss=0.2181 val_loss=0.2343 scale=1.0000 norm=1.6101\n",
      "[iter 55] loss=0.2153 val_loss=0.2313 scale=1.0000 norm=1.6502\n",
      "[iter 56] loss=0.2126 val_loss=0.2286 scale=1.0000 norm=1.6922\n",
      "[iter 57] loss=0.2101 val_loss=0.2260 scale=1.0000 norm=1.7354\n",
      "[iter 58] loss=0.2077 val_loss=0.2234 scale=1.0000 norm=1.7803\n",
      "[iter 59] loss=0.2054 val_loss=0.2211 scale=1.0000 norm=1.8259\n",
      "[iter 60] loss=0.2033 val_loss=0.2189 scale=1.0000 norm=1.8723\n",
      "[iter 61] loss=0.2012 val_loss=0.2167 scale=1.0000 norm=1.9201\n",
      "[iter 62] loss=0.1993 val_loss=0.2146 scale=1.0000 norm=1.9683\n",
      "[iter 63] loss=0.1974 val_loss=0.2125 scale=1.0000 norm=2.0175\n",
      "[iter 64] loss=0.1956 val_loss=0.2107 scale=1.0000 norm=2.0650\n",
      "[iter 65] loss=0.1940 val_loss=0.2088 scale=1.0000 norm=2.1148\n",
      "[iter 66] loss=0.1924 val_loss=0.2071 scale=1.0000 norm=2.1624\n",
      "[iter 67] loss=0.1908 val_loss=0.2055 scale=1.0000 norm=2.2089\n",
      "[iter 68] loss=0.1894 val_loss=0.2040 scale=1.0000 norm=2.2558\n",
      "[iter 69] loss=0.1880 val_loss=0.2024 scale=1.0000 norm=2.3004\n",
      "[iter 70] loss=0.1867 val_loss=0.2010 scale=1.0000 norm=2.3457\n",
      "[iter 71] loss=0.1855 val_loss=0.1997 scale=1.0000 norm=2.3889\n",
      "[iter 72] loss=0.1843 val_loss=0.1984 scale=1.0000 norm=2.4310\n",
      "[iter 73] loss=0.1832 val_loss=0.1972 scale=1.0000 norm=2.4721\n",
      "[iter 74] loss=0.1821 val_loss=0.1960 scale=1.0000 norm=2.5109\n",
      "[iter 75] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5502\n",
      "[iter 76] loss=0.1801 val_loss=0.1940 scale=1.0000 norm=2.5883\n",
      "[iter 77] loss=0.1792 val_loss=0.1930 scale=1.0000 norm=2.6249\n",
      "[iter 78] loss=0.1784 val_loss=0.1919 scale=1.0000 norm=2.6617\n",
      "[iter 79] loss=0.1775 val_loss=0.1911 scale=1.0000 norm=2.6959\n",
      "[iter 80] loss=0.1768 val_loss=0.1902 scale=1.0000 norm=2.7289\n",
      "[iter 81] loss=0.1760 val_loss=0.1895 scale=1.0000 norm=2.7603\n",
      "[iter 82] loss=0.1753 val_loss=0.1887 scale=1.0000 norm=2.7905\n",
      "[iter 83] loss=0.1746 val_loss=0.1883 scale=0.5000 norm=1.4094\n",
      "[iter 84] loss=0.1743 val_loss=0.1876 scale=1.0000 norm=2.8341\n",
      "[iter 85] loss=0.1737 val_loss=0.1870 scale=1.0000 norm=2.8618\n",
      "[iter 86] loss=0.1731 val_loss=0.1867 scale=0.5000 norm=1.4439\n",
      "[iter 87] loss=0.1728 val_loss=0.1865 scale=0.5000 norm=1.4502\n",
      "[iter 88] loss=0.1725 val_loss=0.1859 scale=1.0000 norm=2.9145\n",
      "[iter 89] loss=0.1720 val_loss=0.1854 scale=1.0000 norm=2.9379\n",
      "[iter 90] loss=0.1715 val_loss=0.1852 scale=0.5000 norm=1.4811\n",
      "[iter 91] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4876\n",
      "[iter 92] loss=0.1710 val_loss=0.1846 scale=1.0000 norm=2.9870\n",
      "[iter 93] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=3.0107\n",
      "[iter 94] loss=0.1702 val_loss=0.1839 scale=1.0000 norm=3.0335\n",
      "[iter 95] loss=0.1698 val_loss=0.1838 scale=0.5000 norm=1.5294\n",
      "[iter 96] loss=0.1696 val_loss=0.1836 scale=0.5000 norm=1.5356\n",
      "[iter 97] loss=0.1695 val_loss=0.1833 scale=1.0000 norm=3.0847\n",
      "[iter 98] loss=0.1691 val_loss=0.1830 scale=1.0000 norm=3.1097\n",
      "[iter 99] loss=0.1688 val_loss=0.1828 scale=1.0000 norm=3.1368\n",
      "Expected 12 Excel files, but found 7 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3054 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5282 val_loss=-0.3417 scale=1.0000 norm=1.0710\n",
      "[iter 2] loss=-0.5639 val_loss=-0.3723 scale=1.0000 norm=1.0382\n",
      "[iter 3] loss=-0.5940 val_loss=-0.4012 scale=1.0000 norm=1.0103\n",
      "[iter 4] loss=-0.6219 val_loss=-0.4272 scale=1.0000 norm=0.9848\n",
      "[iter 5] loss=-0.6467 val_loss=-0.4512 scale=1.0000 norm=0.9621\n",
      "[iter 6] loss=-0.6698 val_loss=-0.4735 scale=1.0000 norm=0.9410\n",
      "[iter 7] loss=-0.6914 val_loss=-0.4945 scale=1.0000 norm=0.9214\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9030\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5335 scale=1.0000 norm=0.8857\n",
      "[iter 10] loss=-0.7500 val_loss=-0.5518 scale=1.0000 norm=0.8695\n",
      "[iter 11] loss=-0.7679 val_loss=-0.5695 scale=1.0000 norm=0.8541\n",
      "[iter 12] loss=-0.7855 val_loss=-0.5867 scale=1.0000 norm=0.8392\n",
      "[iter 13] loss=-0.8024 val_loss=-0.6036 scale=1.0000 norm=0.8252\n",
      "[iter 14] loss=-0.8190 val_loss=-0.6358 scale=2.0000 norm=1.6235\n",
      "[iter 15] loss=-0.8507 val_loss=-0.6674 scale=2.0000 norm=1.5735\n",
      "[iter 16] loss=-0.8818 val_loss=-0.6968 scale=2.0000 norm=1.5270\n",
      "[iter 17] loss=-0.9112 val_loss=-0.7257 scale=2.0000 norm=1.4855\n",
      "[iter 18] loss=-0.9397 val_loss=-0.7539 scale=2.0000 norm=1.4478\n",
      "[iter 19] loss=-0.9678 val_loss=-0.7813 scale=2.0000 norm=1.4129\n",
      "[iter 20] loss=-0.9953 val_loss=-0.8079 scale=2.0000 norm=1.3806\n",
      "[iter 21] loss=-1.0218 val_loss=-0.8340 scale=2.0000 norm=1.3519\n",
      "[iter 22] loss=-1.0481 val_loss=-0.8593 scale=2.0000 norm=1.3252\n",
      "[iter 23] loss=-1.0740 val_loss=-0.8841 scale=2.0000 norm=1.3006\n",
      "[iter 24] loss=-1.0991 val_loss=-0.9085 scale=2.0000 norm=1.2787\n",
      "[iter 25] loss=-1.1239 val_loss=-0.9326 scale=2.0000 norm=1.2586\n",
      "[iter 26] loss=-1.1485 val_loss=-0.9559 scale=2.0000 norm=1.2399\n",
      "[iter 27] loss=-1.1725 val_loss=-0.9795 scale=2.0000 norm=1.2231\n",
      "[iter 28] loss=-1.1964 val_loss=-1.0021 scale=2.0000 norm=1.2074\n",
      "[iter 29] loss=-1.2197 val_loss=-1.0243 scale=2.0000 norm=1.1932\n",
      "[iter 30] loss=-1.2426 val_loss=-1.0466 scale=2.0000 norm=1.1803\n",
      "[iter 31] loss=-1.2655 val_loss=-1.0685 scale=2.0000 norm=1.1681\n",
      "[iter 32] loss=-1.2877 val_loss=-1.0897 scale=2.0000 norm=1.1572\n",
      "[iter 33] loss=-1.3097 val_loss=-1.1107 scale=2.0000 norm=1.1471\n",
      "[iter 34] loss=-1.3313 val_loss=-1.1311 scale=2.0000 norm=1.1378\n",
      "[iter 35] loss=-1.3525 val_loss=-1.1513 scale=2.0000 norm=1.1294\n",
      "[iter 36] loss=-1.3734 val_loss=-1.1712 scale=2.0000 norm=1.1215\n",
      "[iter 37] loss=-1.3939 val_loss=-1.1907 scale=2.0000 norm=1.1143\n",
      "[iter 38] loss=-1.4140 val_loss=-1.2095 scale=2.0000 norm=1.1077\n",
      "[iter 39] loss=-1.4336 val_loss=-1.2281 scale=2.0000 norm=1.1016\n",
      "[iter 40] loss=-1.4530 val_loss=-1.2464 scale=2.0000 norm=1.0958\n",
      "[iter 41] loss=-1.4719 val_loss=-1.2640 scale=2.0000 norm=1.0907\n",
      "[iter 42] loss=-1.4905 val_loss=-1.2812 scale=2.0000 norm=1.0859\n",
      "[iter 43] loss=-1.5086 val_loss=-1.2980 scale=2.0000 norm=1.0816\n",
      "[iter 44] loss=-1.5262 val_loss=-1.3145 scale=2.0000 norm=1.0776\n",
      "[iter 45] loss=-1.5435 val_loss=-1.3306 scale=2.0000 norm=1.0739\n",
      "[iter 46] loss=-1.5604 val_loss=-1.3463 scale=2.0000 norm=1.0704\n",
      "[iter 47] loss=-1.5768 val_loss=-1.3615 scale=2.0000 norm=1.0673\n",
      "[iter 48] loss=-1.5930 val_loss=-1.3762 scale=2.0000 norm=1.0644\n",
      "[iter 49] loss=-1.6086 val_loss=-1.3907 scale=2.0000 norm=1.0619\n",
      "[iter 50] loss=-1.6238 val_loss=-1.4048 scale=2.0000 norm=1.0595\n",
      "[iter 51] loss=-1.6386 val_loss=-1.4184 scale=2.0000 norm=1.0575\n",
      "[iter 52] loss=-1.6531 val_loss=-1.4316 scale=2.0000 norm=1.0557\n",
      "[iter 53] loss=-1.6672 val_loss=-1.4442 scale=2.0000 norm=1.0541\n",
      "[iter 54] loss=-1.6809 val_loss=-1.4563 scale=2.0000 norm=1.0525\n",
      "[iter 55] loss=-1.6941 val_loss=-1.4682 scale=2.0000 norm=1.0514\n",
      "[iter 56] loss=-1.7069 val_loss=-1.4800 scale=2.0000 norm=1.0504\n",
      "[iter 57] loss=-1.7194 val_loss=-1.4911 scale=2.0000 norm=1.0496\n",
      "[iter 58] loss=-1.7314 val_loss=-1.5022 scale=2.0000 norm=1.0490\n",
      "[iter 59] loss=-1.7432 val_loss=-1.5128 scale=2.0000 norm=1.0484\n",
      "[iter 60] loss=-1.7544 val_loss=-1.5231 scale=2.0000 norm=1.0483\n",
      "[iter 61] loss=-1.7653 val_loss=-1.5325 scale=2.0000 norm=1.0482\n",
      "[iter 62] loss=-1.7758 val_loss=-1.5421 scale=2.0000 norm=1.0484\n",
      "[iter 63] loss=-1.7859 val_loss=-1.5511 scale=2.0000 norm=1.0487\n",
      "[iter 64] loss=-1.7957 val_loss=-1.5599 scale=2.0000 norm=1.0491\n",
      "[iter 65] loss=-1.8051 val_loss=-1.5683 scale=2.0000 norm=1.0496\n",
      "[iter 66] loss=-1.8143 val_loss=-1.5761 scale=2.0000 norm=1.0501\n",
      "[iter 67] loss=-1.8230 val_loss=-1.5838 scale=2.0000 norm=1.0510\n",
      "[iter 68] loss=-1.8314 val_loss=-1.5909 scale=2.0000 norm=1.0521\n",
      "[iter 69] loss=-1.8395 val_loss=-1.5982 scale=2.0000 norm=1.0532\n",
      "[iter 70] loss=-1.8473 val_loss=-1.6049 scale=2.0000 norm=1.0543\n",
      "[iter 71] loss=-1.8547 val_loss=-1.6117 scale=2.0000 norm=1.0556\n",
      "[iter 72] loss=-1.8619 val_loss=-1.6181 scale=2.0000 norm=1.0570\n",
      "[iter 73] loss=-1.8687 val_loss=-1.6242 scale=2.0000 norm=1.0585\n",
      "[iter 74] loss=-1.8753 val_loss=-1.6297 scale=2.0000 norm=1.0601\n",
      "[iter 75] loss=-1.8815 val_loss=-1.6353 scale=2.0000 norm=1.0618\n",
      "[iter 76] loss=-1.8876 val_loss=-1.6403 scale=2.0000 norm=1.0636\n",
      "[iter 77] loss=-1.8933 val_loss=-1.6451 scale=2.0000 norm=1.0655\n",
      "[iter 78] loss=-1.8988 val_loss=-1.6496 scale=2.0000 norm=1.0674\n",
      "[iter 79] loss=-1.9040 val_loss=-1.6540 scale=2.0000 norm=1.0693\n",
      "[iter 80] loss=-1.9091 val_loss=-1.6578 scale=2.0000 norm=1.0713\n",
      "[iter 81] loss=-1.9138 val_loss=-1.6621 scale=2.0000 norm=1.0733\n",
      "[iter 82] loss=-1.9184 val_loss=-1.6656 scale=2.0000 norm=1.0753\n",
      "[iter 83] loss=-1.9227 val_loss=-1.6691 scale=2.0000 norm=1.0775\n",
      "[iter 84] loss=-1.9268 val_loss=-1.6728 scale=2.0000 norm=1.0796\n",
      "[iter 85] loss=-1.9309 val_loss=-1.6757 scale=2.0000 norm=1.0817\n",
      "[iter 86] loss=-1.9346 val_loss=-1.6789 scale=2.0000 norm=1.0839\n",
      "[iter 87] loss=-1.9382 val_loss=-1.6816 scale=2.0000 norm=1.0860\n",
      "[iter 88] loss=-1.9416 val_loss=-1.6841 scale=2.0000 norm=1.0881\n",
      "[iter 89] loss=-1.9449 val_loss=-1.6869 scale=2.0000 norm=1.0904\n",
      "[iter 90] loss=-1.9481 val_loss=-1.6895 scale=2.0000 norm=1.0924\n",
      "[iter 91] loss=-1.9511 val_loss=-1.6914 scale=2.0000 norm=1.0945\n",
      "[iter 92] loss=-1.9538 val_loss=-1.6937 scale=2.0000 norm=1.0968\n",
      "[iter 93] loss=-1.9564 val_loss=-1.6956 scale=2.0000 norm=1.0990\n",
      "[iter 94] loss=-1.9589 val_loss=-1.6970 scale=2.0000 norm=1.1012\n",
      "[iter 95] loss=-1.9611 val_loss=-1.6987 scale=2.0000 norm=1.1034\n",
      "[iter 96] loss=-1.9633 val_loss=-1.7003 scale=2.0000 norm=1.1056\n",
      "[iter 97] loss=-1.9655 val_loss=-1.7014 scale=2.0000 norm=1.1078\n",
      "[iter 98] loss=-1.9674 val_loss=-1.7032 scale=2.0000 norm=1.1098\n",
      "[iter 99] loss=-1.9695 val_loss=-1.7043 scale=2.0000 norm=1.1117\n",
      "Expected 12 Excel files, but found 8 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2397 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2365 scale=1.0000 norm=1.5731\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6121\n",
      "[iter 55] loss=0.2148 val_loss=0.2305 scale=1.0000 norm=1.6527\n",
      "[iter 56] loss=0.2121 val_loss=0.2277 scale=1.0000 norm=1.6943\n",
      "[iter 57] loss=0.2096 val_loss=0.2251 scale=1.0000 norm=1.7379\n",
      "[iter 58] loss=0.2072 val_loss=0.2225 scale=1.0000 norm=1.7827\n",
      "[iter 59] loss=0.2049 val_loss=0.2202 scale=1.0000 norm=1.8285\n",
      "[iter 60] loss=0.2027 val_loss=0.2179 scale=1.0000 norm=1.8758\n",
      "[iter 61] loss=0.2006 val_loss=0.2157 scale=1.0000 norm=1.9236\n",
      "[iter 62] loss=0.1987 val_loss=0.2136 scale=1.0000 norm=1.9726\n",
      "[iter 63] loss=0.1968 val_loss=0.2117 scale=1.0000 norm=2.0222\n",
      "[iter 64] loss=0.1950 val_loss=0.2097 scale=1.0000 norm=2.0716\n",
      "[iter 65] loss=0.1934 val_loss=0.2079 scale=1.0000 norm=2.1198\n",
      "[iter 66] loss=0.1918 val_loss=0.2062 scale=1.0000 norm=2.1685\n",
      "[iter 67] loss=0.1903 val_loss=0.2045 scale=1.0000 norm=2.2166\n",
      "[iter 68] loss=0.1888 val_loss=0.2030 scale=1.0000 norm=2.2621\n",
      "[iter 69] loss=0.1874 val_loss=0.2016 scale=1.0000 norm=2.3092\n",
      "[iter 70] loss=0.1861 val_loss=0.2002 scale=1.0000 norm=2.3542\n",
      "[iter 71] loss=0.1849 val_loss=0.1988 scale=1.0000 norm=2.4003\n",
      "[iter 72] loss=0.1837 val_loss=0.1975 scale=1.0000 norm=2.4434\n",
      "[iter 73] loss=0.1826 val_loss=0.1964 scale=1.0000 norm=2.4850\n",
      "[iter 74] loss=0.1816 val_loss=0.1953 scale=1.0000 norm=2.5247\n",
      "[iter 75] loss=0.1806 val_loss=0.1942 scale=1.0000 norm=2.5634\n",
      "[iter 76] loss=0.1796 val_loss=0.1931 scale=1.0000 norm=2.6012\n",
      "[iter 77] loss=0.1787 val_loss=0.1921 scale=1.0000 norm=2.6392\n",
      "[iter 78] loss=0.1778 val_loss=0.1912 scale=1.0000 norm=2.6753\n",
      "[iter 79] loss=0.1770 val_loss=0.1908 scale=0.5000 norm=1.3554\n",
      "[iter 80] loss=0.1766 val_loss=0.1904 scale=0.5000 norm=1.3637\n",
      "[iter 81] loss=0.1762 val_loss=0.1896 scale=1.0000 norm=2.7448\n",
      "[iter 82] loss=0.1755 val_loss=0.1892 scale=0.5000 norm=1.3885\n",
      "[iter 83] loss=0.1752 val_loss=0.1885 scale=1.0000 norm=2.7917\n",
      "[iter 84] loss=0.1745 val_loss=0.1881 scale=0.5000 norm=1.4103\n",
      "[iter 85] loss=0.1741 val_loss=0.1874 scale=1.0000 norm=2.8352\n",
      "[iter 86] loss=0.1735 val_loss=0.1871 scale=0.5000 norm=1.4310\n",
      "[iter 87] loss=0.1732 val_loss=0.1868 scale=0.5000 norm=1.4379\n",
      "[iter 88] loss=0.1729 val_loss=0.1865 scale=0.5000 norm=1.4448\n",
      "[iter 89] loss=0.1726 val_loss=0.1859 scale=1.0000 norm=2.9025\n",
      "[iter 90] loss=0.1721 val_loss=0.1856 scale=0.5000 norm=1.4639\n",
      "[iter 91] loss=0.1718 val_loss=0.1852 scale=1.0000 norm=2.9406\n",
      "[iter 92] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4827\n",
      "[iter 93] loss=0.1711 val_loss=0.1848 scale=0.5000 norm=1.4891\n",
      "[iter 94] loss=0.1709 val_loss=0.1845 scale=0.5000 norm=1.4961\n",
      "[iter 95] loss=0.1706 val_loss=0.1844 scale=0.5000 norm=1.5023\n",
      "[iter 96] loss=0.1704 val_loss=0.1839 scale=1.0000 norm=3.0181\n",
      "[iter 97] loss=0.1700 val_loss=0.1837 scale=1.0000 norm=3.0428\n",
      "[iter 98] loss=0.1696 val_loss=0.1835 scale=0.5000 norm=1.5336\n",
      "[iter 99] loss=0.1695 val_loss=0.1834 scale=0.5000 norm=1.5405\n",
      "Expected 12 Excel files, but found 9 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3056 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5283 val_loss=-0.3417 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=-0.5638 val_loss=-0.3725 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=-0.5939 val_loss=-0.4014 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=-0.6217 val_loss=-0.4271 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=-0.6465 val_loss=-0.4512 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=-0.6699 val_loss=-0.4735 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=-0.6915 val_loss=-0.4946 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5336 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=-0.7501 val_loss=-0.5700 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=-0.7856 val_loss=-0.5871 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=-0.8025 val_loss=-0.6209 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=-0.8358 val_loss=-0.6521 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=-0.8668 val_loss=-0.6821 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=-0.8967 val_loss=-0.7114 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=-0.9259 val_loss=-0.7397 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=-0.9540 val_loss=-0.7674 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=-0.9816 val_loss=-0.7945 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=-1.0087 val_loss=-0.8209 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=-1.0353 val_loss=-0.8466 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=-1.0612 val_loss=-0.8716 scale=2.0000 norm=1.3122\n",
      "[iter 22] loss=-1.0866 val_loss=-0.8961 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=-1.1117 val_loss=-0.9207 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=-1.1367 val_loss=-0.9446 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=-1.1610 val_loss=-0.9681 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=-1.1848 val_loss=-0.9910 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=-1.2083 val_loss=-1.0135 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=-1.2315 val_loss=-1.0355 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=-1.2543 val_loss=-1.0576 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=-1.2769 val_loss=-1.0790 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=-1.2988 val_loss=-1.1003 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=-1.3206 val_loss=-1.1211 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=-1.3419 val_loss=-1.1416 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=-1.3630 val_loss=-1.1615 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=-1.3837 val_loss=-1.1812 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=-1.4040 val_loss=-1.2005 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=-1.4240 val_loss=-1.2194 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=-1.4435 val_loss=-1.2379 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=-1.4628 val_loss=-1.2558 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=-1.4814 val_loss=-1.2733 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=-1.4997 val_loss=-1.2904 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=-1.5176 val_loss=-1.3072 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=-1.5351 val_loss=-1.3235 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=-1.5522 val_loss=-1.3393 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=-1.5688 val_loss=-1.3549 scale=2.0000 norm=1.0687\n",
      "[iter 46] loss=-1.5851 val_loss=-1.3699 scale=2.0000 norm=1.0657\n",
      "[iter 47] loss=-1.6009 val_loss=-1.3845 scale=2.0000 norm=1.0631\n",
      "[iter 48] loss=-1.6164 val_loss=-1.3988 scale=2.0000 norm=1.0606\n",
      "[iter 49] loss=-1.6314 val_loss=-1.4126 scale=2.0000 norm=1.0584\n",
      "[iter 50] loss=-1.6461 val_loss=-1.4261 scale=2.0000 norm=1.0565\n",
      "[iter 51] loss=-1.6603 val_loss=-1.4391 scale=2.0000 norm=1.0548\n",
      "[iter 52] loss=-1.6741 val_loss=-1.4515 scale=2.0000 norm=1.0533\n",
      "[iter 53] loss=-1.6876 val_loss=-1.4636 scale=2.0000 norm=1.0518\n",
      "[iter 54] loss=-1.7007 val_loss=-1.4755 scale=2.0000 norm=1.0508\n",
      "[iter 55] loss=-1.7134 val_loss=-1.4868 scale=2.0000 norm=1.0498\n",
      "[iter 56] loss=-1.7257 val_loss=-1.4979 scale=2.0000 norm=1.0491\n",
      "[iter 57] loss=-1.7375 val_loss=-1.5086 scale=2.0000 norm=1.0486\n",
      "[iter 58] loss=-1.7489 val_loss=-1.5189 scale=2.0000 norm=1.0483\n",
      "[iter 59] loss=-1.7600 val_loss=-1.5285 scale=2.0000 norm=1.0481\n",
      "[iter 60] loss=-1.7707 val_loss=-1.5381 scale=2.0000 norm=1.0482\n",
      "[iter 61] loss=-1.7810 val_loss=-1.5473 scale=2.0000 norm=1.0484\n",
      "[iter 62] loss=-1.7910 val_loss=-1.5562 scale=2.0000 norm=1.0487\n",
      "[iter 63] loss=-1.8005 val_loss=-1.5648 scale=2.0000 norm=1.0492\n",
      "[iter 64] loss=-1.8098 val_loss=-1.5732 scale=2.0000 norm=1.0499\n",
      "[iter 65] loss=-1.8187 val_loss=-1.5813 scale=2.0000 norm=1.0507\n",
      "[iter 66] loss=-1.8273 val_loss=-1.5891 scale=2.0000 norm=1.0515\n",
      "[iter 67] loss=-1.8357 val_loss=-1.5967 scale=2.0000 norm=1.0524\n",
      "[iter 68] loss=-1.8436 val_loss=-1.6034 scale=2.0000 norm=1.0534\n",
      "[iter 69] loss=-1.8512 val_loss=-1.6101 scale=2.0000 norm=1.0548\n",
      "[iter 70] loss=-1.8585 val_loss=-1.6161 scale=2.0000 norm=1.0562\n",
      "[iter 71] loss=-1.8655 val_loss=-1.6221 scale=2.0000 norm=1.0577\n",
      "[iter 72] loss=-1.8722 val_loss=-1.6280 scale=2.0000 norm=1.0593\n",
      "[iter 73] loss=-1.8786 val_loss=-1.6334 scale=2.0000 norm=1.0609\n",
      "[iter 74] loss=-1.8848 val_loss=-1.6387 scale=2.0000 norm=1.0626\n",
      "[iter 75] loss=-1.8907 val_loss=-1.6436 scale=2.0000 norm=1.0644\n",
      "[iter 76] loss=-1.8963 val_loss=-1.6488 scale=2.0000 norm=1.0665\n",
      "[iter 77] loss=-1.9017 val_loss=-1.6531 scale=2.0000 norm=1.0684\n",
      "[iter 78] loss=-1.9067 val_loss=-1.6572 scale=2.0000 norm=1.0704\n",
      "[iter 79] loss=-1.9116 val_loss=-1.6613 scale=2.0000 norm=1.0724\n",
      "[iter 80] loss=-1.9163 val_loss=-1.6651 scale=2.0000 norm=1.0744\n",
      "[iter 81] loss=-1.9208 val_loss=-1.6686 scale=2.0000 norm=1.0764\n",
      "[iter 82] loss=-1.9250 val_loss=-1.6724 scale=2.0000 norm=1.0786\n",
      "[iter 83] loss=-1.9292 val_loss=-1.6753 scale=2.0000 norm=1.0806\n",
      "[iter 84] loss=-1.9330 val_loss=-1.6782 scale=2.0000 norm=1.0827\n",
      "[iter 85] loss=-1.9365 val_loss=-1.6813 scale=2.0000 norm=1.0849\n",
      "[iter 86] loss=-1.9401 val_loss=-1.6840 scale=2.0000 norm=1.0869\n",
      "[iter 87] loss=-1.9434 val_loss=-1.6867 scale=2.0000 norm=1.0891\n",
      "[iter 88] loss=-1.9465 val_loss=-1.6892 scale=2.0000 norm=1.0913\n",
      "[iter 89] loss=-1.9496 val_loss=-1.6913 scale=2.0000 norm=1.0934\n",
      "[iter 90] loss=-1.9525 val_loss=-1.6933 scale=2.0000 norm=1.0956\n",
      "[iter 91] loss=-1.9552 val_loss=-1.6953 scale=2.0000 norm=1.0978\n",
      "[iter 92] loss=-1.9577 val_loss=-1.6966 scale=2.0000 norm=1.1000\n",
      "[iter 93] loss=-1.9602 val_loss=-1.6983 scale=2.0000 norm=1.1020\n",
      "[iter 94] loss=-1.9624 val_loss=-1.7003 scale=2.0000 norm=1.1041\n",
      "[iter 95] loss=-1.9648 val_loss=-1.7018 scale=2.0000 norm=1.1062\n",
      "[iter 96] loss=-1.9668 val_loss=-1.7032 scale=2.0000 norm=1.1084\n",
      "[iter 97] loss=-1.9687 val_loss=-1.7041 scale=2.0000 norm=1.1104\n",
      "[iter 98] loss=-1.9706 val_loss=-1.7055 scale=2.0000 norm=1.1124\n",
      "[iter 99] loss=-1.9725 val_loss=-1.7069 scale=2.0000 norm=1.1144\n",
      "Expected 12 Excel files, but found 10 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2398 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2366 scale=1.0000 norm=1.5728\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6117\n",
      "[iter 55] loss=0.2148 val_loss=0.2306 scale=1.0000 norm=1.6521\n",
      "[iter 56] loss=0.2121 val_loss=0.2279 scale=1.0000 norm=1.6938\n",
      "[iter 57] loss=0.2095 val_loss=0.2252 scale=1.0000 norm=1.7368\n",
      "[iter 58] loss=0.2071 val_loss=0.2226 scale=1.0000 norm=1.7815\n",
      "[iter 59] loss=0.2048 val_loss=0.2202 scale=1.0000 norm=1.8280\n",
      "[iter 60] loss=0.2025 val_loss=0.2179 scale=1.0000 norm=1.8747\n",
      "[iter 61] loss=0.2005 val_loss=0.2157 scale=1.0000 norm=1.9225\n",
      "[iter 62] loss=0.1985 val_loss=0.2136 scale=1.0000 norm=1.9715\n",
      "[iter 63] loss=0.1966 val_loss=0.2116 scale=1.0000 norm=2.0201\n",
      "[iter 64] loss=0.1948 val_loss=0.2097 scale=1.0000 norm=2.0695\n",
      "[iter 65] loss=0.1931 val_loss=0.2079 scale=1.0000 norm=2.1185\n",
      "[iter 66] loss=0.1915 val_loss=0.2061 scale=1.0000 norm=2.1670\n",
      "[iter 67] loss=0.1899 val_loss=0.2045 scale=1.0000 norm=2.2159\n",
      "[iter 68] loss=0.1885 val_loss=0.2029 scale=1.0000 norm=2.2634\n",
      "[iter 69] loss=0.1871 val_loss=0.2015 scale=1.0000 norm=2.3105\n",
      "[iter 70] loss=0.1858 val_loss=0.2000 scale=1.0000 norm=2.3566\n",
      "[iter 71] loss=0.1845 val_loss=0.1986 scale=1.0000 norm=2.4010\n",
      "[iter 72] loss=0.1833 val_loss=0.1972 scale=1.0000 norm=2.4445\n",
      "[iter 73] loss=0.1822 val_loss=0.1961 scale=1.0000 norm=2.4863\n",
      "[iter 74] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5263\n",
      "[iter 75] loss=0.1801 val_loss=0.1939 scale=1.0000 norm=2.5651\n",
      "[iter 76] loss=0.1791 val_loss=0.1934 scale=0.5000 norm=1.3018\n",
      "[iter 77] loss=0.1786 val_loss=0.1928 scale=0.5000 norm=1.3107\n",
      "[iter 78] loss=0.1781 val_loss=0.1919 scale=1.0000 norm=2.6394\n",
      "[iter 79] loss=0.1773 val_loss=0.1914 scale=0.5000 norm=1.3388\n",
      "[iter 80] loss=0.1768 val_loss=0.1904 scale=1.0000 norm=2.6951\n",
      "[iter 81] loss=0.1760 val_loss=0.1899 scale=0.5000 norm=1.3646\n",
      "[iter 82] loss=0.1756 val_loss=0.1895 scale=0.5000 norm=1.3732\n",
      "[iter 83] loss=0.1752 val_loss=0.1887 scale=1.0000 norm=2.7620\n",
      "[iter 84] loss=0.1745 val_loss=0.1884 scale=0.5000 norm=1.3976\n",
      "[iter 85] loss=0.1742 val_loss=0.1880 scale=0.5000 norm=1.4048\n",
      "[iter 86] loss=0.1738 val_loss=0.1877 scale=0.5000 norm=1.4127\n",
      "[iter 87] loss=0.1735 val_loss=0.1873 scale=0.5000 norm=1.4203\n",
      "[iter 88] loss=0.1732 val_loss=0.1870 scale=0.5000 norm=1.4272\n",
      "[iter 89] loss=0.1729 val_loss=0.1866 scale=0.5000 norm=1.4342\n",
      "[iter 90] loss=0.1726 val_loss=0.1863 scale=0.5000 norm=1.4411\n",
      "[iter 91] loss=0.1723 val_loss=0.1860 scale=0.5000 norm=1.4474\n",
      "[iter 92] loss=0.1720 val_loss=0.1857 scale=0.5000 norm=1.4536\n",
      "[iter 93] loss=0.1717 val_loss=0.1851 scale=1.0000 norm=2.9208\n",
      "[iter 94] loss=0.1711 val_loss=0.1849 scale=0.5000 norm=1.4734\n",
      "[iter 95] loss=0.1709 val_loss=0.1847 scale=0.5000 norm=1.4792\n",
      "[iter 96] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=2.9721\n",
      "[iter 97] loss=0.1701 val_loss=0.1840 scale=0.5000 norm=1.4982\n",
      "[iter 98] loss=0.1699 val_loss=0.1838 scale=0.5000 norm=1.5045\n",
      "[iter 99] loss=0.1697 val_loss=0.1836 scale=0.5000 norm=1.5113\n",
      "Expected 12 Excel files, but found 11 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3056 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5283 val_loss=-0.3417 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=-0.5638 val_loss=-0.3725 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=-0.5939 val_loss=-0.4014 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=-0.6217 val_loss=-0.4271 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=-0.6465 val_loss=-0.4512 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=-0.6699 val_loss=-0.4735 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=-0.6915 val_loss=-0.4946 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5336 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=-0.7501 val_loss=-0.5700 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=-0.7856 val_loss=-0.5871 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=-0.8025 val_loss=-0.6209 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=-0.8358 val_loss=-0.6521 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=-0.8668 val_loss=-0.6821 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=-0.8967 val_loss=-0.7114 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=-0.9259 val_loss=-0.7397 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=-0.9540 val_loss=-0.7674 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=-0.9816 val_loss=-0.7945 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=-1.0087 val_loss=-0.8209 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=-1.0353 val_loss=-0.8466 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=-1.0612 val_loss=-0.8716 scale=2.0000 norm=1.3122\n",
      "[iter 22] loss=-1.0866 val_loss=-0.8961 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=-1.1117 val_loss=-0.9207 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=-1.1367 val_loss=-0.9446 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=-1.1610 val_loss=-0.9681 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=-1.1848 val_loss=-0.9910 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=-1.2083 val_loss=-1.0135 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=-1.2315 val_loss=-1.0355 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=-1.2543 val_loss=-1.0576 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=-1.2769 val_loss=-1.0790 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=-1.2988 val_loss=-1.1003 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=-1.3206 val_loss=-1.1211 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=-1.3419 val_loss=-1.1416 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=-1.3630 val_loss=-1.1615 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=-1.3837 val_loss=-1.1812 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=-1.4040 val_loss=-1.2005 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=-1.4240 val_loss=-1.2194 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=-1.4435 val_loss=-1.2379 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=-1.4628 val_loss=-1.2558 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=-1.4814 val_loss=-1.2733 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=-1.4997 val_loss=-1.2904 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=-1.5176 val_loss=-1.3072 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=-1.5351 val_loss=-1.3235 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=-1.5522 val_loss=-1.3393 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=-1.5689 val_loss=-1.3550 scale=2.0000 norm=1.0686\n",
      "[iter 46] loss=-1.5853 val_loss=-1.3699 scale=2.0000 norm=1.0656\n",
      "[iter 47] loss=-1.6011 val_loss=-1.3846 scale=2.0000 norm=1.0629\n",
      "[iter 48] loss=-1.6167 val_loss=-1.3989 scale=2.0000 norm=1.0604\n",
      "[iter 49] loss=-1.6318 val_loss=-1.4126 scale=2.0000 norm=1.0582\n",
      "[iter 50] loss=-1.6465 val_loss=-1.4263 scale=2.0000 norm=1.0562\n",
      "[iter 51] loss=-1.6608 val_loss=-1.4391 scale=2.0000 norm=1.0543\n",
      "[iter 52] loss=-1.6747 val_loss=-1.4518 scale=2.0000 norm=1.0526\n",
      "[iter 53] loss=-1.6883 val_loss=-1.4642 scale=2.0000 norm=1.0513\n",
      "[iter 54] loss=-1.7015 val_loss=-1.4760 scale=2.0000 norm=1.0501\n",
      "[iter 55] loss=-1.7142 val_loss=-1.4876 scale=2.0000 norm=1.0490\n",
      "[iter 56] loss=-1.7265 val_loss=-1.4985 scale=2.0000 norm=1.0482\n",
      "[iter 57] loss=-1.7384 val_loss=-1.5095 scale=2.0000 norm=1.0477\n",
      "[iter 58] loss=-1.7501 val_loss=-1.5198 scale=2.0000 norm=1.0471\n",
      "[iter 59] loss=-1.7613 val_loss=-1.5300 scale=2.0000 norm=1.0469\n",
      "[iter 60] loss=-1.7722 val_loss=-1.5397 scale=2.0000 norm=1.0467\n",
      "[iter 61] loss=-1.7826 val_loss=-1.5491 scale=2.0000 norm=1.0468\n",
      "[iter 62] loss=-1.7928 val_loss=-1.5582 scale=2.0000 norm=1.0470\n",
      "[iter 63] loss=-1.8025 val_loss=-1.5667 scale=2.0000 norm=1.0474\n",
      "[iter 64] loss=-1.8119 val_loss=-1.5748 scale=2.0000 norm=1.0481\n",
      "[iter 65] loss=-1.8209 val_loss=-1.5826 scale=2.0000 norm=1.0487\n",
      "[iter 66] loss=-1.8296 val_loss=-1.5906 scale=2.0000 norm=1.0496\n",
      "[iter 67] loss=-1.8380 val_loss=-1.5980 scale=2.0000 norm=1.0503\n",
      "[iter 68] loss=-1.8460 val_loss=-1.6052 scale=2.0000 norm=1.0512\n",
      "[iter 69] loss=-1.8538 val_loss=-1.6119 scale=2.0000 norm=1.0525\n",
      "[iter 70] loss=-1.8612 val_loss=-1.6187 scale=2.0000 norm=1.0537\n",
      "[iter 71] loss=-1.8684 val_loss=-1.6248 scale=2.0000 norm=1.0550\n",
      "[iter 72] loss=-1.8752 val_loss=-1.6307 scale=2.0000 norm=1.0563\n",
      "[iter 73] loss=-1.8818 val_loss=-1.6363 scale=2.0000 norm=1.0579\n",
      "[iter 74] loss=-1.8881 val_loss=-1.6415 scale=2.0000 norm=1.0595\n",
      "[iter 75] loss=-1.8941 val_loss=-1.6459 scale=2.0000 norm=1.0612\n",
      "[iter 76] loss=-1.8997 val_loss=-1.6510 scale=2.0000 norm=1.0629\n",
      "[iter 77] loss=-1.9052 val_loss=-1.6560 scale=2.0000 norm=1.0648\n",
      "[iter 78] loss=-1.9106 val_loss=-1.6600 scale=2.0000 norm=1.0667\n",
      "[iter 79] loss=-1.9155 val_loss=-1.6640 scale=2.0000 norm=1.0687\n",
      "[iter 80] loss=-1.9202 val_loss=-1.6686 scale=2.0000 norm=1.0707\n",
      "[iter 81] loss=-1.9250 val_loss=-1.6720 scale=2.0000 norm=1.0727\n",
      "[iter 82] loss=-1.9293 val_loss=-1.6751 scale=2.0000 norm=1.0748\n",
      "[iter 83] loss=-1.9333 val_loss=-1.6785 scale=2.0000 norm=1.0769\n",
      "[iter 84] loss=-1.9373 val_loss=-1.6813 scale=2.0000 norm=1.0790\n",
      "[iter 85] loss=-1.9409 val_loss=-1.6843 scale=2.0000 norm=1.0812\n",
      "[iter 86] loss=-1.9444 val_loss=-1.6871 scale=2.0000 norm=1.0834\n",
      "[iter 87] loss=-1.9478 val_loss=-1.6898 scale=2.0000 norm=1.0856\n",
      "[iter 88] loss=-1.9510 val_loss=-1.6926 scale=2.0000 norm=1.0878\n",
      "[iter 89] loss=-1.9542 val_loss=-1.6949 scale=2.0000 norm=1.0897\n",
      "[iter 90] loss=-1.9572 val_loss=-1.6964 scale=2.0000 norm=1.0919\n",
      "[iter 91] loss=-1.9599 val_loss=-1.6984 scale=2.0000 norm=1.0939\n",
      "[iter 92] loss=-1.9625 val_loss=-1.6999 scale=2.0000 norm=1.0962\n",
      "[iter 93] loss=-1.9650 val_loss=-1.7017 scale=2.0000 norm=1.0983\n",
      "[iter 94] loss=-1.9673 val_loss=-1.7031 scale=2.0000 norm=1.1005\n",
      "[iter 95] loss=-1.9695 val_loss=-1.7055 scale=2.0000 norm=1.1025\n",
      "[iter 96] loss=-1.9720 val_loss=-1.7066 scale=2.0000 norm=1.1044\n",
      "[iter 97] loss=-1.9739 val_loss=-1.7080 scale=2.0000 norm=1.1064\n",
      "[iter 98] loss=-1.9759 val_loss=-1.7085 scale=2.0000 norm=1.1084\n",
      "[iter 99] loss=-1.9776 val_loss=-1.7098 scale=2.0000 norm=1.1104\n",
      "Merge completed! The final file is 'Merged_Sheet.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_model(entsoe, case=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6806 scale=2.0000 norm=2.2332\n",
      "[iter 1] loss=0.6374 val_loss=0.6721 scale=2.0000 norm=2.2169\n",
      "[iter 2] loss=0.6306 val_loss=0.6645 scale=2.0000 norm=2.2040\n",
      "[iter 3] loss=0.6245 val_loss=0.6577 scale=2.0000 norm=2.1939\n",
      "[iter 4] loss=0.6189 val_loss=0.6515 scale=2.0000 norm=2.1860\n",
      "[iter 5] loss=0.6139 val_loss=0.6459 scale=2.0000 norm=2.1802\n",
      "[iter 6] loss=0.6094 val_loss=0.6409 scale=2.0000 norm=2.1761\n",
      "[iter 7] loss=0.6052 val_loss=0.6363 scale=2.0000 norm=2.1736\n",
      "[iter 8] loss=0.6015 val_loss=0.6321 scale=2.0000 norm=2.1724\n",
      "[iter 9] loss=0.5981 val_loss=0.6283 scale=2.0000 norm=2.1723\n",
      "[iter 10] loss=0.5950 val_loss=0.6248 scale=2.0000 norm=2.1732\n",
      "[iter 11] loss=0.5922 val_loss=0.6218 scale=2.0000 norm=2.1750\n",
      "[iter 12] loss=0.5896 val_loss=0.6189 scale=2.0000 norm=2.1776\n",
      "[iter 13] loss=0.5872 val_loss=0.6163 scale=2.0000 norm=2.1807\n",
      "[iter 14] loss=0.5851 val_loss=0.6139 scale=2.0000 norm=2.1844\n",
      "[iter 15] loss=0.5831 val_loss=0.6118 scale=2.0000 norm=2.1885\n",
      "[iter 16] loss=0.5813 val_loss=0.6097 scale=2.0000 norm=2.1931\n",
      "[iter 17] loss=0.5797 val_loss=0.6079 scale=2.0000 norm=2.1980\n",
      "[iter 18] loss=0.5782 val_loss=0.6062 scale=2.0000 norm=2.2032\n",
      "[iter 19] loss=0.5768 val_loss=0.6047 scale=2.0000 norm=2.2087\n",
      "[iter 20] loss=0.5755 val_loss=0.6033 scale=2.0000 norm=2.2142\n",
      "[iter 21] loss=0.5743 val_loss=0.6019 scale=2.0000 norm=2.2200\n",
      "[iter 22] loss=0.5732 val_loss=0.6008 scale=2.0000 norm=2.2258\n",
      "[iter 23] loss=0.5722 val_loss=0.5997 scale=2.0000 norm=2.2318\n",
      "[iter 24] loss=0.5713 val_loss=0.5988 scale=2.0000 norm=2.2379\n",
      "[iter 25] loss=0.5705 val_loss=0.5978 scale=2.0000 norm=2.2440\n",
      "[iter 26] loss=0.5697 val_loss=0.5970 scale=2.0000 norm=2.2502\n",
      "[iter 27] loss=0.5690 val_loss=0.5963 scale=2.0000 norm=2.2563\n",
      "[iter 28] loss=0.5683 val_loss=0.5956 scale=2.0000 norm=2.2625\n",
      "[iter 29] loss=0.5677 val_loss=0.5949 scale=2.0000 norm=2.2686\n",
      "[iter 30] loss=0.5671 val_loss=0.5943 scale=2.0000 norm=2.2747\n",
      "[iter 31] loss=0.5666 val_loss=0.5938 scale=2.0000 norm=2.2806\n",
      "[iter 32] loss=0.5661 val_loss=0.5933 scale=2.0000 norm=2.2867\n",
      "[iter 33] loss=0.5656 val_loss=0.5930 scale=1.0000 norm=1.1462\n",
      "[iter 34] loss=0.5654 val_loss=0.5927 scale=2.0000 norm=2.2954\n",
      "[iter 35] loss=0.5650 val_loss=0.5925 scale=1.0000 norm=1.1506\n",
      "[iter 36] loss=0.5648 val_loss=0.5921 scale=2.0000 norm=2.3041\n",
      "[iter 37] loss=0.5644 val_loss=0.5917 scale=2.0000 norm=2.3096\n",
      "[iter 38] loss=0.5641 val_loss=0.5913 scale=2.0000 norm=2.3152\n",
      "[iter 39] loss=0.5637 val_loss=0.5911 scale=2.0000 norm=2.3206\n",
      "[iter 40] loss=0.5635 val_loss=0.5909 scale=2.0000 norm=2.3259\n",
      "[iter 41] loss=0.5632 val_loss=0.5906 scale=2.0000 norm=2.3310\n",
      "[iter 42] loss=0.5630 val_loss=0.5905 scale=1.0000 norm=1.1681\n",
      "[iter 43] loss=0.5628 val_loss=0.5903 scale=2.0000 norm=2.3386\n",
      "[iter 44] loss=0.5626 val_loss=0.5902 scale=1.0000 norm=1.1717\n",
      "[iter 45] loss=0.5625 val_loss=0.5900 scale=2.0000 norm=2.3458\n",
      "[iter 46] loss=0.5623 val_loss=0.5899 scale=1.0000 norm=1.1752\n",
      "[iter 47] loss=0.5622 val_loss=0.5897 scale=2.0000 norm=2.3527\n",
      "[iter 48] loss=0.5620 val_loss=0.5897 scale=1.0000 norm=1.1786\n",
      "[iter 49] loss=0.5620 val_loss=0.5895 scale=2.0000 norm=2.3593\n",
      "[iter 50] loss=0.5618 val_loss=0.5895 scale=1.0000 norm=1.1818\n",
      "[iter 51] loss=0.5617 val_loss=0.5893 scale=2.0000 norm=2.3656\n",
      "[iter 52] loss=0.5616 val_loss=0.5893 scale=1.0000 norm=1.1848\n",
      "[iter 53] loss=0.5615 val_loss=0.5892 scale=1.0000 norm=1.1858\n",
      "[iter 54] loss=0.5615 val_loss=0.5891 scale=1.0000 norm=1.1867\n",
      "[iter 55] loss=0.5614 val_loss=0.5890 scale=2.0000 norm=2.3753\n",
      "[iter 56] loss=0.5613 val_loss=0.5889 scale=1.0000 norm=1.1895\n",
      "[iter 57] loss=0.5612 val_loss=0.5889 scale=1.0000 norm=1.1904\n",
      "[iter 58] loss=0.5612 val_loss=0.5888 scale=2.0000 norm=2.3825\n",
      "[iter 59] loss=0.5610 val_loss=0.5888 scale=1.0000 norm=1.1929\n",
      "[iter 60] loss=0.5610 val_loss=0.5887 scale=1.0000 norm=1.1937\n",
      "[iter 61] loss=0.5609 val_loss=0.5886 scale=2.0000 norm=2.3890\n",
      "[iter 62] loss=0.5608 val_loss=0.5886 scale=1.0000 norm=1.1960\n",
      "[iter 63] loss=0.5608 val_loss=0.5885 scale=2.0000 norm=2.3936\n",
      "[iter 64] loss=0.5607 val_loss=0.5885 scale=2.0000 norm=2.3964\n",
      "[iter 65] loss=0.5606 val_loss=0.5884 scale=1.0000 norm=1.1996\n",
      "[iter 66] loss=0.5606 val_loss=0.5883 scale=2.0000 norm=2.4005\n",
      "[iter 67] loss=0.5605 val_loss=0.5883 scale=1.0000 norm=1.2016\n",
      "[iter 68] loss=0.5604 val_loss=0.5883 scale=2.0000 norm=2.4044\n",
      "[iter 69] loss=0.5604 val_loss=0.5883 scale=2.0000 norm=2.4067\n",
      "[iter 70] loss=0.5603 val_loss=0.5883 scale=2.0000 norm=2.4089\n",
      "[iter 71] loss=0.5602 val_loss=0.5883 scale=1.0000 norm=1.2056\n",
      "[iter 72] loss=0.5602 val_loss=0.5883 scale=1.0000 norm=1.2061\n",
      "[iter 73] loss=0.5602 val_loss=0.5883 scale=2.0000 norm=2.4131\n",
      "[iter 74] loss=0.5601 val_loss=0.5883 scale=1.0000 norm=1.2075\n",
      "[iter 75] loss=0.5601 val_loss=0.5883 scale=1.0000 norm=1.2080\n",
      "[iter 76] loss=0.5600 val_loss=0.5883 scale=1.0000 norm=1.2085\n",
      "[iter 77] loss=0.5600 val_loss=0.5883 scale=2.0000 norm=2.4178\n",
      "[iter 78] loss=0.5600 val_loss=0.5883 scale=1.0000 norm=1.2097\n",
      "[iter 79] loss=0.5599 val_loss=0.5882 scale=2.0000 norm=2.4202\n",
      "[iter 80] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2109\n",
      "[iter 81] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2113\n",
      "[iter 82] loss=0.5599 val_loss=0.5883 scale=1.0000 norm=1.2116\n",
      "[iter 83] loss=0.5598 val_loss=0.5883 scale=2.0000 norm=2.4240\n",
      "[iter 84] loss=0.5598 val_loss=0.5883 scale=1.0000 norm=1.2127\n",
      "[iter 85] loss=0.5598 val_loss=0.5883 scale=2.0000 norm=2.4261\n",
      "[iter 86] loss=0.5597 val_loss=0.5882 scale=1.0000 norm=1.2137\n",
      "[iter 87] loss=0.5597 val_loss=0.5883 scale=2.0000 norm=2.4279\n",
      "[iter 88] loss=0.5597 val_loss=0.5883 scale=1.0000 norm=1.2145\n",
      "[iter 89] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2148\n",
      "[iter 90] loss=0.5596 val_loss=0.5883 scale=2.0000 norm=2.4302\n",
      "[iter 91] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2156\n",
      "[iter 92] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2158\n",
      "[iter 93] loss=0.5596 val_loss=0.5883 scale=1.0000 norm=1.2161\n",
      "[iter 94] loss=0.5596 val_loss=0.5883 scale=2.0000 norm=2.4327\n",
      "[iter 95] loss=0.5595 val_loss=0.5884 scale=2.0000 norm=2.4337\n",
      "[iter 96] loss=0.5595 val_loss=0.5883 scale=2.0000 norm=2.4346\n",
      "[iter 97] loss=0.5595 val_loss=0.5883 scale=1.0000 norm=1.2178\n",
      "[iter 98] loss=0.5595 val_loss=0.5883 scale=1.0000 norm=1.2179\n",
      "[iter 99] loss=0.5594 val_loss=0.5883 scale=1.0000 norm=1.2181\n",
      "Expected 12 Excel files, but found 14 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.2720 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.4935 val_loss=-0.2795 scale=1.0000 norm=1.1022\n",
      "[iter 2] loss=-0.5004 val_loss=-0.2865 scale=1.0000 norm=1.0951\n",
      "[iter 3] loss=-0.5067 val_loss=-0.2931 scale=1.0000 norm=1.0886\n",
      "[iter 4] loss=-0.5127 val_loss=-0.2992 scale=1.0000 norm=1.0825\n",
      "[iter 5] loss=-0.5182 val_loss=-0.3049 scale=1.0000 norm=1.0769\n",
      "[iter 6] loss=-0.5235 val_loss=-0.3103 scale=1.0000 norm=1.0716\n",
      "[iter 7] loss=-0.5284 val_loss=-0.3154 scale=1.0000 norm=1.0667\n",
      "[iter 8] loss=-0.5331 val_loss=-0.3202 scale=1.0000 norm=1.0621\n",
      "[iter 9] loss=-0.5375 val_loss=-0.3248 scale=1.0000 norm=1.0579\n",
      "[iter 10] loss=-0.5416 val_loss=-0.3292 scale=1.0000 norm=1.0539\n",
      "[iter 11] loss=-0.5456 val_loss=-0.3333 scale=1.0000 norm=1.0501\n",
      "[iter 12] loss=-0.5493 val_loss=-0.3373 scale=1.0000 norm=1.0466\n",
      "[iter 13] loss=-0.5528 val_loss=-0.3410 scale=1.0000 norm=1.0434\n",
      "[iter 14] loss=-0.5562 val_loss=-0.3445 scale=1.0000 norm=1.0403\n",
      "[iter 15] loss=-0.5593 val_loss=-0.3479 scale=1.0000 norm=1.0375\n",
      "[iter 16] loss=-0.5624 val_loss=-0.3511 scale=1.0000 norm=1.0348\n",
      "[iter 17] loss=-0.5653 val_loss=-0.3541 scale=1.0000 norm=1.0323\n",
      "[iter 18] loss=-0.5681 val_loss=-0.3571 scale=1.0000 norm=1.0299\n",
      "[iter 19] loss=-0.5707 val_loss=-0.3598 scale=1.0000 norm=1.0277\n",
      "[iter 20] loss=-0.5733 val_loss=-0.3625 scale=1.0000 norm=1.0256\n",
      "[iter 21] loss=-0.5757 val_loss=-0.3650 scale=1.0000 norm=1.0237\n",
      "[iter 22] loss=-0.5780 val_loss=-0.3674 scale=1.0000 norm=1.0218\n",
      "[iter 23] loss=-0.5802 val_loss=-0.3697 scale=1.0000 norm=1.0202\n",
      "[iter 24] loss=-0.5823 val_loss=-0.3719 scale=1.0000 norm=1.0186\n",
      "[iter 25] loss=-0.5844 val_loss=-0.3739 scale=1.0000 norm=1.0171\n",
      "[iter 26] loss=-0.5863 val_loss=-0.3759 scale=1.0000 norm=1.0157\n",
      "[iter 27] loss=-0.5882 val_loss=-0.3797 scale=2.0000 norm=2.0288\n",
      "[iter 28] loss=-0.5917 val_loss=-0.3814 scale=1.0000 norm=1.0121\n",
      "[iter 29] loss=-0.5934 val_loss=-0.3848 scale=2.0000 norm=2.0220\n",
      "[iter 30] loss=-0.5966 val_loss=-0.3878 scale=2.0000 norm=2.0182\n",
      "[iter 31] loss=-0.5995 val_loss=-0.3905 scale=2.0000 norm=2.0149\n",
      "[iter 32] loss=-0.6022 val_loss=-0.3931 scale=2.0000 norm=2.0120\n",
      "[iter 33] loss=-0.6047 val_loss=-0.3955 scale=2.0000 norm=2.0096\n",
      "[iter 34] loss=-0.6071 val_loss=-0.3976 scale=2.0000 norm=2.0073\n",
      "[iter 35] loss=-0.6093 val_loss=-0.3996 scale=2.0000 norm=2.0055\n",
      "[iter 36] loss=-0.6114 val_loss=-0.4013 scale=2.0000 norm=2.0039\n",
      "[iter 37] loss=-0.6132 val_loss=-0.4031 scale=2.0000 norm=2.0027\n",
      "[iter 38] loss=-0.6150 val_loss=-0.4045 scale=2.0000 norm=2.0017\n",
      "[iter 39] loss=-0.6166 val_loss=-0.4058 scale=2.0000 norm=2.0008\n",
      "[iter 40] loss=-0.6182 val_loss=-0.4070 scale=2.0000 norm=2.0000\n",
      "[iter 41] loss=-0.6196 val_loss=-0.4081 scale=2.0000 norm=1.9995\n",
      "[iter 42] loss=-0.6209 val_loss=-0.4091 scale=2.0000 norm=1.9992\n",
      "[iter 43] loss=-0.6221 val_loss=-0.4098 scale=2.0000 norm=1.9990\n",
      "[iter 44] loss=-0.6232 val_loss=-0.4107 scale=2.0000 norm=1.9988\n",
      "[iter 45] loss=-0.6243 val_loss=-0.4115 scale=2.0000 norm=1.9988\n",
      "[iter 46] loss=-0.6253 val_loss=-0.4121 scale=2.0000 norm=1.9988\n",
      "[iter 47] loss=-0.6262 val_loss=-0.4128 scale=2.0000 norm=1.9988\n",
      "[iter 48] loss=-0.6271 val_loss=-0.4132 scale=2.0000 norm=1.9989\n",
      "[iter 49] loss=-0.6279 val_loss=-0.4136 scale=2.0000 norm=1.9991\n",
      "[iter 50] loss=-0.6286 val_loss=-0.4139 scale=2.0000 norm=1.9993\n",
      "[iter 51] loss=-0.6293 val_loss=-0.4143 scale=2.0000 norm=1.9997\n",
      "[iter 52] loss=-0.6300 val_loss=-0.4145 scale=2.0000 norm=1.9999\n",
      "[iter 53] loss=-0.6306 val_loss=-0.4148 scale=2.0000 norm=2.0003\n",
      "[iter 54] loss=-0.6311 val_loss=-0.4149 scale=2.0000 norm=2.0006\n",
      "[iter 55] loss=-0.6317 val_loss=-0.4151 scale=2.0000 norm=2.0010\n",
      "[iter 56] loss=-0.6322 val_loss=-0.4153 scale=2.0000 norm=2.0013\n",
      "[iter 57] loss=-0.6327 val_loss=-0.4154 scale=2.0000 norm=2.0017\n",
      "[iter 58] loss=-0.6331 val_loss=-0.4154 scale=2.0000 norm=2.0021\n",
      "[iter 59] loss=-0.6335 val_loss=-0.4154 scale=2.0000 norm=2.0024\n",
      "[iter 60] loss=-0.6340 val_loss=-0.4154 scale=2.0000 norm=2.0028\n",
      "[iter 61] loss=-0.6343 val_loss=-0.4154 scale=2.0000 norm=2.0032\n",
      "[iter 62] loss=-0.6347 val_loss=-0.4153 scale=2.0000 norm=2.0036\n",
      "[iter 63] loss=-0.6350 val_loss=-0.4153 scale=2.0000 norm=2.0039\n",
      "[iter 64] loss=-0.6353 val_loss=-0.4152 scale=2.0000 norm=2.0043\n",
      "[iter 65] loss=-0.6356 val_loss=-0.4152 scale=1.0000 norm=1.0023\n",
      "[iter 66] loss=-0.6357 val_loss=-0.4150 scale=2.0000 norm=2.0049\n",
      "[iter 67] loss=-0.6360 val_loss=-0.4150 scale=2.0000 norm=2.0053\n",
      "[iter 68] loss=-0.6362 val_loss=-0.4150 scale=2.0000 norm=2.0056\n",
      "[iter 69] loss=-0.6364 val_loss=-0.4147 scale=2.0000 norm=2.0059\n",
      "[iter 70] loss=-0.6367 val_loss=-0.4146 scale=2.0000 norm=2.0062\n",
      "[iter 71] loss=-0.6369 val_loss=-0.4145 scale=2.0000 norm=2.0066\n",
      "[iter 72] loss=-0.6371 val_loss=-0.4144 scale=1.0000 norm=1.0034\n",
      "[iter 73] loss=-0.6372 val_loss=-0.4143 scale=1.0000 norm=1.0035\n",
      "[iter 74] loss=-0.6373 val_loss=-0.4142 scale=1.0000 norm=1.0036\n",
      "[iter 75] loss=-0.6374 val_loss=-0.4139 scale=2.0000 norm=2.0073\n",
      "[iter 76] loss=-0.6375 val_loss=-0.4138 scale=2.0000 norm=2.0076\n",
      "[iter 77] loss=-0.6377 val_loss=-0.4136 scale=2.0000 norm=2.0078\n",
      "[iter 78] loss=-0.6379 val_loss=-0.4133 scale=2.0000 norm=2.0081\n",
      "[iter 79] loss=-0.6380 val_loss=-0.4131 scale=2.0000 norm=2.0084\n",
      "[iter 80] loss=-0.6381 val_loss=-0.4128 scale=2.0000 norm=2.0086\n",
      "[iter 81] loss=-0.6382 val_loss=-0.4126 scale=2.0000 norm=2.0089\n",
      "[iter 82] loss=-0.6384 val_loss=-0.4123 scale=2.0000 norm=2.0091\n",
      "[iter 83] loss=-0.6385 val_loss=-0.4121 scale=2.0000 norm=2.0094\n",
      "[iter 84] loss=-0.6386 val_loss=-0.4120 scale=2.0000 norm=2.0096\n",
      "[iter 85] loss=-0.6387 val_loss=-0.4116 scale=2.0000 norm=2.0098\n",
      "[iter 86] loss=-0.6388 val_loss=-0.4113 scale=2.0000 norm=2.0100\n",
      "[iter 87] loss=-0.6389 val_loss=-0.4110 scale=2.0000 norm=2.0102\n",
      "[iter 88] loss=-0.6390 val_loss=-0.4106 scale=2.0000 norm=2.0103\n",
      "[iter 89] loss=-0.6391 val_loss=-0.4104 scale=2.0000 norm=2.0104\n",
      "[iter 90] loss=-0.6392 val_loss=-0.4100 scale=2.0000 norm=2.0105\n",
      "[iter 91] loss=-0.6393 val_loss=-0.4099 scale=1.0000 norm=1.0053\n",
      "[iter 92] loss=-0.6394 val_loss=-0.4095 scale=2.0000 norm=2.0107\n",
      "[iter 93] loss=-0.6395 val_loss=-0.4095 scale=2.0000 norm=2.0108\n",
      "[iter 94] loss=-0.6396 val_loss=-0.4092 scale=2.0000 norm=2.0109\n",
      "[iter 95] loss=-0.6397 val_loss=-0.4089 scale=2.0000 norm=2.0110\n",
      "[iter 96] loss=-0.6397 val_loss=-0.4085 scale=2.0000 norm=2.0110\n",
      "[iter 97] loss=-0.6398 val_loss=-0.4085 scale=1.0000 norm=1.0056\n",
      "[iter 98] loss=-0.6399 val_loss=-0.4083 scale=2.0000 norm=2.0111\n",
      "[iter 99] loss=-0.6400 val_loss=-0.4082 scale=1.0000 norm=1.0056\n",
      "Expected 12 Excel files, but found 14 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0960\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5835 val_loss=0.6084 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5814 scale=1.0000 norm=1.0242\n",
      "[iter 7] loss=0.5450 val_loss=0.5689 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5334 val_loss=0.5569 scale=1.0000 norm=1.0063\n",
      "[iter 9] loss=0.5222 val_loss=0.5455 scale=1.0000 norm=0.9993\n",
      "[iter 10] loss=0.5116 val_loss=0.5346 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5014 val_loss=0.5242 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4917 val_loss=0.5142 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4823 val_loss=0.5045 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4733 val_loss=0.4953 scale=1.0000 norm=0.9789\n",
      "[iter 15] loss=0.4647 val_loss=0.4864 scale=1.0000 norm=0.9775\n",
      "[iter 16] loss=0.4564 val_loss=0.4779 scale=1.0000 norm=0.9768\n",
      "[iter 17] loss=0.4483 val_loss=0.4698 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4406 val_loss=0.4619 scale=1.0000 norm=0.9778\n",
      "[iter 19] loss=0.4332 val_loss=0.4543 scale=1.0000 norm=0.9794\n",
      "[iter 20] loss=0.4260 val_loss=0.4469 scale=1.0000 norm=0.9816\n",
      "[iter 21] loss=0.4191 val_loss=0.4399 scale=1.0000 norm=0.9845\n",
      "[iter 22] loss=0.4125 val_loss=0.4330 scale=1.0000 norm=0.9880\n",
      "[iter 23] loss=0.4060 val_loss=0.4265 scale=1.0000 norm=0.9922\n",
      "[iter 24] loss=0.3998 val_loss=0.4201 scale=1.0000 norm=0.9970\n",
      "[iter 25] loss=0.3938 val_loss=0.4140 scale=1.0000 norm=1.0024\n",
      "[iter 26] loss=0.3880 val_loss=0.4081 scale=1.0000 norm=1.0084\n",
      "[iter 27] loss=0.3825 val_loss=0.4023 scale=1.0000 norm=1.0149\n",
      "[iter 28] loss=0.3771 val_loss=0.3968 scale=1.0000 norm=1.0220\n",
      "[iter 29] loss=0.3718 val_loss=0.3914 scale=1.0000 norm=1.0297\n",
      "[iter 30] loss=0.3668 val_loss=0.3863 scale=1.0000 norm=1.0380\n",
      "[iter 31] loss=0.3619 val_loss=0.3813 scale=1.0000 norm=1.0468\n",
      "[iter 32] loss=0.3573 val_loss=0.3765 scale=1.0000 norm=1.0562\n",
      "[iter 33] loss=0.3527 val_loss=0.3719 scale=1.0000 norm=1.0661\n",
      "[iter 34] loss=0.3484 val_loss=0.3674 scale=1.0000 norm=1.0766\n",
      "[iter 35] loss=0.3442 val_loss=0.3630 scale=1.0000 norm=1.0877\n",
      "[iter 36] loss=0.3401 val_loss=0.3589 scale=1.0000 norm=1.0992\n",
      "[iter 37] loss=0.3362 val_loss=0.3548 scale=1.0000 norm=1.1113\n",
      "[iter 38] loss=0.3324 val_loss=0.3509 scale=1.0000 norm=1.1238\n",
      "[iter 39] loss=0.3288 val_loss=0.3472 scale=1.0000 norm=1.1370\n",
      "[iter 40] loss=0.3253 val_loss=0.3436 scale=1.0000 norm=1.1506\n",
      "[iter 41] loss=0.3219 val_loss=0.3401 scale=1.0000 norm=1.1648\n",
      "[iter 42] loss=0.3187 val_loss=0.3368 scale=1.0000 norm=1.1795\n",
      "[iter 43] loss=0.3156 val_loss=0.3336 scale=1.0000 norm=1.1946\n",
      "[iter 44] loss=0.3126 val_loss=0.3305 scale=1.0000 norm=1.2102\n",
      "[iter 45] loss=0.3097 val_loss=0.3275 scale=1.0000 norm=1.2264\n",
      "[iter 46] loss=0.3070 val_loss=0.3246 scale=1.0000 norm=1.2431\n",
      "[iter 47] loss=0.3043 val_loss=0.3218 scale=1.0000 norm=1.2603\n",
      "[iter 48] loss=0.3018 val_loss=0.3191 scale=1.0000 norm=1.2778\n",
      "[iter 49] loss=0.2994 val_loss=0.3166 scale=1.0000 norm=1.2958\n",
      "[iter 50] loss=0.2970 val_loss=0.3141 scale=1.0000 norm=1.3143\n",
      "[iter 51] loss=0.2948 val_loss=0.3118 scale=1.0000 norm=1.3332\n",
      "[iter 52] loss=0.2927 val_loss=0.3096 scale=1.0000 norm=1.3526\n",
      "[iter 53] loss=0.2906 val_loss=0.3074 scale=1.0000 norm=1.3723\n",
      "[iter 54] loss=0.2887 val_loss=0.3054 scale=1.0000 norm=1.3925\n",
      "[iter 55] loss=0.2868 val_loss=0.3034 scale=1.0000 norm=1.4129\n",
      "[iter 56] loss=0.2850 val_loss=0.3015 scale=1.0000 norm=1.4336\n",
      "[iter 57] loss=0.2833 val_loss=0.2997 scale=1.0000 norm=1.4546\n",
      "[iter 58] loss=0.2817 val_loss=0.2981 scale=1.0000 norm=1.4759\n",
      "[iter 59] loss=0.2801 val_loss=0.2964 scale=1.0000 norm=1.4973\n",
      "[iter 60] loss=0.2786 val_loss=0.2949 scale=1.0000 norm=1.5191\n",
      "[iter 61] loss=0.2772 val_loss=0.2934 scale=1.0000 norm=1.5410\n",
      "[iter 62] loss=0.2759 val_loss=0.2920 scale=1.0000 norm=1.5630\n",
      "[iter 63] loss=0.2746 val_loss=0.2907 scale=1.0000 norm=1.5851\n",
      "[iter 64] loss=0.2733 val_loss=0.2895 scale=1.0000 norm=1.6073\n",
      "[iter 65] loss=0.2722 val_loss=0.2883 scale=1.0000 norm=1.6297\n",
      "[iter 66] loss=0.2711 val_loss=0.2871 scale=1.0000 norm=1.6521\n",
      "[iter 67] loss=0.2700 val_loss=0.2861 scale=1.0000 norm=1.6747\n",
      "[iter 68] loss=0.2690 val_loss=0.2851 scale=1.0000 norm=1.6972\n",
      "[iter 69] loss=0.2681 val_loss=0.2841 scale=1.0000 norm=1.7197\n",
      "[iter 70] loss=0.2672 val_loss=0.2832 scale=1.0000 norm=1.7420\n",
      "[iter 71] loss=0.2664 val_loss=0.2823 scale=1.0000 norm=1.7645\n",
      "[iter 72] loss=0.2656 val_loss=0.2815 scale=1.0000 norm=1.7865\n",
      "[iter 73] loss=0.2648 val_loss=0.2808 scale=1.0000 norm=1.8088\n",
      "[iter 74] loss=0.2641 val_loss=0.2801 scale=1.0000 norm=1.8311\n",
      "[iter 75] loss=0.2634 val_loss=0.2794 scale=1.0000 norm=1.8530\n",
      "[iter 76] loss=0.2628 val_loss=0.2787 scale=1.0000 norm=1.8744\n",
      "[iter 77] loss=0.2621 val_loss=0.2781 scale=1.0000 norm=1.8955\n",
      "[iter 78] loss=0.2615 val_loss=0.2776 scale=1.0000 norm=1.9166\n",
      "[iter 79] loss=0.2610 val_loss=0.2770 scale=1.0000 norm=1.9365\n",
      "[iter 80] loss=0.2604 val_loss=0.2765 scale=1.0000 norm=1.9567\n",
      "[iter 81] loss=0.2599 val_loss=0.2760 scale=1.0000 norm=1.9760\n",
      "[iter 82] loss=0.2595 val_loss=0.2756 scale=1.0000 norm=1.9956\n",
      "[iter 83] loss=0.2590 val_loss=0.2751 scale=1.0000 norm=2.0143\n",
      "[iter 84] loss=0.2586 val_loss=0.2747 scale=1.0000 norm=2.0327\n",
      "[iter 85] loss=0.2582 val_loss=0.2743 scale=1.0000 norm=2.0514\n",
      "[iter 86] loss=0.2578 val_loss=0.2741 scale=0.5000 norm=1.0347\n",
      "[iter 87] loss=0.2576 val_loss=0.2738 scale=1.0000 norm=2.0781\n",
      "[iter 88] loss=0.2573 val_loss=0.2735 scale=1.0000 norm=2.0957\n",
      "[iter 89] loss=0.2570 val_loss=0.2732 scale=1.0000 norm=2.1127\n",
      "[iter 90] loss=0.2567 val_loss=0.2731 scale=0.5000 norm=1.0637\n",
      "[iter 91] loss=0.2566 val_loss=0.2729 scale=1.0000 norm=2.1355\n",
      "[iter 92] loss=0.2563 val_loss=0.2728 scale=0.5000 norm=1.0756\n",
      "[iter 93] loss=0.2562 val_loss=0.2727 scale=0.5000 norm=1.0795\n",
      "[iter 94] loss=0.2561 val_loss=0.2725 scale=1.0000 norm=2.1665\n",
      "[iter 95] loss=0.2559 val_loss=0.2724 scale=0.5000 norm=1.0909\n",
      "[iter 96] loss=0.2558 val_loss=0.2723 scale=1.0000 norm=2.1901\n",
      "[iter 97] loss=0.2556 val_loss=0.2722 scale=1.0000 norm=2.2045\n",
      "[iter 98] loss=0.2554 val_loss=0.2721 scale=0.5000 norm=1.1093\n",
      "[iter 99] loss=0.2553 val_loss=0.2721 scale=0.5000 norm=1.1129\n",
      "Expected 12 Excel files, but found 15 files. Skipping the merge step.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3018 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5241 val_loss=-0.3345 scale=1.0000 norm=1.0745\n",
      "[iter 2] loss=-0.5563 val_loss=-0.3636 scale=1.0000 norm=1.0443\n",
      "[iter 3] loss=-0.5847 val_loss=-0.3897 scale=1.0000 norm=1.0178\n",
      "[iter 4] loss=-0.6102 val_loss=-0.4367 scale=2.0000 norm=1.9877\n",
      "[iter 5] loss=-0.6558 val_loss=-0.4768 scale=2.0000 norm=1.9023\n",
      "[iter 6] loss=-0.6952 val_loss=-0.5127 scale=2.0000 norm=1.8293\n",
      "[iter 7] loss=-0.7303 val_loss=-0.5458 scale=2.0000 norm=1.7655\n",
      "[iter 8] loss=-0.7625 val_loss=-0.5759 scale=2.0000 norm=1.7090\n",
      "[iter 9] loss=-0.7922 val_loss=-0.6044 scale=2.0000 norm=1.6589\n",
      "[iter 10] loss=-0.8203 val_loss=-0.6310 scale=2.0000 norm=1.6139\n",
      "[iter 11] loss=-0.8467 val_loss=-0.6563 scale=2.0000 norm=1.5735\n",
      "[iter 12] loss=-0.8720 val_loss=-0.6806 scale=2.0000 norm=1.5373\n",
      "[iter 13] loss=-0.8961 val_loss=-0.7039 scale=2.0000 norm=1.5048\n",
      "[iter 14] loss=-0.9194 val_loss=-0.7263 scale=2.0000 norm=1.4755\n",
      "[iter 15] loss=-0.9418 val_loss=-0.7478 scale=2.0000 norm=1.4490\n",
      "[iter 16] loss=-0.9636 val_loss=-0.7686 scale=2.0000 norm=1.4253\n",
      "[iter 17] loss=-0.9846 val_loss=-0.7888 scale=2.0000 norm=1.4041\n",
      "[iter 18] loss=-1.0049 val_loss=-0.8083 scale=2.0000 norm=1.3850\n",
      "[iter 19] loss=-1.0246 val_loss=-0.8271 scale=2.0000 norm=1.3679\n",
      "[iter 20] loss=-1.0438 val_loss=-0.8454 scale=2.0000 norm=1.3525\n",
      "[iter 21] loss=-1.0624 val_loss=-0.8631 scale=2.0000 norm=1.3388\n",
      "[iter 22] loss=-1.0804 val_loss=-0.8803 scale=2.0000 norm=1.3265\n",
      "[iter 23] loss=-1.0980 val_loss=-0.8971 scale=2.0000 norm=1.3155\n",
      "[iter 24] loss=-1.1150 val_loss=-0.9132 scale=2.0000 norm=1.3057\n",
      "[iter 25] loss=-1.1316 val_loss=-0.9289 scale=2.0000 norm=1.2970\n",
      "[iter 26] loss=-1.1476 val_loss=-0.9441 scale=2.0000 norm=1.2893\n",
      "[iter 27] loss=-1.1632 val_loss=-0.9589 scale=2.0000 norm=1.2825\n",
      "[iter 28] loss=-1.1784 val_loss=-0.9733 scale=2.0000 norm=1.2764\n",
      "[iter 29] loss=-1.1931 val_loss=-0.9872 scale=2.0000 norm=1.2711\n",
      "[iter 30] loss=-1.2074 val_loss=-1.0007 scale=2.0000 norm=1.2664\n",
      "[iter 31] loss=-1.2212 val_loss=-1.0137 scale=2.0000 norm=1.2623\n",
      "[iter 32] loss=-1.2346 val_loss=-1.0265 scale=2.0000 norm=1.2589\n",
      "[iter 33] loss=-1.2476 val_loss=-1.0387 scale=2.0000 norm=1.2559\n",
      "[iter 34] loss=-1.2602 val_loss=-1.0505 scale=2.0000 norm=1.2533\n",
      "[iter 35] loss=-1.2723 val_loss=-1.0620 scale=2.0000 norm=1.2513\n",
      "[iter 36] loss=-1.2841 val_loss=-1.0730 scale=2.0000 norm=1.2495\n",
      "[iter 37] loss=-1.2954 val_loss=-1.0837 scale=2.0000 norm=1.2481\n",
      "[iter 38] loss=-1.3064 val_loss=-1.0939 scale=2.0000 norm=1.2471\n",
      "[iter 39] loss=-1.3170 val_loss=-1.1039 scale=2.0000 norm=1.2463\n",
      "[iter 40] loss=-1.3272 val_loss=-1.1136 scale=2.0000 norm=1.2458\n",
      "[iter 41] loss=-1.3372 val_loss=-1.1228 scale=2.0000 norm=1.2455\n",
      "[iter 42] loss=-1.3468 val_loss=-1.1319 scale=2.0000 norm=1.2454\n",
      "[iter 43] loss=-1.3559 val_loss=-1.1406 scale=2.0000 norm=1.2456\n",
      "[iter 44] loss=-1.3649 val_loss=-1.1488 scale=2.0000 norm=1.2458\n",
      "[iter 45] loss=-1.3734 val_loss=-1.1569 scale=2.0000 norm=1.2463\n",
      "[iter 46] loss=-1.3817 val_loss=-1.1646 scale=2.0000 norm=1.2470\n",
      "[iter 47] loss=-1.3896 val_loss=-1.1719 scale=2.0000 norm=1.2477\n",
      "[iter 48] loss=-1.3973 val_loss=-1.1789 scale=2.0000 norm=1.2487\n",
      "[iter 49] loss=-1.4046 val_loss=-1.1857 scale=2.0000 norm=1.2497\n",
      "[iter 50] loss=-1.4116 val_loss=-1.1923 scale=2.0000 norm=1.2509\n",
      "[iter 51] loss=-1.4185 val_loss=-1.1987 scale=2.0000 norm=1.2521\n",
      "[iter 52] loss=-1.4250 val_loss=-1.2047 scale=2.0000 norm=1.2534\n",
      "[iter 53] loss=-1.4313 val_loss=-1.2105 scale=2.0000 norm=1.2549\n",
      "[iter 54] loss=-1.4373 val_loss=-1.2161 scale=2.0000 norm=1.2563\n",
      "[iter 55] loss=-1.4431 val_loss=-1.2214 scale=2.0000 norm=1.2579\n",
      "[iter 56] loss=-1.4487 val_loss=-1.2264 scale=2.0000 norm=1.2595\n",
      "[iter 57] loss=-1.4540 val_loss=-1.2314 scale=2.0000 norm=1.2612\n",
      "[iter 58] loss=-1.4591 val_loss=-1.2359 scale=2.0000 norm=1.2629\n",
      "[iter 59] loss=-1.4640 val_loss=-1.2404 scale=2.0000 norm=1.2647\n",
      "[iter 60] loss=-1.4687 val_loss=-1.2446 scale=2.0000 norm=1.2665\n",
      "[iter 61] loss=-1.4731 val_loss=-1.2487 scale=2.0000 norm=1.2683\n",
      "[iter 62] loss=-1.4774 val_loss=-1.2526 scale=2.0000 norm=1.2702\n",
      "[iter 63] loss=-1.4815 val_loss=-1.2564 scale=2.0000 norm=1.2720\n",
      "[iter 64] loss=-1.4855 val_loss=-1.2597 scale=2.0000 norm=1.2739\n",
      "[iter 65] loss=-1.4892 val_loss=-1.2629 scale=2.0000 norm=1.2757\n",
      "[iter 66] loss=-1.4927 val_loss=-1.2660 scale=2.0000 norm=1.2777\n",
      "[iter 67] loss=-1.4961 val_loss=-1.2690 scale=2.0000 norm=1.2795\n",
      "[iter 68] loss=-1.4994 val_loss=-1.2719 scale=2.0000 norm=1.2815\n",
      "[iter 69] loss=-1.5025 val_loss=-1.2745 scale=2.0000 norm=1.2833\n",
      "[iter 70] loss=-1.5054 val_loss=-1.2770 scale=2.0000 norm=1.2851\n",
      "[iter 71] loss=-1.5082 val_loss=-1.2793 scale=2.0000 norm=1.2870\n",
      "[iter 72] loss=-1.5109 val_loss=-1.2815 scale=2.0000 norm=1.2888\n",
      "[iter 73] loss=-1.5135 val_loss=-1.2834 scale=2.0000 norm=1.2906\n",
      "[iter 74] loss=-1.5158 val_loss=-1.2852 scale=2.0000 norm=1.2925\n",
      "[iter 75] loss=-1.5182 val_loss=-1.2868 scale=2.0000 norm=1.2941\n",
      "[iter 76] loss=-1.5203 val_loss=-1.2883 scale=2.0000 norm=1.2958\n",
      "[iter 77] loss=-1.5223 val_loss=-1.2898 scale=2.0000 norm=1.2975\n",
      "[iter 78] loss=-1.5243 val_loss=-1.2910 scale=2.0000 norm=1.2993\n",
      "[iter 79] loss=-1.5262 val_loss=-1.2924 scale=2.0000 norm=1.3009\n",
      "[iter 80] loss=-1.5279 val_loss=-1.2934 scale=2.0000 norm=1.3027\n",
      "[iter 81] loss=-1.5296 val_loss=-1.2946 scale=2.0000 norm=1.3043\n",
      "[iter 82] loss=-1.5312 val_loss=-1.2953 scale=2.0000 norm=1.3061\n",
      "[iter 83] loss=-1.5326 val_loss=-1.2962 scale=2.0000 norm=1.3076\n",
      "[iter 84] loss=-1.5340 val_loss=-1.2968 scale=2.0000 norm=1.3092\n",
      "[iter 85] loss=-1.5353 val_loss=-1.2974 scale=2.0000 norm=1.3107\n",
      "[iter 86] loss=-1.5365 val_loss=-1.2979 scale=2.0000 norm=1.3123\n",
      "[iter 87] loss=-1.5377 val_loss=-1.2986 scale=2.0000 norm=1.3137\n",
      "[iter 88] loss=-1.5389 val_loss=-1.2993 scale=2.0000 norm=1.3152\n",
      "[iter 89] loss=-1.5400 val_loss=-1.2997 scale=2.0000 norm=1.3167\n",
      "[iter 90] loss=-1.5410 val_loss=-1.3002 scale=2.0000 norm=1.3182\n",
      "[iter 91] loss=-1.5419 val_loss=-1.3005 scale=2.0000 norm=1.3197\n",
      "[iter 92] loss=-1.5428 val_loss=-1.3008 scale=2.0000 norm=1.3212\n",
      "[iter 93] loss=-1.5437 val_loss=-1.3012 scale=2.0000 norm=1.3225\n",
      "[iter 94] loss=-1.5445 val_loss=-1.3012 scale=2.0000 norm=1.3237\n",
      "[iter 95] loss=-1.5452 val_loss=-1.3012 scale=1.0000 norm=0.6624\n",
      "[iter 96] loss=-1.5456 val_loss=-1.3015 scale=2.0000 norm=1.3254\n",
      "[iter 97] loss=-1.5463 val_loss=-1.3018 scale=2.0000 norm=1.3267\n",
      "[iter 98] loss=-1.5469 val_loss=-1.3019 scale=2.0000 norm=1.3279\n",
      "[iter 99] loss=-1.5476 val_loss=-1.3019 scale=1.0000 norm=0.6645\n",
      "Merge completed! The final file is 'Merged_Sheet.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "\n",
    "results_per_time_interval_df, results_summary_stats_df, results_per_row_df, hyperparameters_df = evaluate_ngboost_model(entsoe, case=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alter code ohne Figur und excel Dokument fÃ¼r merged information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6806 scale=2.0000 norm=2.2332\n",
      "[iter 1] loss=0.6375 val_loss=0.6722 scale=2.0000 norm=2.2170\n",
      "[iter 2] loss=0.6307 val_loss=0.6647 scale=2.0000 norm=2.2042\n",
      "[iter 3] loss=0.6246 val_loss=0.6579 scale=2.0000 norm=2.1944\n",
      "[iter 4] loss=0.6192 val_loss=0.6519 scale=2.0000 norm=2.1869\n",
      "[iter 5] loss=0.6143 val_loss=0.6464 scale=2.0000 norm=2.1814\n",
      "[iter 6] loss=0.6099 val_loss=0.6415 scale=2.0000 norm=2.1775\n",
      "[iter 7] loss=0.6059 val_loss=0.6370 scale=2.0000 norm=2.1751\n",
      "[iter 8] loss=0.6022 val_loss=0.6330 scale=2.0000 norm=2.1740\n",
      "[iter 9] loss=0.5989 val_loss=0.6293 scale=2.0000 norm=2.1739\n",
      "[iter 10] loss=0.5959 val_loss=0.6259 scale=2.0000 norm=2.1747\n",
      "[iter 11] loss=0.5932 val_loss=0.6228 scale=2.0000 norm=2.1763\n",
      "[iter 12] loss=0.5907 val_loss=0.6200 scale=2.0000 norm=2.1787\n",
      "[iter 13] loss=0.5884 val_loss=0.6175 scale=2.0000 norm=2.1816\n",
      "[iter 14] loss=0.5863 val_loss=0.6152 scale=2.0000 norm=2.1851\n",
      "[iter 15] loss=0.5844 val_loss=0.6131 scale=2.0000 norm=2.1890\n",
      "[iter 16] loss=0.5826 val_loss=0.6112 scale=2.0000 norm=2.1933\n",
      "[iter 17] loss=0.5811 val_loss=0.6094 scale=2.0000 norm=2.1980\n",
      "[iter 18] loss=0.5796 val_loss=0.6078 scale=2.0000 norm=2.2029\n",
      "[iter 19] loss=0.5783 val_loss=0.6063 scale=2.0000 norm=2.2081\n",
      "[iter 20] loss=0.5771 val_loss=0.6050 scale=2.0000 norm=2.2135\n",
      "[iter 21] loss=0.5759 val_loss=0.6038 scale=2.0000 norm=2.2190\n",
      "[iter 22] loss=0.5749 val_loss=0.6027 scale=2.0000 norm=2.2247\n",
      "[iter 23] loss=0.5740 val_loss=0.6017 scale=2.0000 norm=2.2305\n",
      "[iter 24] loss=0.5731 val_loss=0.6008 scale=2.0000 norm=2.2363\n",
      "[iter 25] loss=0.5724 val_loss=0.5999 scale=2.0000 norm=2.2422\n",
      "[iter 26] loss=0.5717 val_loss=0.5992 scale=2.0000 norm=2.2482\n",
      "[iter 27] loss=0.5710 val_loss=0.5985 scale=2.0000 norm=2.2541\n",
      "[iter 28] loss=0.5704 val_loss=0.5979 scale=2.0000 norm=2.2601\n",
      "[iter 29] loss=0.5699 val_loss=0.5974 scale=2.0000 norm=2.2660\n",
      "[iter 30] loss=0.5694 val_loss=0.5969 scale=2.0000 norm=2.2720\n",
      "[iter 31] loss=0.5690 val_loss=0.5964 scale=2.0000 norm=2.2778\n",
      "[iter 32] loss=0.5686 val_loss=0.5960 scale=2.0000 norm=2.2836\n",
      "[iter 33] loss=0.5682 val_loss=0.5957 scale=2.0000 norm=2.2894\n",
      "[iter 34] loss=0.5679 val_loss=0.5953 scale=2.0000 norm=2.2951\n",
      "[iter 35] loss=0.5676 val_loss=0.5951 scale=2.0000 norm=2.3007\n",
      "[iter 36] loss=0.5673 val_loss=0.5948 scale=2.0000 norm=2.3061\n",
      "[iter 37] loss=0.5671 val_loss=0.5947 scale=1.0000 norm=1.1558\n",
      "[iter 38] loss=0.5670 val_loss=0.5945 scale=2.0000 norm=2.3141\n",
      "[iter 39] loss=0.5667 val_loss=0.5944 scale=1.0000 norm=1.1597\n",
      "[iter 40] loss=0.5667 val_loss=0.5943 scale=1.0000 norm=1.1610\n",
      "[iter 41] loss=0.5666 val_loss=0.5942 scale=1.0000 norm=1.1622\n",
      "[iter 42] loss=0.5665 val_loss=0.5941 scale=1.0000 norm=1.1634\n",
      "[iter 43] loss=0.5664 val_loss=0.5940 scale=1.0000 norm=1.1647\n",
      "[iter 44] loss=0.5663 val_loss=0.5940 scale=1.0000 norm=1.1659\n",
      "[iter 45] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1671\n",
      "[iter 46] loss=0.5662 val_loss=0.5939 scale=1.0000 norm=1.1682\n",
      "[iter 47] loss=0.5661 val_loss=0.5939 scale=1.0000 norm=1.1694\n",
      "[iter 48] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1705\n",
      "[iter 49] loss=0.5660 val_loss=0.5938 scale=1.0000 norm=1.1717\n",
      "[iter 50] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1728\n",
      "[iter 51] loss=0.5659 val_loss=0.5937 scale=1.0000 norm=1.1739\n",
      "[iter 52] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1749\n",
      "[iter 53] loss=0.5658 val_loss=0.5937 scale=1.0000 norm=1.1760\n",
      "[iter 54] loss=0.5657 val_loss=0.5937 scale=1.0000 norm=1.1770\n",
      "[iter 55] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1780\n",
      "[iter 56] loss=0.5657 val_loss=0.5936 scale=1.0000 norm=1.1790\n",
      "[iter 57] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1800\n",
      "[iter 58] loss=0.5656 val_loss=0.5936 scale=1.0000 norm=1.1810\n",
      "[iter 59] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1819\n",
      "[iter 60] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1828\n",
      "[iter 61] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1837\n",
      "[iter 62] loss=0.5655 val_loss=0.5936 scale=1.0000 norm=1.1846\n",
      "[iter 63] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1855\n",
      "[iter 64] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1863\n",
      "[iter 65] loss=0.5654 val_loss=0.5935 scale=1.0000 norm=1.1872\n",
      "[iter 66] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1880\n",
      "[iter 67] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1888\n",
      "[iter 68] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1896\n",
      "[iter 69] loss=0.5653 val_loss=0.5935 scale=1.0000 norm=1.1903\n",
      "[iter 70] loss=0.5653 val_loss=0.5936 scale=1.0000 norm=1.1911\n",
      "[iter 71] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1918\n",
      "[iter 72] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1925\n",
      "[iter 73] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1932\n",
      "[iter 74] loss=0.5652 val_loss=0.5936 scale=1.0000 norm=1.1939\n",
      "[iter 75] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1945\n",
      "[iter 76] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1952\n",
      "[iter 77] loss=0.5652 val_loss=0.5937 scale=1.0000 norm=1.1958\n",
      "[iter 78] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1964\n",
      "[iter 79] loss=0.5651 val_loss=0.5937 scale=1.0000 norm=1.1970\n",
      "[iter 80] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1976\n",
      "[iter 81] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1982\n",
      "[iter 82] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1987\n",
      "[iter 83] loss=0.5651 val_loss=0.5938 scale=1.0000 norm=1.1993\n",
      "[iter 84] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.1998\n",
      "[iter 85] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2003\n",
      "[iter 86] loss=0.5651 val_loss=0.5939 scale=1.0000 norm=1.2008\n",
      "[iter 87] loss=0.5651 val_loss=0.5940 scale=1.0000 norm=1.2013\n",
      "[iter 88] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2017\n",
      "[iter 89] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2022\n",
      "[iter 90] loss=0.5650 val_loss=0.5940 scale=1.0000 norm=1.2026\n",
      "[iter 91] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2031\n",
      "[iter 92] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2035\n",
      "[iter 93] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2039\n",
      "[iter 94] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2043\n",
      "[iter 95] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2047\n",
      "[iter 96] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2050\n",
      "[iter 97] loss=0.5650 val_loss=0.5941 scale=1.0000 norm=1.2054\n",
      "[iter 98] loss=0.5650 val_loss=0.5942 scale=2.0000 norm=2.4115\n",
      "[iter 99] loss=0.5650 val_loss=0.5942 scale=1.0000 norm=1.2065\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.527452</td>\n",
       "      <td>0.127293</td>\n",
       "      <td>2.945731</td>\n",
       "      <td>0.104590</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0.301276</td>\n",
       "      <td>-16.310341</td>\n",
       "      <td>2.462182</td>\n",
       "      <td>0.527452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.528015</td>\n",
       "      <td>0.117377</td>\n",
       "      <td>3.034884</td>\n",
       "      <td>0.104495</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.473311</td>\n",
       "      <td>0.301891</td>\n",
       "      <td>-17.337429</td>\n",
       "      <td>2.458429</td>\n",
       "      <td>0.528015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.529974</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>3.208672</td>\n",
       "      <td>0.103955</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.479594</td>\n",
       "      <td>0.306262</td>\n",
       "      <td>-18.670506</td>\n",
       "      <td>2.451273</td>\n",
       "      <td>0.529974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.533789</td>\n",
       "      <td>0.126418</td>\n",
       "      <td>3.471371</td>\n",
       "      <td>0.103474</td>\n",
       "      <td>0.023219</td>\n",
       "      <td>0.475667</td>\n",
       "      <td>0.302312</td>\n",
       "      <td>-22.804050</td>\n",
       "      <td>2.451273</td>\n",
       "      <td>0.533789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.534015</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>3.623714</td>\n",
       "      <td>0.102753</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.467540</td>\n",
       "      <td>0.303279</td>\n",
       "      <td>-26.445000</td>\n",
       "      <td>2.450815</td>\n",
       "      <td>0.534015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>0.121338</td>\n",
       "      <td>2.567617</td>\n",
       "      <td>0.107025</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.445425</td>\n",
       "      <td>0.288973</td>\n",
       "      <td>-11.218587</td>\n",
       "      <td>2.417542</td>\n",
       "      <td>0.527363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.121263</td>\n",
       "      <td>2.658296</td>\n",
       "      <td>0.106515</td>\n",
       "      <td>0.023216</td>\n",
       "      <td>0.455137</td>\n",
       "      <td>0.289712</td>\n",
       "      <td>-11.682353</td>\n",
       "      <td>2.441640</td>\n",
       "      <td>0.526984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.527614</td>\n",
       "      <td>0.122556</td>\n",
       "      <td>2.759381</td>\n",
       "      <td>0.105974</td>\n",
       "      <td>0.023686</td>\n",
       "      <td>0.450364</td>\n",
       "      <td>0.286348</td>\n",
       "      <td>-12.547662</td>\n",
       "      <td>2.449185</td>\n",
       "      <td>0.527614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.528161</td>\n",
       "      <td>0.119704</td>\n",
       "      <td>2.856737</td>\n",
       "      <td>0.105456</td>\n",
       "      <td>0.023459</td>\n",
       "      <td>0.461679</td>\n",
       "      <td>0.293559</td>\n",
       "      <td>-13.897368</td>\n",
       "      <td>2.457971</td>\n",
       "      <td>0.528161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.528321</td>\n",
       "      <td>0.127422</td>\n",
       "      <td>2.947207</td>\n",
       "      <td>0.104971</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>0.463634</td>\n",
       "      <td>0.295479</td>\n",
       "      <td>-15.441766</td>\n",
       "      <td>2.461653</td>\n",
       "      <td>0.528321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.527452           0.127293           2.945731   \n",
       "1          2            0.528015           0.117377           3.034884   \n",
       "2          3            0.529974           0.118462           3.208672   \n",
       "3          4            0.533789           0.126418           3.471371   \n",
       "4          5            0.534015           0.125654           3.623714   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.527363           0.121338           2.567617   \n",
       "92        93            0.526984           0.121263           2.658296   \n",
       "93        94            0.527614           0.122556           2.759381   \n",
       "94        95            0.528161           0.119704           2.856737   \n",
       "95        96            0.528321           0.127422           2.947207   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.104590            0.021858            0.464429  0.301276   \n",
       "1              0.104495            0.021690            0.473311  0.301891   \n",
       "2              0.103955            0.023160            0.479594  0.306262   \n",
       "3              0.103474            0.023219            0.475667  0.302312   \n",
       "4              0.102753            0.023301            0.467540  0.303279   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.107025            0.021376            0.445425  0.288973   \n",
       "92             0.106515            0.023216            0.455137  0.289712   \n",
       "93             0.105974            0.023686            0.450364  0.286348   \n",
       "94             0.105456            0.023459            0.461679  0.293559   \n",
       "95             0.104971            0.023197            0.463634  0.295479   \n",
       "\n",
       "      NLL_min   NLL_max  model_scores  \n",
       "0  -16.310341  2.462182      0.527452  \n",
       "1  -17.337429  2.458429      0.528015  \n",
       "2  -18.670506  2.451273      0.529974  \n",
       "3  -22.804050  2.451273      0.533789  \n",
       "4  -26.445000  2.450815      0.534015  \n",
       "..        ...       ...           ...  \n",
       "91 -11.218587  2.417542      0.527363  \n",
       "92 -11.682353  2.441640      0.526984  \n",
       "93 -12.547662  2.449185      0.527614  \n",
       "94 -13.897368  2.457971      0.528161  \n",
       "95 -15.441766  2.461653      0.528321  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594162</td>\n",
       "      <td>0.097035</td>\n",
       "      <td>5.890023</td>\n",
       "      <td>0.106901</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.67271</td>\n",
       "      <td>0.357223</td>\n",
       "      <td>-76.403841</td>\n",
       "      <td>2.462182</td>\n",
       "      <td>0.594162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.594162           0.097035           5.890023   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.106901            0.019255             0.67271  0.357223   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -76.403841  2.462182           0.594162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318985</td>\n",
       "      <td>0.135220</td>\n",
       "      <td>-0.336709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.329743</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>-0.374002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.344702</td>\n",
       "      <td>0.140830</td>\n",
       "      <td>-0.389813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.370102</td>\n",
       "      <td>0.155723</td>\n",
       "      <td>-0.480130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.352404</td>\n",
       "      <td>0.143660</td>\n",
       "      <td>-0.406276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.588794</td>\n",
       "      <td>0.169652</td>\n",
       "      <td>-0.636659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.599610</td>\n",
       "      <td>0.174756</td>\n",
       "      <td>-0.668718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.589348</td>\n",
       "      <td>0.169897</td>\n",
       "      <td>-0.638686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.172441</td>\n",
       "      <td>-0.654711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.609878</td>\n",
       "      <td>0.179665</td>\n",
       "      <td>-0.699409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.318985        0.135220 -0.336709\n",
       "1             2       0.329743        0.141667 -0.374002\n",
       "2             3       0.344702        0.140830 -0.389813\n",
       "3             4       0.370102        0.155723 -0.480130\n",
       "4             5       0.352404        0.143660 -0.406276\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.588794        0.169652 -0.636659\n",
       "35036     35037       0.599610        0.174756 -0.668718\n",
       "35037     35038       0.589348        0.169897 -0.638686\n",
       "35038     35039       0.594754        0.172441 -0.654711\n",
       "35039     35040       0.609878        0.179665 -0.699409\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset feature_columns                                  distribution  \\\n",
       "0  entsoe    [power_t-96]  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.2717 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.4931 val_loss=-0.2789 scale=1.0000 norm=1.1025\n",
      "[iter 2] loss=-0.4995 val_loss=-0.2856 scale=1.0000 norm=1.0957\n",
      "[iter 3] loss=-0.5054 val_loss=-0.2918 scale=1.0000 norm=1.0895\n",
      "[iter 4] loss=-0.5109 val_loss=-0.2976 scale=1.0000 norm=1.0837\n",
      "[iter 5] loss=-0.5161 val_loss=-0.3031 scale=1.0000 norm=1.0783\n",
      "[iter 6] loss=-0.5209 val_loss=-0.3082 scale=1.0000 norm=1.0733\n",
      "[iter 7] loss=-0.5255 val_loss=-0.3130 scale=1.0000 norm=1.0686\n",
      "[iter 8] loss=-0.5297 val_loss=-0.3175 scale=1.0000 norm=1.0642\n",
      "[iter 9] loss=-0.5338 val_loss=-0.3217 scale=1.0000 norm=1.0602\n",
      "[iter 10] loss=-0.5376 val_loss=-0.3258 scale=1.0000 norm=1.0563\n",
      "[iter 11] loss=-0.5413 val_loss=-0.3296 scale=1.0000 norm=1.0527\n",
      "[iter 12] loss=-0.5447 val_loss=-0.3332 scale=1.0000 norm=1.0493\n",
      "[iter 13] loss=-0.5480 val_loss=-0.3366 scale=1.0000 norm=1.0462\n",
      "[iter 14] loss=-0.5511 val_loss=-0.3431 scale=2.0000 norm=2.0866\n",
      "[iter 15] loss=-0.5570 val_loss=-0.3489 scale=2.0000 norm=2.0757\n",
      "[iter 16] loss=-0.5622 val_loss=-0.3542 scale=2.0000 norm=2.0663\n",
      "[iter 17] loss=-0.5670 val_loss=-0.3590 scale=2.0000 norm=2.0581\n",
      "[iter 18] loss=-0.5714 val_loss=-0.3634 scale=2.0000 norm=2.0510\n",
      "[iter 19] loss=-0.5754 val_loss=-0.3674 scale=2.0000 norm=2.0448\n",
      "[iter 20] loss=-0.5790 val_loss=-0.3709 scale=2.0000 norm=2.0394\n",
      "[iter 21] loss=-0.5824 val_loss=-0.3742 scale=2.0000 norm=2.0347\n",
      "[iter 22] loss=-0.5855 val_loss=-0.3772 scale=2.0000 norm=2.0307\n",
      "[iter 23] loss=-0.5883 val_loss=-0.3799 scale=2.0000 norm=2.0272\n",
      "[iter 24] loss=-0.5909 val_loss=-0.3824 scale=2.0000 norm=2.0243\n",
      "[iter 25] loss=-0.5933 val_loss=-0.3847 scale=2.0000 norm=2.0218\n",
      "[iter 26] loss=-0.5955 val_loss=-0.3868 scale=2.0000 norm=2.0197\n",
      "[iter 27] loss=-0.5976 val_loss=-0.3887 scale=2.0000 norm=2.0180\n",
      "[iter 28] loss=-0.5995 val_loss=-0.3904 scale=2.0000 norm=2.0166\n",
      "[iter 29] loss=-0.6012 val_loss=-0.3919 scale=2.0000 norm=2.0154\n",
      "[iter 30] loss=-0.6028 val_loss=-0.3933 scale=2.0000 norm=2.0145\n",
      "[iter 31] loss=-0.6043 val_loss=-0.3946 scale=2.0000 norm=2.0138\n",
      "[iter 32] loss=-0.6056 val_loss=-0.3957 scale=2.0000 norm=2.0133\n",
      "[iter 33] loss=-0.6069 val_loss=-0.3968 scale=2.0000 norm=2.0130\n",
      "[iter 34] loss=-0.6080 val_loss=-0.3976 scale=2.0000 norm=2.0128\n",
      "[iter 35] loss=-0.6091 val_loss=-0.3985 scale=2.0000 norm=2.0127\n",
      "[iter 36] loss=-0.6101 val_loss=-0.3991 scale=2.0000 norm=2.0127\n",
      "[iter 37] loss=-0.6110 val_loss=-0.3997 scale=2.0000 norm=2.0129\n",
      "[iter 38] loss=-0.6118 val_loss=-0.4002 scale=2.0000 norm=2.0131\n",
      "[iter 39] loss=-0.6126 val_loss=-0.4007 scale=2.0000 norm=2.0134\n",
      "[iter 40] loss=-0.6133 val_loss=-0.4010 scale=2.0000 norm=2.0137\n",
      "[iter 41] loss=-0.6139 val_loss=-0.4013 scale=2.0000 norm=2.0141\n",
      "[iter 42] loss=-0.6145 val_loss=-0.4015 scale=2.0000 norm=2.0145\n",
      "[iter 43] loss=-0.6151 val_loss=-0.4017 scale=2.0000 norm=2.0150\n",
      "[iter 44] loss=-0.6156 val_loss=-0.4018 scale=2.0000 norm=2.0155\n",
      "[iter 45] loss=-0.6160 val_loss=-0.4019 scale=2.0000 norm=2.0160\n",
      "[iter 46] loss=-0.6164 val_loss=-0.4019 scale=2.0000 norm=2.0165\n",
      "[iter 47] loss=-0.6168 val_loss=-0.4020 scale=2.0000 norm=2.0171\n",
      "[iter 48] loss=-0.6172 val_loss=-0.4019 scale=2.0000 norm=2.0176\n",
      "[iter 49] loss=-0.6175 val_loss=-0.4018 scale=2.0000 norm=2.0182\n",
      "[iter 50] loss=-0.6178 val_loss=-0.4018 scale=2.0000 norm=2.0187\n",
      "[iter 51] loss=-0.6181 val_loss=-0.4018 scale=2.0000 norm=2.0193\n",
      "[iter 52] loss=-0.6183 val_loss=-0.4017 scale=2.0000 norm=2.0198\n",
      "[iter 53] loss=-0.6186 val_loss=-0.4015 scale=2.0000 norm=2.0203\n",
      "[iter 54] loss=-0.6188 val_loss=-0.4014 scale=2.0000 norm=2.0208\n",
      "[iter 55] loss=-0.6190 val_loss=-0.4011 scale=2.0000 norm=2.0213\n",
      "[iter 56] loss=-0.6192 val_loss=-0.4010 scale=2.0000 norm=2.0218\n",
      "[iter 57] loss=-0.6193 val_loss=-0.4008 scale=2.0000 norm=2.0222\n",
      "[iter 58] loss=-0.6195 val_loss=-0.4006 scale=2.0000 norm=2.0226\n",
      "[iter 59] loss=-0.6197 val_loss=-0.4004 scale=2.0000 norm=2.0231\n",
      "[iter 60] loss=-0.6198 val_loss=-0.4001 scale=2.0000 norm=2.0235\n",
      "[iter 61] loss=-0.6199 val_loss=-0.3999 scale=2.0000 norm=2.0239\n",
      "[iter 62] loss=-0.6200 val_loss=-0.3996 scale=2.0000 norm=2.0243\n",
      "[iter 63] loss=-0.6202 val_loss=-0.3994 scale=2.0000 norm=2.0247\n",
      "[iter 64] loss=-0.6203 val_loss=-0.3991 scale=2.0000 norm=2.0250\n",
      "[iter 65] loss=-0.6203 val_loss=-0.3988 scale=2.0000 norm=2.0254\n",
      "[iter 66] loss=-0.6204 val_loss=-0.3986 scale=2.0000 norm=2.0257\n",
      "[iter 67] loss=-0.6205 val_loss=-0.3983 scale=2.0000 norm=2.0260\n",
      "[iter 68] loss=-0.6206 val_loss=-0.3980 scale=2.0000 norm=2.0263\n",
      "[iter 69] loss=-0.6207 val_loss=-0.3977 scale=2.0000 norm=2.0266\n",
      "[iter 70] loss=-0.6207 val_loss=-0.3974 scale=2.0000 norm=2.0269\n",
      "[iter 71] loss=-0.6208 val_loss=-0.3972 scale=2.0000 norm=2.0271\n",
      "[iter 72] loss=-0.6208 val_loss=-0.3969 scale=2.0000 norm=2.0274\n",
      "[iter 73] loss=-0.6209 val_loss=-0.3967 scale=2.0000 norm=2.0276\n",
      "[iter 74] loss=-0.6210 val_loss=-0.3964 scale=2.0000 norm=2.0278\n",
      "[iter 75] loss=-0.6210 val_loss=-0.3962 scale=2.0000 norm=2.0281\n",
      "[iter 76] loss=-0.6211 val_loss=-0.3959 scale=2.0000 norm=2.0283\n",
      "[iter 77] loss=-0.6211 val_loss=-0.3956 scale=2.0000 norm=2.0284\n",
      "[iter 78] loss=-0.6211 val_loss=-0.3954 scale=2.0000 norm=2.0286\n",
      "[iter 79] loss=-0.6212 val_loss=-0.3952 scale=2.0000 norm=2.0288\n",
      "[iter 80] loss=-0.6212 val_loss=-0.3949 scale=2.0000 norm=2.0290\n",
      "[iter 81] loss=-0.6213 val_loss=-0.3946 scale=2.0000 norm=2.0291\n",
      "[iter 82] loss=-0.6213 val_loss=-0.3943 scale=2.0000 norm=2.0292\n",
      "[iter 83] loss=-0.6213 val_loss=-0.3941 scale=2.0000 norm=2.0294\n",
      "[iter 84] loss=-0.6214 val_loss=-0.3940 scale=1.0000 norm=1.0147\n",
      "[iter 85] loss=-0.6214 val_loss=-0.3938 scale=2.0000 norm=2.0294\n",
      "[iter 86] loss=-0.6215 val_loss=-0.3936 scale=2.0000 norm=2.0296\n",
      "[iter 87] loss=-0.6215 val_loss=-0.3934 scale=2.0000 norm=2.0297\n",
      "[iter 88] loss=-0.6215 val_loss=-0.3932 scale=2.0000 norm=2.0298\n",
      "[iter 89] loss=-0.6215 val_loss=-0.3931 scale=2.0000 norm=2.0299\n",
      "[iter 90] loss=-0.6216 val_loss=-0.3930 scale=1.0000 norm=1.0150\n",
      "[iter 91] loss=-0.6216 val_loss=-0.3929 scale=1.0000 norm=1.0150\n",
      "[iter 92] loss=-0.6216 val_loss=-0.3929 scale=1.0000 norm=1.0150\n",
      "[iter 93] loss=-0.6217 val_loss=-0.3927 scale=2.0000 norm=2.0300\n",
      "[iter 94] loss=-0.6217 val_loss=-0.3926 scale=2.0000 norm=2.0301\n",
      "[iter 95] loss=-0.6217 val_loss=-0.3925 scale=1.0000 norm=1.0151\n",
      "[iter 96] loss=-0.6217 val_loss=-0.3923 scale=2.0000 norm=2.0302\n",
      "[iter 97] loss=-0.6217 val_loss=-0.3921 scale=2.0000 norm=2.0303\n",
      "[iter 98] loss=-0.6218 val_loss=-0.3920 scale=1.0000 norm=1.0152\n",
      "[iter 99] loss=-0.6218 val_loss=-0.3919 scale=1.0000 norm=1.0152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537649</td>\n",
       "      <td>0.145426</td>\n",
       "      <td>2.751427</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.021762</td>\n",
       "      <td>0.470965</td>\n",
       "      <td>0.310102</td>\n",
       "      <td>-8.188232</td>\n",
       "      <td>2.620279</td>\n",
       "      <td>-0.310102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.538279</td>\n",
       "      <td>0.140797</td>\n",
       "      <td>2.840580</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.482642</td>\n",
       "      <td>0.313692</td>\n",
       "      <td>-8.773340</td>\n",
       "      <td>2.593023</td>\n",
       "      <td>-0.313692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.540054</td>\n",
       "      <td>0.130817</td>\n",
       "      <td>3.017881</td>\n",
       "      <td>0.105717</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.493840</td>\n",
       "      <td>0.318430</td>\n",
       "      <td>-9.876306</td>\n",
       "      <td>2.567069</td>\n",
       "      <td>-0.318430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.543939</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>3.277068</td>\n",
       "      <td>0.105252</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.485165</td>\n",
       "      <td>0.319234</td>\n",
       "      <td>-11.912503</td>\n",
       "      <td>2.567069</td>\n",
       "      <td>-0.319234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.544089</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>3.452851</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.475086</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>-16.359392</td>\n",
       "      <td>2.565647</td>\n",
       "      <td>-0.315138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.537392</td>\n",
       "      <td>0.140868</td>\n",
       "      <td>2.455417</td>\n",
       "      <td>0.108759</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.451250</td>\n",
       "      <td>0.299585</td>\n",
       "      <td>-5.844949</td>\n",
       "      <td>2.610450</td>\n",
       "      <td>-0.299585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.140934</td>\n",
       "      <td>2.557743</td>\n",
       "      <td>0.108168</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.459892</td>\n",
       "      <td>0.300358</td>\n",
       "      <td>-6.087454</td>\n",
       "      <td>2.682225</td>\n",
       "      <td>-0.300358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.538411</td>\n",
       "      <td>0.141086</td>\n",
       "      <td>2.662264</td>\n",
       "      <td>0.107935</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.458133</td>\n",
       "      <td>0.296767</td>\n",
       "      <td>-6.608451</td>\n",
       "      <td>2.673838</td>\n",
       "      <td>-0.296767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.538613</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>2.766034</td>\n",
       "      <td>0.107272</td>\n",
       "      <td>0.022558</td>\n",
       "      <td>0.471411</td>\n",
       "      <td>0.298518</td>\n",
       "      <td>-7.351262</td>\n",
       "      <td>2.656880</td>\n",
       "      <td>-0.298518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.539023</td>\n",
       "      <td>0.145944</td>\n",
       "      <td>2.851383</td>\n",
       "      <td>0.106767</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.471582</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>-8.389071</td>\n",
       "      <td>2.640297</td>\n",
       "      <td>-0.301255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.537649           0.145426           2.751427   \n",
       "1          2            0.538279           0.140797           2.840580   \n",
       "2          3            0.540054           0.130817           3.017881   \n",
       "3          4            0.543939           0.127473           3.277068   \n",
       "4          5            0.544089           0.126221           3.452851   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.537392           0.140868           2.455417   \n",
       "92        93            0.536985           0.140934           2.557743   \n",
       "93        94            0.538411           0.141086           2.662264   \n",
       "94        95            0.538613           0.140691           2.766034   \n",
       "95        96            0.539023           0.145944           2.851383   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.106279            0.021762            0.470965  0.310102   \n",
       "1              0.106227            0.021418            0.482642  0.313692   \n",
       "2              0.105717            0.022286            0.493840  0.318430   \n",
       "3              0.105252            0.022260            0.485165  0.319234   \n",
       "4              0.104539            0.022252            0.475086  0.315138   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.108759            0.022798            0.451250  0.299585   \n",
       "92             0.108168            0.023186            0.459892  0.300358   \n",
       "93             0.107935            0.023695            0.458133  0.296767   \n",
       "94             0.107272            0.022558            0.471411  0.298518   \n",
       "95             0.106767            0.022492            0.471582  0.301255   \n",
       "\n",
       "      NLL_min   NLL_max  model_scores  \n",
       "0   -8.188232  2.620279     -0.310102  \n",
       "1   -8.773340  2.593023     -0.313692  \n",
       "2   -9.876306  2.567069     -0.318430  \n",
       "3  -11.912503  2.567069     -0.319234  \n",
       "4  -16.359392  2.565647     -0.315138  \n",
       "..        ...       ...           ...  \n",
       "91  -5.844949  2.610450     -0.299585  \n",
       "92  -6.087454  2.682225     -0.300358  \n",
       "93  -6.608451  2.673838     -0.296767  \n",
       "94  -7.351262  2.656880     -0.298518  \n",
       "95  -8.389071  2.640297     -0.301255  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.598208</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>5.76988</td>\n",
       "      <td>0.107759</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.681694</td>\n",
       "      <td>0.391899</td>\n",
       "      <td>-22.42936</td>\n",
       "      <td>2.703592</td>\n",
       "      <td>-0.391899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.598208             0.1217            5.76988   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.107759            0.020418            0.681694  0.391899   \n",
       "\n",
       "    NLL_min   NLL_max  model_scores_mean  \n",
       "0 -22.42936  2.703592          -0.391899  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.362262</td>\n",
       "      <td>0.148818</td>\n",
       "      <td>-0.432126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.374076</td>\n",
       "      <td>0.155768</td>\n",
       "      <td>-0.473793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.387520</td>\n",
       "      <td>0.153610</td>\n",
       "      <td>-0.478837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.414538</td>\n",
       "      <td>0.169451</td>\n",
       "      <td>-0.570695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.388123</td>\n",
       "      <td>0.154426</td>\n",
       "      <td>-0.478541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.641102</td>\n",
       "      <td>0.179656</td>\n",
       "      <td>-0.718106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.652189</td>\n",
       "      <td>0.184888</td>\n",
       "      <td>-0.750035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.645731</td>\n",
       "      <td>0.180766</td>\n",
       "      <td>-0.725969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.651295</td>\n",
       "      <td>0.183384</td>\n",
       "      <td>-0.741976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.666840</td>\n",
       "      <td>0.190808</td>\n",
       "      <td>-0.786595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.362262        0.148818 -0.432126\n",
       "1             2       0.374076        0.155768 -0.473793\n",
       "2             3       0.387520        0.153610 -0.478837\n",
       "3             4       0.414538        0.169451 -0.570695\n",
       "4             5       0.388123        0.154426 -0.478541\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.641102        0.179656 -0.718106\n",
       "35036     35037       0.652189        0.184888 -0.750035\n",
       "35037     35038       0.645731        0.180766 -0.725969\n",
       "35038     35039       0.651295        0.183384 -0.741976\n",
       "35039     35040       0.666840        0.190808 -0.786595\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset feature_columns                                  distribution  \\\n",
       "0  entsoe    [power_t-96]  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0961\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5835 val_loss=0.6085 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5815 scale=1.0000 norm=1.0242\n",
      "[iter 7] loss=0.5450 val_loss=0.5690 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5334 val_loss=0.5570 scale=1.0000 norm=1.0064\n",
      "[iter 9] loss=0.5223 val_loss=0.5457 scale=1.0000 norm=0.9993\n",
      "[iter 10] loss=0.5117 val_loss=0.5347 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5015 val_loss=0.5243 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4917 val_loss=0.5143 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4824 val_loss=0.5047 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4734 val_loss=0.4955 scale=1.0000 norm=0.9790\n",
      "[iter 15] loss=0.4647 val_loss=0.4866 scale=1.0000 norm=0.9776\n",
      "[iter 16] loss=0.4564 val_loss=0.4781 scale=1.0000 norm=0.9769\n",
      "[iter 17] loss=0.4484 val_loss=0.4700 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4407 val_loss=0.4621 scale=1.0000 norm=0.9779\n",
      "[iter 19] loss=0.4333 val_loss=0.4545 scale=1.0000 norm=0.9795\n",
      "[iter 20] loss=0.4261 val_loss=0.4472 scale=1.0000 norm=0.9817\n",
      "[iter 21] loss=0.4192 val_loss=0.4401 scale=1.0000 norm=0.9846\n",
      "[iter 22] loss=0.4126 val_loss=0.4333 scale=1.0000 norm=0.9881\n",
      "[iter 23] loss=0.4061 val_loss=0.4267 scale=1.0000 norm=0.9923\n",
      "[iter 24] loss=0.3999 val_loss=0.4204 scale=1.0000 norm=0.9971\n",
      "[iter 25] loss=0.3939 val_loss=0.4142 scale=1.0000 norm=1.0025\n",
      "[iter 26] loss=0.3882 val_loss=0.4083 scale=1.0000 norm=1.0084\n",
      "[iter 27] loss=0.3826 val_loss=0.4026 scale=1.0000 norm=1.0150\n",
      "[iter 28] loss=0.3772 val_loss=0.3971 scale=1.0000 norm=1.0221\n",
      "[iter 29] loss=0.3720 val_loss=0.3917 scale=1.0000 norm=1.0298\n",
      "[iter 30] loss=0.3669 val_loss=0.3866 scale=1.0000 norm=1.0381\n",
      "[iter 31] loss=0.3621 val_loss=0.3816 scale=1.0000 norm=1.0469\n",
      "[iter 32] loss=0.3574 val_loss=0.3768 scale=1.0000 norm=1.0562\n",
      "[iter 33] loss=0.3529 val_loss=0.3721 scale=1.0000 norm=1.0661\n",
      "[iter 34] loss=0.3485 val_loss=0.3676 scale=1.0000 norm=1.0766\n",
      "[iter 35] loss=0.3443 val_loss=0.3633 scale=1.0000 norm=1.0876\n",
      "[iter 36] loss=0.3402 val_loss=0.3591 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3363 val_loss=0.3551 scale=1.0000 norm=1.1112\n",
      "[iter 38] loss=0.3326 val_loss=0.3512 scale=1.0000 norm=1.1237\n",
      "[iter 39] loss=0.3289 val_loss=0.3475 scale=1.0000 norm=1.1369\n",
      "[iter 40] loss=0.3255 val_loss=0.3439 scale=1.0000 norm=1.1505\n",
      "[iter 41] loss=0.3221 val_loss=0.3404 scale=1.0000 norm=1.1646\n",
      "[iter 42] loss=0.3189 val_loss=0.3371 scale=1.0000 norm=1.1793\n",
      "[iter 43] loss=0.3158 val_loss=0.3339 scale=1.0000 norm=1.1945\n",
      "[iter 44] loss=0.3128 val_loss=0.3308 scale=1.0000 norm=1.2102\n",
      "[iter 45] loss=0.3099 val_loss=0.3278 scale=1.0000 norm=1.2264\n",
      "[iter 46] loss=0.3072 val_loss=0.3250 scale=1.0000 norm=1.2430\n",
      "[iter 47] loss=0.3045 val_loss=0.3222 scale=1.0000 norm=1.2602\n",
      "[iter 48] loss=0.3020 val_loss=0.3196 scale=1.0000 norm=1.2778\n",
      "[iter 49] loss=0.2996 val_loss=0.3171 scale=1.0000 norm=1.2958\n",
      "[iter 50] loss=0.2973 val_loss=0.3147 scale=1.0000 norm=1.3143\n",
      "[iter 51] loss=0.2951 val_loss=0.3124 scale=1.0000 norm=1.3332\n",
      "[iter 52] loss=0.2929 val_loss=0.3102 scale=1.0000 norm=1.3525\n",
      "[iter 53] loss=0.2909 val_loss=0.3081 scale=1.0000 norm=1.3723\n",
      "[iter 54] loss=0.2890 val_loss=0.3060 scale=1.0000 norm=1.3923\n",
      "[iter 55] loss=0.2871 val_loss=0.3041 scale=1.0000 norm=1.4128\n",
      "[iter 56] loss=0.2854 val_loss=0.3022 scale=1.0000 norm=1.4335\n",
      "[iter 57] loss=0.2837 val_loss=0.3004 scale=1.0000 norm=1.4545\n",
      "[iter 58] loss=0.2821 val_loss=0.2988 scale=1.0000 norm=1.4757\n",
      "[iter 59] loss=0.2805 val_loss=0.2972 scale=1.0000 norm=1.4972\n",
      "[iter 60] loss=0.2791 val_loss=0.2956 scale=1.0000 norm=1.5189\n",
      "[iter 61] loss=0.2777 val_loss=0.2942 scale=1.0000 norm=1.5407\n",
      "[iter 62] loss=0.2764 val_loss=0.2928 scale=1.0000 norm=1.5627\n",
      "[iter 63] loss=0.2751 val_loss=0.2915 scale=1.0000 norm=1.5848\n",
      "[iter 64] loss=0.2739 val_loss=0.2903 scale=1.0000 norm=1.6071\n",
      "[iter 65] loss=0.2728 val_loss=0.2891 scale=1.0000 norm=1.6295\n",
      "[iter 66] loss=0.2717 val_loss=0.2880 scale=1.0000 norm=1.6519\n",
      "[iter 67] loss=0.2707 val_loss=0.2869 scale=1.0000 norm=1.6744\n",
      "[iter 68] loss=0.2697 val_loss=0.2859 scale=1.0000 norm=1.6969\n",
      "[iter 69] loss=0.2688 val_loss=0.2850 scale=1.0000 norm=1.7195\n",
      "[iter 70] loss=0.2679 val_loss=0.2841 scale=1.0000 norm=1.7419\n",
      "[iter 71] loss=0.2671 val_loss=0.2832 scale=1.0000 norm=1.7643\n",
      "[iter 72] loss=0.2663 val_loss=0.2825 scale=1.0000 norm=1.7867\n",
      "[iter 73] loss=0.2656 val_loss=0.2817 scale=1.0000 norm=1.8089\n",
      "[iter 74] loss=0.2649 val_loss=0.2810 scale=1.0000 norm=1.8310\n",
      "[iter 75] loss=0.2643 val_loss=0.2804 scale=1.0000 norm=1.8528\n",
      "[iter 76] loss=0.2637 val_loss=0.2798 scale=1.0000 norm=1.8742\n",
      "[iter 77] loss=0.2631 val_loss=0.2792 scale=1.0000 norm=1.8954\n",
      "[iter 78] loss=0.2625 val_loss=0.2787 scale=1.0000 norm=1.9164\n",
      "[iter 79] loss=0.2620 val_loss=0.2782 scale=1.0000 norm=1.9371\n",
      "[iter 80] loss=0.2615 val_loss=0.2777 scale=1.0000 norm=1.9571\n",
      "[iter 81] loss=0.2611 val_loss=0.2773 scale=1.0000 norm=1.9771\n",
      "[iter 82] loss=0.2606 val_loss=0.2771 scale=0.5000 norm=0.9983\n",
      "[iter 83] loss=0.2604 val_loss=0.2769 scale=0.5000 norm=1.0028\n",
      "[iter 84] loss=0.2602 val_loss=0.2767 scale=0.5000 norm=1.0074\n",
      "[iter 85] loss=0.2600 val_loss=0.2763 scale=1.0000 norm=2.0237\n",
      "[iter 86] loss=0.2597 val_loss=0.2761 scale=0.5000 norm=1.0209\n",
      "[iter 87] loss=0.2595 val_loss=0.2758 scale=1.0000 norm=2.0507\n",
      "[iter 88] loss=0.2592 val_loss=0.2757 scale=0.5000 norm=1.0342\n",
      "[iter 89] loss=0.2590 val_loss=0.2755 scale=0.5000 norm=1.0386\n",
      "[iter 90] loss=0.2589 val_loss=0.2754 scale=0.5000 norm=1.0430\n",
      "[iter 91] loss=0.2587 val_loss=0.2753 scale=0.5000 norm=1.0473\n",
      "[iter 92] loss=0.2586 val_loss=0.2751 scale=0.5000 norm=1.0516\n",
      "[iter 93] loss=0.2585 val_loss=0.2750 scale=0.5000 norm=1.0559\n",
      "[iter 94] loss=0.2584 val_loss=0.2749 scale=0.5000 norm=1.0601\n",
      "[iter 95] loss=0.2582 val_loss=0.2748 scale=0.5000 norm=1.0644\n",
      "[iter 96] loss=0.2581 val_loss=0.2747 scale=0.5000 norm=1.0686\n",
      "[iter 97] loss=0.2580 val_loss=0.2746 scale=1.0000 norm=2.1455\n",
      "[iter 98] loss=0.2578 val_loss=0.2745 scale=0.5000 norm=1.0814\n",
      "[iter 99] loss=0.2577 val_loss=0.2744 scale=0.5000 norm=1.0852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.264119</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>1.843364</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.246034</td>\n",
       "      <td>1.181318</td>\n",
       "      <td>-4.452546</td>\n",
       "      <td>3.239751</td>\n",
       "      <td>0.264119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.256047</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>1.826902</td>\n",
       "      <td>0.042521</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.245063</td>\n",
       "      <td>1.220266</td>\n",
       "      <td>-4.875345</td>\n",
       "      <td>3.197452</td>\n",
       "      <td>0.256047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.255210</td>\n",
       "      <td>0.042522</td>\n",
       "      <td>1.847871</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.250181</td>\n",
       "      <td>1.224061</td>\n",
       "      <td>-5.582254</td>\n",
       "      <td>3.184421</td>\n",
       "      <td>0.255210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.263589</td>\n",
       "      <td>0.040177</td>\n",
       "      <td>1.935265</td>\n",
       "      <td>0.043666</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>1.181143</td>\n",
       "      <td>-6.810906</td>\n",
       "      <td>3.194656</td>\n",
       "      <td>0.263589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.276389</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>2.350113</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.264569</td>\n",
       "      <td>1.095351</td>\n",
       "      <td>-13.806473</td>\n",
       "      <td>3.280074</td>\n",
       "      <td>0.276389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.248994</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>1.477869</td>\n",
       "      <td>0.042808</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.492718</td>\n",
       "      <td>1.220676</td>\n",
       "      <td>-7.945705</td>\n",
       "      <td>3.371682</td>\n",
       "      <td>0.248994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.255955</td>\n",
       "      <td>0.042142</td>\n",
       "      <td>1.573762</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.510068</td>\n",
       "      <td>1.188542</td>\n",
       "      <td>-8.208379</td>\n",
       "      <td>3.409821</td>\n",
       "      <td>0.255955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>1.656464</td>\n",
       "      <td>0.042216</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>1.228028</td>\n",
       "      <td>-6.596305</td>\n",
       "      <td>3.403516</td>\n",
       "      <td>0.248534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.247176</td>\n",
       "      <td>0.040990</td>\n",
       "      <td>1.762140</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.367759</td>\n",
       "      <td>1.239769</td>\n",
       "      <td>-5.086997</td>\n",
       "      <td>3.355049</td>\n",
       "      <td>0.247176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.252901</td>\n",
       "      <td>0.038293</td>\n",
       "      <td>1.822399</td>\n",
       "      <td>0.042070</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.264641</td>\n",
       "      <td>1.228453</td>\n",
       "      <td>-4.124133</td>\n",
       "      <td>3.301078</td>\n",
       "      <td>0.252901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.264119           0.039231           1.843364   \n",
       "1          2            0.256047           0.040304           1.826902   \n",
       "2          3            0.255210           0.042522           1.847871   \n",
       "3          4            0.263589           0.040177           1.935265   \n",
       "4          5            0.276389           0.037387           2.350113   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.248994           0.042107           1.477869   \n",
       "92        93            0.255955           0.042142           1.573762   \n",
       "93        94            0.248534           0.041178           1.656464   \n",
       "94        95            0.247176           0.040990           1.762140   \n",
       "95        96            0.252901           0.038293           1.822399   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.043700            0.007590            0.246034  1.181318   \n",
       "1              0.042521            0.007338            0.245063  1.220266   \n",
       "2              0.042479            0.007353            0.250181  1.224061   \n",
       "3              0.043666            0.007335            0.256068  1.181143   \n",
       "4              0.046109            0.007356            0.264569  1.095351   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.042808            0.007356            0.492718  1.220676   \n",
       "92             0.043565            0.007415            0.510068  1.188542   \n",
       "93             0.042216            0.007543            0.455700  1.228028   \n",
       "94             0.041710            0.007644            0.367759  1.239769   \n",
       "95             0.042070            0.007639            0.264641  1.228453   \n",
       "\n",
       "      NLL_min   NLL_max  model_scores  \n",
       "0   -4.452546  3.239751      0.264119  \n",
       "1   -4.875345  3.197452      0.256047  \n",
       "2   -5.582254  3.184421      0.255210  \n",
       "3   -6.810906  3.194656      0.263589  \n",
       "4  -13.806473  3.280074      0.276389  \n",
       "..        ...       ...           ...  \n",
       "91  -7.945705  3.371682      0.248994  \n",
       "92  -8.208379  3.409821      0.255955  \n",
       "93  -6.596305  3.403516      0.248534  \n",
       "94  -5.086997  3.355049      0.247176  \n",
       "95  -4.124133  3.301078      0.252901  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.274447</td>\n",
       "      <td>0.036167</td>\n",
       "      <td>5.30723</td>\n",
       "      <td>0.041566</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.517243</td>\n",
       "      <td>1.300109</td>\n",
       "      <td>-25.411731</td>\n",
       "      <td>3.654129</td>\n",
       "      <td>0.274447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.274447           0.036167            5.30723   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.041566            0.007335            0.517243  1.300109   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -25.411731  3.654129           0.274447  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128530</td>\n",
       "      <td>0.084984</td>\n",
       "      <td>0.672531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>0.080946</td>\n",
       "      <td>0.713430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.147393</td>\n",
       "      <td>0.096697</td>\n",
       "      <td>0.542058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.122406</td>\n",
       "      <td>0.083131</td>\n",
       "      <td>0.689244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.163583</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.408125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.317015</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>-0.374866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.345987</td>\n",
       "      <td>0.132514</td>\n",
       "      <td>-0.614721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.317944</td>\n",
       "      <td>0.121215</td>\n",
       "      <td>-0.382897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.301698</td>\n",
       "      <td>0.116607</td>\n",
       "      <td>-0.269452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.315853</td>\n",
       "      <td>0.124870</td>\n",
       "      <td>-0.512466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.128530        0.084984  0.672531\n",
       "1             2       0.120391        0.080946  0.713430\n",
       "2             3       0.147393        0.096697  0.542058\n",
       "3             4       0.122406        0.083131  0.689244\n",
       "4             5       0.163583        0.108400  0.408125\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.317015        0.120779 -0.374866\n",
       "35036     35037       0.345987        0.132514 -0.614721\n",
       "35037     35038       0.317944        0.121215 -0.382897\n",
       "35038     35039       0.301698        0.116607 -0.269452\n",
       "35039     35040       0.315853        0.124870 -0.512466\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[ws_10m_loc_mean, ws_100m_loc_mean]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                      feature_columns  \\\n",
       "0  entsoe  [ws_10m_loc_mean, ws_100m_loc_mean]   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3017 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5238 val_loss=-0.3343 scale=1.0000 norm=1.0747\n",
      "[iter 2] loss=-0.5560 val_loss=-0.3633 scale=1.0000 norm=1.0446\n",
      "[iter 3] loss=-0.5843 val_loss=-0.3893 scale=1.0000 norm=1.0181\n",
      "[iter 4] loss=-0.6097 val_loss=-0.4362 scale=2.0000 norm=1.9884\n",
      "[iter 5] loss=-0.6553 val_loss=-0.4763 scale=2.0000 norm=1.9030\n",
      "[iter 6] loss=-0.6946 val_loss=-0.5120 scale=2.0000 norm=1.8300\n",
      "[iter 7] loss=-0.7297 val_loss=-0.5448 scale=2.0000 norm=1.7662\n",
      "[iter 8] loss=-0.7618 val_loss=-0.5749 scale=2.0000 norm=1.7097\n",
      "[iter 9] loss=-0.7915 val_loss=-0.6032 scale=2.0000 norm=1.6596\n",
      "[iter 10] loss=-0.8195 val_loss=-0.6298 scale=2.0000 norm=1.6145\n",
      "[iter 11] loss=-0.8460 val_loss=-0.6550 scale=2.0000 norm=1.5742\n",
      "[iter 12] loss=-0.8712 val_loss=-0.6792 scale=2.0000 norm=1.5380\n",
      "[iter 13] loss=-0.8953 val_loss=-0.7023 scale=2.0000 norm=1.5054\n",
      "[iter 14] loss=-0.9184 val_loss=-0.7246 scale=2.0000 norm=1.4762\n",
      "[iter 15] loss=-0.9409 val_loss=-0.7460 scale=2.0000 norm=1.4498\n",
      "[iter 16] loss=-0.9625 val_loss=-0.7667 scale=2.0000 norm=1.4263\n",
      "[iter 17] loss=-0.9834 val_loss=-0.7868 scale=2.0000 norm=1.4052\n",
      "[iter 18] loss=-1.0037 val_loss=-0.8062 scale=2.0000 norm=1.3861\n",
      "[iter 19] loss=-1.0234 val_loss=-0.8251 scale=2.0000 norm=1.3691\n",
      "[iter 20] loss=-1.0425 val_loss=-0.8433 scale=2.0000 norm=1.3538\n",
      "[iter 21] loss=-1.0611 val_loss=-0.8610 scale=2.0000 norm=1.3401\n",
      "[iter 22] loss=-1.0791 val_loss=-0.8782 scale=2.0000 norm=1.3279\n",
      "[iter 23] loss=-1.0966 val_loss=-0.8948 scale=2.0000 norm=1.3170\n",
      "[iter 24] loss=-1.1136 val_loss=-0.9110 scale=2.0000 norm=1.3073\n",
      "[iter 25] loss=-1.1301 val_loss=-0.9266 scale=2.0000 norm=1.2987\n",
      "[iter 26] loss=-1.1461 val_loss=-0.9419 scale=2.0000 norm=1.2911\n",
      "[iter 27] loss=-1.1617 val_loss=-0.9566 scale=2.0000 norm=1.2843\n",
      "[iter 28] loss=-1.1768 val_loss=-0.9708 scale=2.0000 norm=1.2784\n",
      "[iter 29] loss=-1.1914 val_loss=-0.9846 scale=2.0000 norm=1.2733\n",
      "[iter 30] loss=-1.2056 val_loss=-0.9980 scale=2.0000 norm=1.2688\n",
      "[iter 31] loss=-1.2193 val_loss=-1.0109 scale=2.0000 norm=1.2649\n",
      "[iter 32] loss=-1.2326 val_loss=-1.0235 scale=2.0000 norm=1.2616\n",
      "[iter 33] loss=-1.2455 val_loss=-1.0356 scale=2.0000 norm=1.2588\n",
      "[iter 34] loss=-1.2579 val_loss=-1.0473 scale=2.0000 norm=1.2564\n",
      "[iter 35] loss=-1.2699 val_loss=-1.0587 scale=2.0000 norm=1.2545\n",
      "[iter 36] loss=-1.2816 val_loss=-1.0697 scale=2.0000 norm=1.2529\n",
      "[iter 37] loss=-1.2929 val_loss=-1.0802 scale=2.0000 norm=1.2517\n",
      "[iter 38] loss=-1.3038 val_loss=-1.0905 scale=2.0000 norm=1.2508\n",
      "[iter 39] loss=-1.3143 val_loss=-1.1003 scale=2.0000 norm=1.2503\n",
      "[iter 40] loss=-1.3244 val_loss=-1.1098 scale=2.0000 norm=1.2499\n",
      "[iter 41] loss=-1.3342 val_loss=-1.1190 scale=2.0000 norm=1.2498\n",
      "[iter 42] loss=-1.3436 val_loss=-1.1279 scale=2.0000 norm=1.2500\n",
      "[iter 43] loss=-1.3527 val_loss=-1.1364 scale=2.0000 norm=1.2503\n",
      "[iter 44] loss=-1.3615 val_loss=-1.1446 scale=2.0000 norm=1.2508\n",
      "[iter 45] loss=-1.3699 val_loss=-1.1525 scale=2.0000 norm=1.2516\n",
      "[iter 46] loss=-1.3780 val_loss=-1.1601 scale=2.0000 norm=1.2524\n",
      "[iter 47] loss=-1.3859 val_loss=-1.1674 scale=2.0000 norm=1.2534\n",
      "[iter 48] loss=-1.3934 val_loss=-1.1744 scale=2.0000 norm=1.2545\n",
      "[iter 49] loss=-1.4006 val_loss=-1.1812 scale=2.0000 norm=1.2557\n",
      "[iter 50] loss=-1.4076 val_loss=-1.1876 scale=2.0000 norm=1.2570\n",
      "[iter 51] loss=-1.4142 val_loss=-1.1938 scale=2.0000 norm=1.2585\n",
      "[iter 52] loss=-1.4207 val_loss=-1.1998 scale=2.0000 norm=1.2600\n",
      "[iter 53] loss=-1.4268 val_loss=-1.2055 scale=2.0000 norm=1.2615\n",
      "[iter 54] loss=-1.4327 val_loss=-1.2110 scale=2.0000 norm=1.2632\n",
      "[iter 55] loss=-1.4384 val_loss=-1.2163 scale=2.0000 norm=1.2649\n",
      "[iter 56] loss=-1.4438 val_loss=-1.2213 scale=2.0000 norm=1.2667\n",
      "[iter 57] loss=-1.4490 val_loss=-1.2261 scale=2.0000 norm=1.2685\n",
      "[iter 58] loss=-1.4540 val_loss=-1.2306 scale=2.0000 norm=1.2704\n",
      "[iter 59] loss=-1.4587 val_loss=-1.2350 scale=2.0000 norm=1.2723\n",
      "[iter 60] loss=-1.4633 val_loss=-1.2391 scale=2.0000 norm=1.2741\n",
      "[iter 61] loss=-1.4677 val_loss=-1.2431 scale=2.0000 norm=1.2761\n",
      "[iter 62] loss=-1.4719 val_loss=-1.2469 scale=2.0000 norm=1.2780\n",
      "[iter 63] loss=-1.4758 val_loss=-1.2504 scale=2.0000 norm=1.2800\n",
      "[iter 64] loss=-1.4797 val_loss=-1.2537 scale=2.0000 norm=1.2820\n",
      "[iter 65] loss=-1.4833 val_loss=-1.2569 scale=2.0000 norm=1.2840\n",
      "[iter 66] loss=-1.4868 val_loss=-1.2600 scale=2.0000 norm=1.2859\n",
      "[iter 67] loss=-1.4901 val_loss=-1.2629 scale=2.0000 norm=1.2879\n",
      "[iter 68] loss=-1.4933 val_loss=-1.2657 scale=2.0000 norm=1.2899\n",
      "[iter 69] loss=-1.4963 val_loss=-1.2683 scale=2.0000 norm=1.2919\n",
      "[iter 70] loss=-1.4992 val_loss=-1.2707 scale=2.0000 norm=1.2938\n",
      "[iter 71] loss=-1.5019 val_loss=-1.2730 scale=2.0000 norm=1.2958\n",
      "[iter 72] loss=-1.5045 val_loss=-1.2751 scale=2.0000 norm=1.2978\n",
      "[iter 73] loss=-1.5070 val_loss=-1.2770 scale=2.0000 norm=1.2997\n",
      "[iter 74] loss=-1.5093 val_loss=-1.2789 scale=2.0000 norm=1.3016\n",
      "[iter 75] loss=-1.5115 val_loss=-1.2806 scale=2.0000 norm=1.3036\n",
      "[iter 76] loss=-1.5136 val_loss=-1.2822 scale=2.0000 norm=1.3054\n",
      "[iter 77] loss=-1.5156 val_loss=-1.2836 scale=2.0000 norm=1.3073\n",
      "[iter 78] loss=-1.5175 val_loss=-1.2850 scale=2.0000 norm=1.3092\n",
      "[iter 79] loss=-1.5193 val_loss=-1.2863 scale=2.0000 norm=1.3110\n",
      "[iter 80] loss=-1.5210 val_loss=-1.2875 scale=2.0000 norm=1.3128\n",
      "[iter 81] loss=-1.5226 val_loss=-1.2886 scale=2.0000 norm=1.3146\n",
      "[iter 82] loss=-1.5242 val_loss=-1.2896 scale=2.0000 norm=1.3163\n",
      "[iter 83] loss=-1.5256 val_loss=-1.2905 scale=2.0000 norm=1.3180\n",
      "[iter 84] loss=-1.5269 val_loss=-1.2915 scale=2.0000 norm=1.3197\n",
      "[iter 85] loss=-1.5282 val_loss=-1.2924 scale=2.0000 norm=1.3214\n",
      "[iter 86] loss=-1.5295 val_loss=-1.2931 scale=2.0000 norm=1.3230\n",
      "[iter 87] loss=-1.5306 val_loss=-1.2936 scale=2.0000 norm=1.3246\n",
      "[iter 88] loss=-1.5317 val_loss=-1.2940 scale=2.0000 norm=1.3261\n",
      "[iter 89] loss=-1.5326 val_loss=-1.2945 scale=2.0000 norm=1.3275\n",
      "[iter 90] loss=-1.5336 val_loss=-1.2949 scale=2.0000 norm=1.3290\n",
      "[iter 91] loss=-1.5345 val_loss=-1.2952 scale=2.0000 norm=1.3305\n",
      "[iter 92] loss=-1.5353 val_loss=-1.2956 scale=2.0000 norm=1.3318\n",
      "[iter 93] loss=-1.5362 val_loss=-1.2958 scale=2.0000 norm=1.3331\n",
      "[iter 94] loss=-1.5369 val_loss=-1.2960 scale=2.0000 norm=1.3345\n",
      "[iter 95] loss=-1.5376 val_loss=-1.2961 scale=2.0000 norm=1.3357\n",
      "[iter 96] loss=-1.5383 val_loss=-1.2960 scale=2.0000 norm=1.3369\n",
      "[iter 97] loss=-1.5389 val_loss=-1.2961 scale=2.0000 norm=1.3379\n",
      "[iter 98] loss=-1.5396 val_loss=-1.2962 scale=2.0000 norm=1.3389\n",
      "[iter 99] loss=-1.5401 val_loss=-1.2964 scale=2.0000 norm=1.3399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.271728</td>\n",
       "      <td>0.041820</td>\n",
       "      <td>1.953793</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.250761</td>\n",
       "      <td>1.161059</td>\n",
       "      <td>-3.988761</td>\n",
       "      <td>3.405587</td>\n",
       "      <td>-1.161059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.262807</td>\n",
       "      <td>0.040593</td>\n",
       "      <td>1.930249</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.250857</td>\n",
       "      <td>1.199437</td>\n",
       "      <td>-3.768256</td>\n",
       "      <td>3.349743</td>\n",
       "      <td>-1.199437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.261835</td>\n",
       "      <td>0.040505</td>\n",
       "      <td>1.834736</td>\n",
       "      <td>0.043404</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.256465</td>\n",
       "      <td>1.207751</td>\n",
       "      <td>-3.856627</td>\n",
       "      <td>3.333885</td>\n",
       "      <td>-1.207751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.269821</td>\n",
       "      <td>0.042896</td>\n",
       "      <td>1.853216</td>\n",
       "      <td>0.044489</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.264082</td>\n",
       "      <td>1.174168</td>\n",
       "      <td>-4.507171</td>\n",
       "      <td>3.333188</td>\n",
       "      <td>-1.174168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.283085</td>\n",
       "      <td>0.041418</td>\n",
       "      <td>2.259513</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>1.099896</td>\n",
       "      <td>-10.478718</td>\n",
       "      <td>3.428716</td>\n",
       "      <td>-1.099896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.259767</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>1.460305</td>\n",
       "      <td>0.043793</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.488821</td>\n",
       "      <td>1.195623</td>\n",
       "      <td>-7.124445</td>\n",
       "      <td>3.609593</td>\n",
       "      <td>-1.195623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.266221</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>1.512399</td>\n",
       "      <td>0.044522</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.505565</td>\n",
       "      <td>1.168480</td>\n",
       "      <td>-7.409930</td>\n",
       "      <td>3.637677</td>\n",
       "      <td>-1.168480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.256901</td>\n",
       "      <td>0.041248</td>\n",
       "      <td>1.599509</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.455126</td>\n",
       "      <td>1.203468</td>\n",
       "      <td>-5.986289</td>\n",
       "      <td>3.630425</td>\n",
       "      <td>-1.203468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.254593</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>1.709396</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.366850</td>\n",
       "      <td>1.213424</td>\n",
       "      <td>-4.497794</td>\n",
       "      <td>3.547989</td>\n",
       "      <td>-1.213424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.259786</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.766724</td>\n",
       "      <td>0.043098</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.261019</td>\n",
       "      <td>1.202835</td>\n",
       "      <td>-4.051792</td>\n",
       "      <td>3.490926</td>\n",
       "      <td>-1.202835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.271728           0.041820           1.953793   \n",
       "1          2            0.262807           0.040593           1.930249   \n",
       "2          3            0.261835           0.040505           1.834736   \n",
       "3          4            0.269821           0.042896           1.853216   \n",
       "4          5            0.283085           0.041418           2.259513   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.259767           0.041103           1.460305   \n",
       "92        93            0.266221           0.040737           1.512399   \n",
       "93        94            0.256901           0.041248           1.599509   \n",
       "94        95            0.254593           0.041120           1.709396   \n",
       "95        96            0.259786           0.041400           1.766724   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.044748            0.005005            0.250761  1.161059   \n",
       "1              0.043508            0.004727            0.250857  1.199437   \n",
       "2              0.043404            0.004561            0.256465  1.207751   \n",
       "3              0.044489            0.004429            0.264082  1.174168   \n",
       "4              0.046792            0.004689            0.273333  1.099896   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.043793            0.005054            0.488821  1.195623   \n",
       "92             0.044522            0.004841            0.505565  1.168480   \n",
       "93             0.043210            0.004611            0.455126  1.203468   \n",
       "94             0.042774            0.004310            0.366850  1.213424   \n",
       "95             0.043098            0.004733            0.261019  1.202835   \n",
       "\n",
       "      NLL_min   NLL_max  model_scores  \n",
       "0   -3.988761  3.405587     -1.161059  \n",
       "1   -3.768256  3.349743     -1.199437  \n",
       "2   -3.856627  3.333885     -1.207751  \n",
       "3   -4.507171  3.333188     -1.174168  \n",
       "4  -10.478718  3.428716     -1.099896  \n",
       "..        ...       ...           ...  \n",
       "91  -7.124445  3.609593     -1.195623  \n",
       "92  -7.409930  3.637677     -1.168480  \n",
       "93  -5.986289  3.630425     -1.203468  \n",
       "94  -4.497794  3.547989     -1.213424  \n",
       "95  -4.051792  3.490926     -1.202835  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.040505</td>\n",
       "      <td>5.272066</td>\n",
       "      <td>0.04225</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.518075</td>\n",
       "      <td>1.296382</td>\n",
       "      <td>-19.878298</td>\n",
       "      <td>4.079381</td>\n",
       "      <td>-1.296382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.277985           0.040505           5.272066   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.04225            0.004093            0.518075  1.296382   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -19.878298  4.079381          -1.296382  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125016</td>\n",
       "      <td>0.082080</td>\n",
       "      <td>0.699680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>0.077875</td>\n",
       "      <td>0.748392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.144306</td>\n",
       "      <td>0.094028</td>\n",
       "      <td>0.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.117909</td>\n",
       "      <td>0.079396</td>\n",
       "      <td>0.729240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.160519</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>0.395533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.322599</td>\n",
       "      <td>0.121833</td>\n",
       "      <td>-0.311135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>-0.561552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.323513</td>\n",
       "      <td>0.122261</td>\n",
       "      <td>-0.318318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.310915</td>\n",
       "      <td>0.118961</td>\n",
       "      <td>-0.241827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.323876</td>\n",
       "      <td>0.126674</td>\n",
       "      <td>-0.422939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.125016        0.082080  0.699680\n",
       "1             2       0.116615        0.077875  0.748392\n",
       "2             3       0.144306        0.094028  0.552100\n",
       "3             4       0.117909        0.079396  0.729240\n",
       "4             5       0.160519        0.105475  0.395533\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.322599        0.121833 -0.311135\n",
       "35036     35037       0.357705        0.135458 -0.561552\n",
       "35037     35038       0.323513        0.122261 -0.318318\n",
       "35038     35039       0.310915        0.118961 -0.241827\n",
       "35039     35040       0.323876        0.126674 -0.422939\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[ws_10m_loc_mean, ws_100m_loc_mean]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                      feature_columns  \\\n",
       "0  entsoe  [ws_10m_loc_mean, ws_100m_loc_mean]   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6719 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6284 val_loss=0.6547 scale=1.0000 norm=1.0960\n",
      "[iter 2] loss=0.6126 val_loss=0.6384 scale=1.0000 norm=1.0779\n",
      "[iter 3] loss=0.5976 val_loss=0.6230 scale=1.0000 norm=1.0618\n",
      "[iter 4] loss=0.5834 val_loss=0.6084 scale=1.0000 norm=1.0476\n",
      "[iter 5] loss=0.5700 val_loss=0.5946 scale=1.0000 norm=1.0351\n",
      "[iter 6] loss=0.5572 val_loss=0.5814 scale=1.0000 norm=1.0241\n",
      "[iter 7] loss=0.5450 val_loss=0.5689 scale=1.0000 norm=1.0146\n",
      "[iter 8] loss=0.5333 val_loss=0.5569 scale=1.0000 norm=1.0063\n",
      "[iter 9] loss=0.5222 val_loss=0.5455 scale=1.0000 norm=0.9992\n",
      "[iter 10] loss=0.5116 val_loss=0.5346 scale=1.0000 norm=0.9933\n",
      "[iter 11] loss=0.5014 val_loss=0.5242 scale=1.0000 norm=0.9883\n",
      "[iter 12] loss=0.4916 val_loss=0.5142 scale=1.0000 norm=0.9843\n",
      "[iter 13] loss=0.4823 val_loss=0.5045 scale=1.0000 norm=0.9812\n",
      "[iter 14] loss=0.4733 val_loss=0.4953 scale=1.0000 norm=0.9789\n",
      "[iter 15] loss=0.4646 val_loss=0.4865 scale=1.0000 norm=0.9775\n",
      "[iter 16] loss=0.4563 val_loss=0.4779 scale=1.0000 norm=0.9768\n",
      "[iter 17] loss=0.4483 val_loss=0.4698 scale=1.0000 norm=0.9770\n",
      "[iter 18] loss=0.4406 val_loss=0.4619 scale=1.0000 norm=0.9778\n",
      "[iter 19] loss=0.4332 val_loss=0.4543 scale=1.0000 norm=0.9794\n",
      "[iter 20] loss=0.4260 val_loss=0.4469 scale=1.0000 norm=0.9816\n",
      "[iter 21] loss=0.4191 val_loss=0.4399 scale=1.0000 norm=0.9844\n",
      "[iter 22] loss=0.4124 val_loss=0.4330 scale=1.0000 norm=0.9879\n",
      "[iter 23] loss=0.4059 val_loss=0.4264 scale=1.0000 norm=0.9921\n",
      "[iter 24] loss=0.3997 val_loss=0.4200 scale=1.0000 norm=0.9969\n",
      "[iter 25] loss=0.3937 val_loss=0.4138 scale=1.0000 norm=1.0022\n",
      "[iter 26] loss=0.3878 val_loss=0.4078 scale=1.0000 norm=1.0082\n",
      "[iter 27] loss=0.3822 val_loss=0.4021 scale=1.0000 norm=1.0147\n",
      "[iter 28] loss=0.3767 val_loss=0.3965 scale=1.0000 norm=1.0218\n",
      "[iter 29] loss=0.3715 val_loss=0.3911 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3664 val_loss=0.3858 scale=1.0000 norm=1.0377\n",
      "[iter 31] loss=0.3614 val_loss=0.3808 scale=1.0000 norm=1.0465\n",
      "[iter 32] loss=0.3567 val_loss=0.3759 scale=1.0000 norm=1.0559\n",
      "[iter 33] loss=0.3521 val_loss=0.3711 scale=1.0000 norm=1.0658\n",
      "[iter 34] loss=0.3476 val_loss=0.3666 scale=1.0000 norm=1.0763\n",
      "[iter 35] loss=0.3433 val_loss=0.3622 scale=1.0000 norm=1.0874\n",
      "[iter 36] loss=0.3392 val_loss=0.3579 scale=1.0000 norm=1.0991\n",
      "[iter 37] loss=0.3352 val_loss=0.3538 scale=1.0000 norm=1.1113\n",
      "[iter 38] loss=0.3314 val_loss=0.3498 scale=1.0000 norm=1.1240\n",
      "[iter 39] loss=0.3277 val_loss=0.3460 scale=1.0000 norm=1.1373\n",
      "[iter 40] loss=0.3241 val_loss=0.3423 scale=1.0000 norm=1.1511\n",
      "[iter 41] loss=0.3206 val_loss=0.3387 scale=1.0000 norm=1.1655\n",
      "[iter 42] loss=0.3173 val_loss=0.3352 scale=1.0000 norm=1.1804\n",
      "[iter 43] loss=0.3141 val_loss=0.3319 scale=1.0000 norm=1.1958\n",
      "[iter 44] loss=0.3110 val_loss=0.3288 scale=1.0000 norm=1.2118\n",
      "[iter 45] loss=0.3080 val_loss=0.3257 scale=1.0000 norm=1.2283\n",
      "[iter 46] loss=0.3052 val_loss=0.3227 scale=1.0000 norm=1.2454\n",
      "[iter 47] loss=0.3025 val_loss=0.3198 scale=1.0000 norm=1.2630\n",
      "[iter 48] loss=0.2998 val_loss=0.3171 scale=1.0000 norm=1.2809\n",
      "[iter 49] loss=0.2973 val_loss=0.3144 scale=1.0000 norm=1.2993\n",
      "[iter 50] loss=0.2949 val_loss=0.3119 scale=1.0000 norm=1.3181\n",
      "[iter 51] loss=0.2925 val_loss=0.3095 scale=1.0000 norm=1.3374\n",
      "[iter 52] loss=0.2903 val_loss=0.3072 scale=1.0000 norm=1.3575\n",
      "[iter 53] loss=0.2882 val_loss=0.3049 scale=1.0000 norm=1.3777\n",
      "[iter 54] loss=0.2861 val_loss=0.3028 scale=1.0000 norm=1.3983\n",
      "[iter 55] loss=0.2842 val_loss=0.3008 scale=1.0000 norm=1.4194\n",
      "[iter 56] loss=0.2823 val_loss=0.2988 scale=1.0000 norm=1.4408\n",
      "[iter 57] loss=0.2805 val_loss=0.2969 scale=1.0000 norm=1.4627\n",
      "[iter 58] loss=0.2788 val_loss=0.2952 scale=1.0000 norm=1.4846\n",
      "[iter 59] loss=0.2772 val_loss=0.2934 scale=1.0000 norm=1.5069\n",
      "[iter 60] loss=0.2756 val_loss=0.2918 scale=1.0000 norm=1.5293\n",
      "[iter 61] loss=0.2741 val_loss=0.2903 scale=1.0000 norm=1.5520\n",
      "[iter 62] loss=0.2727 val_loss=0.2888 scale=1.0000 norm=1.5751\n",
      "[iter 63] loss=0.2713 val_loss=0.2874 scale=1.0000 norm=1.5980\n",
      "[iter 64] loss=0.2700 val_loss=0.2861 scale=1.0000 norm=1.6211\n",
      "[iter 65] loss=0.2688 val_loss=0.2847 scale=1.0000 norm=1.6443\n",
      "[iter 66] loss=0.2676 val_loss=0.2835 scale=1.0000 norm=1.6677\n",
      "[iter 67] loss=0.2665 val_loss=0.2823 scale=1.0000 norm=1.6912\n",
      "[iter 68] loss=0.2654 val_loss=0.2813 scale=1.0000 norm=1.7147\n",
      "[iter 69] loss=0.2644 val_loss=0.2802 scale=1.0000 norm=1.7387\n",
      "[iter 70] loss=0.2635 val_loss=0.2792 scale=1.0000 norm=1.7623\n",
      "[iter 71] loss=0.2626 val_loss=0.2783 scale=1.0000 norm=1.7857\n",
      "[iter 72] loss=0.2617 val_loss=0.2774 scale=1.0000 norm=1.8095\n",
      "[iter 73] loss=0.2609 val_loss=0.2765 scale=1.0000 norm=1.8328\n",
      "[iter 74] loss=0.2601 val_loss=0.2757 scale=1.0000 norm=1.8561\n",
      "[iter 75] loss=0.2594 val_loss=0.2750 scale=1.0000 norm=1.8797\n",
      "[iter 76] loss=0.2587 val_loss=0.2742 scale=1.0000 norm=1.9026\n",
      "[iter 77] loss=0.2580 val_loss=0.2736 scale=1.0000 norm=1.9252\n",
      "[iter 78] loss=0.2574 val_loss=0.2729 scale=1.0000 norm=1.9479\n",
      "[iter 79] loss=0.2568 val_loss=0.2723 scale=1.0000 norm=1.9698\n",
      "[iter 80] loss=0.2562 val_loss=0.2718 scale=1.0000 norm=1.9922\n",
      "[iter 81] loss=0.2557 val_loss=0.2713 scale=1.0000 norm=2.0139\n",
      "[iter 82] loss=0.2552 val_loss=0.2707 scale=1.0000 norm=2.0354\n",
      "[iter 83] loss=0.2548 val_loss=0.2705 scale=0.5000 norm=1.0279\n",
      "[iter 84] loss=0.2546 val_loss=0.2703 scale=0.5000 norm=1.0330\n",
      "[iter 85] loss=0.2543 val_loss=0.2701 scale=0.5000 norm=1.0381\n",
      "[iter 86] loss=0.2541 val_loss=0.2699 scale=0.5000 norm=1.0430\n",
      "[iter 87] loss=0.2539 val_loss=0.2697 scale=0.5000 norm=1.0479\n",
      "[iter 88] loss=0.2537 val_loss=0.2695 scale=0.5000 norm=1.0526\n",
      "[iter 89] loss=0.2536 val_loss=0.2693 scale=0.5000 norm=1.0573\n",
      "[iter 90] loss=0.2534 val_loss=0.2691 scale=0.5000 norm=1.0622\n",
      "[iter 91] loss=0.2532 val_loss=0.2690 scale=0.5000 norm=1.0668\n",
      "[iter 92] loss=0.2530 val_loss=0.2688 scale=0.5000 norm=1.0713\n",
      "[iter 93] loss=0.2529 val_loss=0.2687 scale=0.5000 norm=1.0758\n",
      "[iter 94] loss=0.2527 val_loss=0.2686 scale=0.5000 norm=1.0805\n",
      "[iter 95] loss=0.2526 val_loss=0.2684 scale=0.5000 norm=1.0849\n",
      "[iter 96] loss=0.2524 val_loss=0.2683 scale=0.5000 norm=1.0895\n",
      "[iter 97] loss=0.2523 val_loss=0.2682 scale=0.5000 norm=1.0941\n",
      "[iter 98] loss=0.2522 val_loss=0.2681 scale=0.5000 norm=1.0985\n",
      "[iter 99] loss=0.2520 val_loss=0.2679 scale=0.5000 norm=1.1029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.255146</td>\n",
       "      <td>0.035575</td>\n",
       "      <td>1.950867</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.256997</td>\n",
       "      <td>1.212219</td>\n",
       "      <td>-4.500322</td>\n",
       "      <td>3.416249</td>\n",
       "      <td>0.255146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.247892</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>1.923008</td>\n",
       "      <td>0.041063</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.237951</td>\n",
       "      <td>1.246805</td>\n",
       "      <td>-4.644070</td>\n",
       "      <td>3.410094</td>\n",
       "      <td>0.247892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.247589</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>1.925165</td>\n",
       "      <td>0.040956</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.240701</td>\n",
       "      <td>1.249662</td>\n",
       "      <td>-5.315924</td>\n",
       "      <td>3.399780</td>\n",
       "      <td>0.247589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.255812</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>1.928825</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.246844</td>\n",
       "      <td>1.211155</td>\n",
       "      <td>-5.384542</td>\n",
       "      <td>3.242941</td>\n",
       "      <td>0.255812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.267912</td>\n",
       "      <td>0.039314</td>\n",
       "      <td>2.191476</td>\n",
       "      <td>0.044357</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.258814</td>\n",
       "      <td>1.136819</td>\n",
       "      <td>-9.660994</td>\n",
       "      <td>3.278190</td>\n",
       "      <td>0.267912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.239934</td>\n",
       "      <td>0.043625</td>\n",
       "      <td>1.534282</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.492859</td>\n",
       "      <td>1.260699</td>\n",
       "      <td>-8.247268</td>\n",
       "      <td>3.329846</td>\n",
       "      <td>0.239934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.246606</td>\n",
       "      <td>0.043568</td>\n",
       "      <td>1.661790</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.507060</td>\n",
       "      <td>1.227222</td>\n",
       "      <td>-8.634752</td>\n",
       "      <td>3.365323</td>\n",
       "      <td>0.246606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.239288</td>\n",
       "      <td>0.043730</td>\n",
       "      <td>1.753675</td>\n",
       "      <td>0.040279</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.459845</td>\n",
       "      <td>1.271025</td>\n",
       "      <td>-6.714806</td>\n",
       "      <td>3.380517</td>\n",
       "      <td>0.239288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.237746</td>\n",
       "      <td>0.041460</td>\n",
       "      <td>1.856388</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.379221</td>\n",
       "      <td>1.279859</td>\n",
       "      <td>-5.601854</td>\n",
       "      <td>3.353540</td>\n",
       "      <td>0.237746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.243609</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>1.922606</td>\n",
       "      <td>0.040381</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>1.263059</td>\n",
       "      <td>-3.900851</td>\n",
       "      <td>3.401686</td>\n",
       "      <td>0.243609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.255146           0.035575           1.950867   \n",
       "1          2            0.247892           0.037963           1.923008   \n",
       "2          3            0.247589           0.039241           1.925165   \n",
       "3          4            0.255812           0.040879           1.928825   \n",
       "4          5            0.267912           0.039314           2.191476   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.239934           0.043625           1.534282   \n",
       "92        93            0.246606           0.043568           1.661790   \n",
       "93        94            0.239288           0.043730           1.753675   \n",
       "94        95            0.237746           0.041460           1.856388   \n",
       "95        96            0.243609           0.037074           1.922606   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.042082            0.007416            0.256997  1.212219   \n",
       "1              0.041063            0.007087            0.237951  1.246805   \n",
       "2              0.040956            0.007136            0.240701  1.249662   \n",
       "3              0.042054            0.007784            0.246844  1.211155   \n",
       "4              0.044357            0.007525            0.258814  1.136819   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.040816            0.007527            0.492859  1.260699   \n",
       "92             0.041559            0.007375            0.507060  1.227222   \n",
       "93             0.040279            0.007595            0.459845  1.271025   \n",
       "94             0.039906            0.007591            0.379221  1.279859   \n",
       "95             0.040381            0.007420            0.269625  1.263059   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -4.500322  3.416249      0.255146  \n",
       "1  -4.644070  3.410094      0.247892  \n",
       "2  -5.315924  3.399780      0.247589  \n",
       "3  -5.384542  3.242941      0.255812  \n",
       "4  -9.660994  3.278190      0.267912  \n",
       "..       ...       ...           ...  \n",
       "91 -8.247268  3.329846      0.239934  \n",
       "92 -8.634752  3.365323      0.246606  \n",
       "93 -6.714806  3.380517      0.239288  \n",
       "94 -5.601854  3.353540      0.237746  \n",
       "95 -3.900851  3.401686      0.243609  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267949</td>\n",
       "      <td>0.035494</td>\n",
       "      <td>5.215438</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.50706</td>\n",
       "      <td>1.32888</td>\n",
       "      <td>-22.550611</td>\n",
       "      <td>3.848754</td>\n",
       "      <td>0.267949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.267949           0.035494           5.215438   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.040297            0.006735             0.50706   1.32888   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -22.550611  3.848754           0.267949  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124840</td>\n",
       "      <td>0.082706</td>\n",
       "      <td>0.696168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>0.077389</td>\n",
       "      <td>0.744579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140523</td>\n",
       "      <td>0.092272</td>\n",
       "      <td>0.599469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>0.076876</td>\n",
       "      <td>0.747241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.146735</td>\n",
       "      <td>0.096920</td>\n",
       "      <td>0.550612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.313481</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>-0.526205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.343048</td>\n",
       "      <td>0.132635</td>\n",
       "      <td>-0.813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.314431</td>\n",
       "      <td>0.121065</td>\n",
       "      <td>-0.535712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.301583</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>-0.429829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.315387</td>\n",
       "      <td>0.125471</td>\n",
       "      <td>-0.669082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.124840        0.082706  0.696168\n",
       "1             2       0.115007        0.077389  0.744579\n",
       "2             3       0.140523        0.092272  0.599469\n",
       "3             4       0.113316        0.076876  0.747241\n",
       "4             5       0.146735        0.096920  0.550612\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.313481        0.120620 -0.526205\n",
       "35036     35037       0.343048        0.132635 -0.813442\n",
       "35037     35038       0.314431        0.121065 -0.535712\n",
       "35038     35039       0.301583        0.117587 -0.429829\n",
       "35039     35040       0.315387        0.125471 -0.669082\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                  feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean]   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3020 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5244 val_loss=-0.3346 scale=1.0000 norm=1.0742\n",
      "[iter 2] loss=-0.5567 val_loss=-0.3637 scale=1.0000 norm=1.0440\n",
      "[iter 3] loss=-0.5852 val_loss=-0.3899 scale=1.0000 norm=1.0173\n",
      "[iter 4] loss=-0.6108 val_loss=-0.4368 scale=2.0000 norm=1.9869\n",
      "[iter 5] loss=-0.6564 val_loss=-0.4769 scale=2.0000 norm=1.9015\n",
      "[iter 6] loss=-0.6957 val_loss=-0.5129 scale=2.0000 norm=1.8285\n",
      "[iter 7] loss=-0.7308 val_loss=-0.5459 scale=2.0000 norm=1.7648\n",
      "[iter 8] loss=-0.7630 val_loss=-0.5761 scale=2.0000 norm=1.7084\n",
      "[iter 9] loss=-0.7927 val_loss=-0.6046 scale=2.0000 norm=1.6583\n",
      "[iter 10] loss=-0.8208 val_loss=-0.6313 scale=2.0000 norm=1.6132\n",
      "[iter 11] loss=-0.8473 val_loss=-0.6567 scale=2.0000 norm=1.5729\n",
      "[iter 12] loss=-0.8725 val_loss=-0.6809 scale=2.0000 norm=1.5368\n",
      "[iter 13] loss=-0.8967 val_loss=-0.7042 scale=2.0000 norm=1.5042\n",
      "[iter 14] loss=-0.9199 val_loss=-0.7265 scale=2.0000 norm=1.4749\n",
      "[iter 15] loss=-0.9424 val_loss=-0.7481 scale=2.0000 norm=1.4485\n",
      "[iter 16] loss=-0.9641 val_loss=-0.7690 scale=2.0000 norm=1.4248\n",
      "[iter 17] loss=-0.9852 val_loss=-0.7892 scale=2.0000 norm=1.4035\n",
      "[iter 18] loss=-1.0055 val_loss=-0.8088 scale=2.0000 norm=1.3843\n",
      "[iter 19] loss=-1.0254 val_loss=-0.8277 scale=2.0000 norm=1.3670\n",
      "[iter 20] loss=-1.0447 val_loss=-0.8461 scale=2.0000 norm=1.3515\n",
      "[iter 21] loss=-1.0635 val_loss=-0.8640 scale=2.0000 norm=1.3375\n",
      "[iter 22] loss=-1.0818 val_loss=-0.8814 scale=2.0000 norm=1.3250\n",
      "[iter 23] loss=-1.0995 val_loss=-0.8983 scale=2.0000 norm=1.3138\n",
      "[iter 24] loss=-1.1168 val_loss=-0.9146 scale=2.0000 norm=1.3038\n",
      "[iter 25] loss=-1.1337 val_loss=-0.9308 scale=2.0000 norm=1.2947\n",
      "[iter 26] loss=-1.1501 val_loss=-0.9461 scale=2.0000 norm=1.2866\n",
      "[iter 27] loss=-1.1661 val_loss=-0.9610 scale=2.0000 norm=1.2795\n",
      "[iter 28] loss=-1.1815 val_loss=-0.9757 scale=2.0000 norm=1.2731\n",
      "[iter 29] loss=-1.1965 val_loss=-0.9899 scale=2.0000 norm=1.2675\n",
      "[iter 30] loss=-1.2111 val_loss=-1.0038 scale=2.0000 norm=1.2627\n",
      "[iter 31] loss=-1.2253 val_loss=-1.0172 scale=2.0000 norm=1.2583\n",
      "[iter 32] loss=-1.2392 val_loss=-1.0302 scale=2.0000 norm=1.2545\n",
      "[iter 33] loss=-1.2525 val_loss=-1.0431 scale=2.0000 norm=1.2512\n",
      "[iter 34] loss=-1.2655 val_loss=-1.0554 scale=2.0000 norm=1.2484\n",
      "[iter 35] loss=-1.2780 val_loss=-1.0672 scale=2.0000 norm=1.2460\n",
      "[iter 36] loss=-1.2902 val_loss=-1.0789 scale=2.0000 norm=1.2440\n",
      "[iter 37] loss=-1.3020 val_loss=-1.0902 scale=2.0000 norm=1.2423\n",
      "[iter 38] loss=-1.3134 val_loss=-1.1011 scale=2.0000 norm=1.2411\n",
      "[iter 39] loss=-1.3245 val_loss=-1.1116 scale=2.0000 norm=1.2400\n",
      "[iter 40] loss=-1.3351 val_loss=-1.1217 scale=2.0000 norm=1.2393\n",
      "[iter 41] loss=-1.3454 val_loss=-1.1314 scale=2.0000 norm=1.2388\n",
      "[iter 42] loss=-1.3553 val_loss=-1.1410 scale=2.0000 norm=1.2386\n",
      "[iter 43] loss=-1.3650 val_loss=-1.1500 scale=2.0000 norm=1.2385\n",
      "[iter 44] loss=-1.3743 val_loss=-1.1589 scale=2.0000 norm=1.2386\n",
      "[iter 45] loss=-1.3832 val_loss=-1.1672 scale=2.0000 norm=1.2390\n",
      "[iter 46] loss=-1.3919 val_loss=-1.1755 scale=2.0000 norm=1.2395\n",
      "[iter 47] loss=-1.4002 val_loss=-1.1833 scale=2.0000 norm=1.2401\n",
      "[iter 48] loss=-1.4083 val_loss=-1.1908 scale=2.0000 norm=1.2409\n",
      "[iter 49] loss=-1.4160 val_loss=-1.1982 scale=2.0000 norm=1.2419\n",
      "[iter 50] loss=-1.4234 val_loss=-1.2053 scale=2.0000 norm=1.2429\n",
      "[iter 51] loss=-1.4306 val_loss=-1.2121 scale=2.0000 norm=1.2440\n",
      "[iter 52] loss=-1.4376 val_loss=-1.2186 scale=2.0000 norm=1.2452\n",
      "[iter 53] loss=-1.4442 val_loss=-1.2250 scale=2.0000 norm=1.2465\n",
      "[iter 54] loss=-1.4506 val_loss=-1.2310 scale=2.0000 norm=1.2480\n",
      "[iter 55] loss=-1.4567 val_loss=-1.2370 scale=2.0000 norm=1.2494\n",
      "[iter 56] loss=-1.4626 val_loss=-1.2425 scale=2.0000 norm=1.2510\n",
      "[iter 57] loss=-1.4683 val_loss=-1.2479 scale=2.0000 norm=1.2526\n",
      "[iter 58] loss=-1.4738 val_loss=-1.2532 scale=2.0000 norm=1.2542\n",
      "[iter 59] loss=-1.4790 val_loss=-1.2582 scale=2.0000 norm=1.2558\n",
      "[iter 60] loss=-1.4840 val_loss=-1.2629 scale=2.0000 norm=1.2575\n",
      "[iter 61] loss=-1.4888 val_loss=-1.2674 scale=2.0000 norm=1.2593\n",
      "[iter 62] loss=-1.4934 val_loss=-1.2717 scale=2.0000 norm=1.2612\n",
      "[iter 63] loss=-1.4979 val_loss=-1.2758 scale=2.0000 norm=1.2629\n",
      "[iter 64] loss=-1.5021 val_loss=-1.2798 scale=2.0000 norm=1.2647\n",
      "[iter 65] loss=-1.5062 val_loss=-1.2834 scale=2.0000 norm=1.2666\n",
      "[iter 66] loss=-1.5100 val_loss=-1.2869 scale=2.0000 norm=1.2684\n",
      "[iter 67] loss=-1.5138 val_loss=-1.2904 scale=2.0000 norm=1.2702\n",
      "[iter 68] loss=-1.5173 val_loss=-1.2935 scale=2.0000 norm=1.2721\n",
      "[iter 69] loss=-1.5207 val_loss=-1.2965 scale=2.0000 norm=1.2738\n",
      "[iter 70] loss=-1.5240 val_loss=-1.2994 scale=2.0000 norm=1.2756\n",
      "[iter 71] loss=-1.5271 val_loss=-1.3020 scale=2.0000 norm=1.2775\n",
      "[iter 72] loss=-1.5300 val_loss=-1.3045 scale=2.0000 norm=1.2793\n",
      "[iter 73] loss=-1.5328 val_loss=-1.3068 scale=2.0000 norm=1.2811\n",
      "[iter 74] loss=-1.5355 val_loss=-1.3092 scale=2.0000 norm=1.2829\n",
      "[iter 75] loss=-1.5381 val_loss=-1.3114 scale=2.0000 norm=1.2848\n",
      "[iter 76] loss=-1.5405 val_loss=-1.3134 scale=2.0000 norm=1.2865\n",
      "[iter 77] loss=-1.5428 val_loss=-1.3155 scale=2.0000 norm=1.2882\n",
      "[iter 78] loss=-1.5451 val_loss=-1.3173 scale=2.0000 norm=1.2900\n",
      "[iter 79] loss=-1.5472 val_loss=-1.3191 scale=2.0000 norm=1.2917\n",
      "[iter 80] loss=-1.5493 val_loss=-1.3205 scale=2.0000 norm=1.2935\n",
      "[iter 81] loss=-1.5512 val_loss=-1.3219 scale=2.0000 norm=1.2951\n",
      "[iter 82] loss=-1.5530 val_loss=-1.3233 scale=2.0000 norm=1.2968\n",
      "[iter 83] loss=-1.5547 val_loss=-1.3247 scale=2.0000 norm=1.2984\n",
      "[iter 84] loss=-1.5564 val_loss=-1.3260 scale=2.0000 norm=1.3000\n",
      "[iter 85] loss=-1.5580 val_loss=-1.3271 scale=2.0000 norm=1.3015\n",
      "[iter 86] loss=-1.5595 val_loss=-1.3280 scale=2.0000 norm=1.3031\n",
      "[iter 87] loss=-1.5609 val_loss=-1.3290 scale=2.0000 norm=1.3046\n",
      "[iter 88] loss=-1.5622 val_loss=-1.3297 scale=2.0000 norm=1.3061\n",
      "[iter 89] loss=-1.5635 val_loss=-1.3301 scale=2.0000 norm=1.3075\n",
      "[iter 90] loss=-1.5647 val_loss=-1.3309 scale=2.0000 norm=1.3088\n",
      "[iter 91] loss=-1.5658 val_loss=-1.3316 scale=2.0000 norm=1.3102\n",
      "[iter 92] loss=-1.5669 val_loss=-1.3321 scale=2.0000 norm=1.3116\n",
      "[iter 93] loss=-1.5679 val_loss=-1.3325 scale=2.0000 norm=1.3129\n",
      "[iter 94] loss=-1.5689 val_loss=-1.3331 scale=2.0000 norm=1.3142\n",
      "[iter 95] loss=-1.5698 val_loss=-1.3333 scale=2.0000 norm=1.3155\n",
      "[iter 96] loss=-1.5707 val_loss=-1.3337 scale=2.0000 norm=1.3166\n",
      "[iter 97] loss=-1.5715 val_loss=-1.3341 scale=2.0000 norm=1.3178\n",
      "[iter 98] loss=-1.5723 val_loss=-1.3342 scale=2.0000 norm=1.3190\n",
      "[iter 99] loss=-1.5730 val_loss=-1.3347 scale=2.0000 norm=1.3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.258365</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>1.873890</td>\n",
       "      <td>0.042607</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>1.212362</td>\n",
       "      <td>-4.052442</td>\n",
       "      <td>3.727156</td>\n",
       "      <td>-1.212362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.250206</td>\n",
       "      <td>0.041294</td>\n",
       "      <td>1.869984</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.234926</td>\n",
       "      <td>1.248774</td>\n",
       "      <td>-3.170278</td>\n",
       "      <td>3.658750</td>\n",
       "      <td>-1.248774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250014</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>1.876125</td>\n",
       "      <td>0.041387</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.228437</td>\n",
       "      <td>1.254218</td>\n",
       "      <td>-3.213207</td>\n",
       "      <td>3.551091</td>\n",
       "      <td>-1.254218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.258486</td>\n",
       "      <td>0.040369</td>\n",
       "      <td>1.878056</td>\n",
       "      <td>0.042423</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.236317</td>\n",
       "      <td>1.222145</td>\n",
       "      <td>-3.388918</td>\n",
       "      <td>3.343097</td>\n",
       "      <td>-1.222145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.270761</td>\n",
       "      <td>0.039846</td>\n",
       "      <td>1.969375</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.256110</td>\n",
       "      <td>1.153924</td>\n",
       "      <td>-7.971978</td>\n",
       "      <td>3.442451</td>\n",
       "      <td>-1.153924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.245529</td>\n",
       "      <td>0.038566</td>\n",
       "      <td>1.518742</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.488119</td>\n",
       "      <td>1.251773</td>\n",
       "      <td>-7.315616</td>\n",
       "      <td>3.603943</td>\n",
       "      <td>-1.251773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.250590</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>1.624872</td>\n",
       "      <td>0.041804</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.502634</td>\n",
       "      <td>1.229226</td>\n",
       "      <td>-7.800260</td>\n",
       "      <td>3.661389</td>\n",
       "      <td>-1.229226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.242244</td>\n",
       "      <td>0.038633</td>\n",
       "      <td>1.712369</td>\n",
       "      <td>0.040708</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.457102</td>\n",
       "      <td>1.263849</td>\n",
       "      <td>-6.205735</td>\n",
       "      <td>3.741193</td>\n",
       "      <td>-1.263849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.241131</td>\n",
       "      <td>0.039353</td>\n",
       "      <td>1.813981</td>\n",
       "      <td>0.040483</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.371905</td>\n",
       "      <td>1.269855</td>\n",
       "      <td>-4.795446</td>\n",
       "      <td>3.683912</td>\n",
       "      <td>-1.269855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.246472</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>1.864804</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.270245</td>\n",
       "      <td>1.256853</td>\n",
       "      <td>-3.203947</td>\n",
       "      <td>3.626072</td>\n",
       "      <td>-1.256853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.258365           0.041534           1.873890   \n",
       "1          2            0.250206           0.041294           1.869984   \n",
       "2          3            0.250014           0.040297           1.876125   \n",
       "3          4            0.258486           0.040369           1.878056   \n",
       "4          5            0.270761           0.039846           1.969375   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.245529           0.038566           1.518742   \n",
       "92        93            0.250590           0.038851           1.624872   \n",
       "93        94            0.242244           0.038633           1.712369   \n",
       "94        95            0.241131           0.039353           1.813981   \n",
       "95        96            0.246472           0.041301           1.864804   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.042607            0.005138            0.258824  1.212362   \n",
       "1              0.041449            0.004610            0.234926  1.248774   \n",
       "2              0.041387            0.004609            0.228437  1.254218   \n",
       "3              0.042423            0.004176            0.236317  1.222145   \n",
       "4              0.044661            0.004215            0.256110  1.153924   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.041301            0.004428            0.488119  1.251773   \n",
       "92             0.041804            0.004340            0.502634  1.229226   \n",
       "93             0.040708            0.004246            0.457102  1.263849   \n",
       "94             0.040483            0.004277            0.371905  1.269855   \n",
       "95             0.040890            0.004768            0.270245  1.256853   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -4.052442  3.727156     -1.212362  \n",
       "1  -3.170278  3.658750     -1.248774  \n",
       "2  -3.213207  3.551091     -1.254218  \n",
       "3  -3.388918  3.343097     -1.222145  \n",
       "4  -7.971978  3.442451     -1.153924  \n",
       "..       ...       ...           ...  \n",
       "91 -7.315616  3.603943     -1.251773  \n",
       "92 -7.800260  3.661389     -1.229226  \n",
       "93 -6.205735  3.741193     -1.263849  \n",
       "94 -4.795446  3.683912     -1.269855  \n",
       "95 -3.203947  3.626072     -1.256853  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.269698</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>5.155103</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.502634</td>\n",
       "      <td>1.334739</td>\n",
       "      <td>-18.039244</td>\n",
       "      <td>5.241196</td>\n",
       "      <td>-1.334739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.269698           0.037543           5.155103   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.040694            0.002293            0.502634  1.334739   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -18.039244  5.241196          -1.334739  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130655</td>\n",
       "      <td>0.085513</td>\n",
       "      <td>0.638052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.117562</td>\n",
       "      <td>0.078117</td>\n",
       "      <td>0.739481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.133611</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>0.644791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.101255</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>0.860962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.152563</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.478771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.318113</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>-0.382802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.345592</td>\n",
       "      <td>0.132168</td>\n",
       "      <td>-0.577432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.319043</td>\n",
       "      <td>0.121583</td>\n",
       "      <td>-0.390849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>0.120946</td>\n",
       "      <td>-0.363308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>-0.598251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.130655        0.085513  0.638052\n",
       "1             2       0.117562        0.078117  0.739481\n",
       "2             3       0.133611        0.086698  0.644791\n",
       "3             4       0.101255        0.067743  0.860962\n",
       "4             5       0.152563        0.100113  0.478771\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.318113        0.121147 -0.382802\n",
       "35036     35037       0.345592        0.132168 -0.577432\n",
       "35037     35038       0.319043        0.121583 -0.390849\n",
       "35038     35039       0.314351        0.120946 -0.363308\n",
       "35039     35040       0.329652        0.129500 -0.598251\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean]</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                  feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean]   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0952\n",
      "[iter 2] loss=0.6111 val_loss=0.6360 scale=1.0000 norm=1.0760\n",
      "[iter 3] loss=0.5953 val_loss=0.6198 scale=1.0000 norm=1.0588\n",
      "[iter 4] loss=0.5803 val_loss=0.6043 scale=1.0000 norm=1.0438\n",
      "[iter 5] loss=0.5659 val_loss=0.5895 scale=1.0000 norm=1.0302\n",
      "[iter 6] loss=0.5522 val_loss=0.5753 scale=1.0000 norm=1.0183\n",
      "[iter 7] loss=0.5389 val_loss=0.5618 scale=1.0000 norm=1.0078\n",
      "[iter 8] loss=0.5262 val_loss=0.5488 scale=1.0000 norm=0.9986\n",
      "[iter 9] loss=0.5140 val_loss=0.5364 scale=1.0000 norm=0.9906\n",
      "[iter 10] loss=0.5022 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4800 val_loss=0.5015 scale=1.0000 norm=0.9735\n",
      "[iter 13] loss=0.4693 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9653\n",
      "[iter 16] loss=0.4395 val_loss=0.4603 scale=1.0000 norm=0.9644\n",
      "[iter 17] loss=0.4302 val_loss=0.4508 scale=1.0000 norm=0.9645\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9653\n",
      "[iter 19] loss=0.4123 val_loss=0.4326 scale=1.0000 norm=0.9671\n",
      "[iter 20] loss=0.4038 val_loss=0.4239 scale=1.0000 norm=0.9695\n",
      "[iter 21] loss=0.3955 val_loss=0.4154 scale=1.0000 norm=0.9730\n",
      "[iter 22] loss=0.3874 val_loss=0.4069 scale=1.0000 norm=0.9772\n",
      "[iter 23] loss=0.3794 val_loss=0.3989 scale=1.0000 norm=0.9822\n",
      "[iter 24] loss=0.3717 val_loss=0.3911 scale=1.0000 norm=0.9881\n",
      "[iter 25] loss=0.3643 val_loss=0.3834 scale=1.0000 norm=0.9948\n",
      "[iter 26] loss=0.3569 val_loss=0.3759 scale=1.0000 norm=1.0023\n",
      "[iter 27] loss=0.3499 val_loss=0.3687 scale=1.0000 norm=1.0107\n",
      "[iter 28] loss=0.3429 val_loss=0.3617 scale=1.0000 norm=1.0198\n",
      "[iter 29] loss=0.3362 val_loss=0.3547 scale=1.0000 norm=1.0299\n",
      "[iter 30] loss=0.3296 val_loss=0.3481 scale=1.0000 norm=1.0407\n",
      "[iter 31] loss=0.3232 val_loss=0.3416 scale=1.0000 norm=1.0523\n",
      "[iter 32] loss=0.3169 val_loss=0.3353 scale=1.0000 norm=1.0650\n",
      "[iter 33] loss=0.3108 val_loss=0.3290 scale=1.0000 norm=1.0785\n",
      "[iter 34] loss=0.3049 val_loss=0.3228 scale=1.0000 norm=1.0929\n",
      "[iter 35] loss=0.2991 val_loss=0.3170 scale=1.0000 norm=1.1080\n",
      "[iter 36] loss=0.2935 val_loss=0.3113 scale=1.0000 norm=1.1244\n",
      "[iter 37] loss=0.2881 val_loss=0.3058 scale=1.0000 norm=1.1416\n",
      "[iter 38] loss=0.2828 val_loss=0.3003 scale=1.0000 norm=1.1599\n",
      "[iter 39] loss=0.2776 val_loss=0.2951 scale=1.0000 norm=1.1790\n",
      "[iter 40] loss=0.2727 val_loss=0.2900 scale=1.0000 norm=1.1991\n",
      "[iter 41] loss=0.2678 val_loss=0.2851 scale=1.0000 norm=1.2205\n",
      "[iter 42] loss=0.2631 val_loss=0.2803 scale=1.0000 norm=1.2428\n",
      "[iter 43] loss=0.2585 val_loss=0.2757 scale=1.0000 norm=1.2664\n",
      "[iter 44] loss=0.2541 val_loss=0.2712 scale=1.0000 norm=1.2910\n",
      "[iter 45] loss=0.2499 val_loss=0.2669 scale=1.0000 norm=1.3170\n",
      "[iter 46] loss=0.2458 val_loss=0.2626 scale=1.0000 norm=1.3439\n",
      "[iter 47] loss=0.2418 val_loss=0.2586 scale=1.0000 norm=1.3722\n",
      "[iter 48] loss=0.2380 val_loss=0.2547 scale=1.0000 norm=1.4018\n",
      "[iter 49] loss=0.2343 val_loss=0.2510 scale=1.0000 norm=1.4329\n",
      "[iter 50] loss=0.2308 val_loss=0.2473 scale=1.0000 norm=1.4653\n",
      "[iter 51] loss=0.2274 val_loss=0.2439 scale=1.0000 norm=1.4991\n",
      "[iter 52] loss=0.2242 val_loss=0.2405 scale=1.0000 norm=1.5347\n",
      "[iter 53] loss=0.2211 val_loss=0.2374 scale=1.0000 norm=1.5716\n",
      "[iter 54] loss=0.2181 val_loss=0.2343 scale=1.0000 norm=1.6101\n",
      "[iter 55] loss=0.2153 val_loss=0.2313 scale=1.0000 norm=1.6502\n",
      "[iter 56] loss=0.2126 val_loss=0.2286 scale=1.0000 norm=1.6922\n",
      "[iter 57] loss=0.2101 val_loss=0.2260 scale=1.0000 norm=1.7354\n",
      "[iter 58] loss=0.2077 val_loss=0.2234 scale=1.0000 norm=1.7803\n",
      "[iter 59] loss=0.2054 val_loss=0.2211 scale=1.0000 norm=1.8259\n",
      "[iter 60] loss=0.2033 val_loss=0.2189 scale=1.0000 norm=1.8723\n",
      "[iter 61] loss=0.2012 val_loss=0.2167 scale=1.0000 norm=1.9201\n",
      "[iter 62] loss=0.1993 val_loss=0.2146 scale=1.0000 norm=1.9683\n",
      "[iter 63] loss=0.1974 val_loss=0.2125 scale=1.0000 norm=2.0175\n",
      "[iter 64] loss=0.1956 val_loss=0.2107 scale=1.0000 norm=2.0650\n",
      "[iter 65] loss=0.1940 val_loss=0.2088 scale=1.0000 norm=2.1148\n",
      "[iter 66] loss=0.1924 val_loss=0.2071 scale=1.0000 norm=2.1624\n",
      "[iter 67] loss=0.1908 val_loss=0.2055 scale=1.0000 norm=2.2089\n",
      "[iter 68] loss=0.1894 val_loss=0.2040 scale=1.0000 norm=2.2558\n",
      "[iter 69] loss=0.1880 val_loss=0.2024 scale=1.0000 norm=2.3004\n",
      "[iter 70] loss=0.1867 val_loss=0.2010 scale=1.0000 norm=2.3457\n",
      "[iter 71] loss=0.1855 val_loss=0.1997 scale=1.0000 norm=2.3889\n",
      "[iter 72] loss=0.1843 val_loss=0.1984 scale=1.0000 norm=2.4310\n",
      "[iter 73] loss=0.1832 val_loss=0.1972 scale=1.0000 norm=2.4721\n",
      "[iter 74] loss=0.1821 val_loss=0.1960 scale=1.0000 norm=2.5109\n",
      "[iter 75] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5502\n",
      "[iter 76] loss=0.1801 val_loss=0.1940 scale=1.0000 norm=2.5883\n",
      "[iter 77] loss=0.1792 val_loss=0.1930 scale=1.0000 norm=2.6249\n",
      "[iter 78] loss=0.1784 val_loss=0.1919 scale=1.0000 norm=2.6617\n",
      "[iter 79] loss=0.1775 val_loss=0.1911 scale=1.0000 norm=2.6959\n",
      "[iter 80] loss=0.1768 val_loss=0.1902 scale=1.0000 norm=2.7289\n",
      "[iter 81] loss=0.1760 val_loss=0.1895 scale=1.0000 norm=2.7603\n",
      "[iter 82] loss=0.1753 val_loss=0.1887 scale=1.0000 norm=2.7905\n",
      "[iter 83] loss=0.1746 val_loss=0.1883 scale=0.5000 norm=1.4094\n",
      "[iter 84] loss=0.1743 val_loss=0.1876 scale=1.0000 norm=2.8341\n",
      "[iter 85] loss=0.1737 val_loss=0.1870 scale=1.0000 norm=2.8618\n",
      "[iter 86] loss=0.1731 val_loss=0.1867 scale=0.5000 norm=1.4439\n",
      "[iter 87] loss=0.1728 val_loss=0.1865 scale=0.5000 norm=1.4502\n",
      "[iter 88] loss=0.1725 val_loss=0.1859 scale=1.0000 norm=2.9145\n",
      "[iter 89] loss=0.1720 val_loss=0.1854 scale=1.0000 norm=2.9379\n",
      "[iter 90] loss=0.1715 val_loss=0.1852 scale=0.5000 norm=1.4811\n",
      "[iter 91] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4876\n",
      "[iter 92] loss=0.1710 val_loss=0.1846 scale=1.0000 norm=2.9870\n",
      "[iter 93] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=3.0107\n",
      "[iter 94] loss=0.1702 val_loss=0.1839 scale=1.0000 norm=3.0335\n",
      "[iter 95] loss=0.1698 val_loss=0.1838 scale=0.5000 norm=1.5294\n",
      "[iter 96] loss=0.1696 val_loss=0.1836 scale=0.5000 norm=1.5356\n",
      "[iter 97] loss=0.1695 val_loss=0.1833 scale=1.0000 norm=3.0847\n",
      "[iter 98] loss=0.1691 val_loss=0.1830 scale=1.0000 norm=3.1097\n",
      "[iter 99] loss=0.1688 val_loss=0.1828 scale=1.0000 norm=3.1368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.177076</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>1.211708</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.176491</td>\n",
       "      <td>1.533382</td>\n",
       "      <td>-5.130505</td>\n",
       "      <td>3.781915</td>\n",
       "      <td>0.177076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174571</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>1.229947</td>\n",
       "      <td>0.030062</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.187393</td>\n",
       "      <td>1.576459</td>\n",
       "      <td>-4.672855</td>\n",
       "      <td>3.849287</td>\n",
       "      <td>0.174571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>1.260057</td>\n",
       "      <td>0.028845</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.199236</td>\n",
       "      <td>1.625567</td>\n",
       "      <td>-4.621095</td>\n",
       "      <td>3.881627</td>\n",
       "      <td>0.171087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.172172</td>\n",
       "      <td>0.025586</td>\n",
       "      <td>1.308767</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>1.636395</td>\n",
       "      <td>-4.929359</td>\n",
       "      <td>3.822051</td>\n",
       "      <td>0.172172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.172720</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>1.672848</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.208911</td>\n",
       "      <td>1.653026</td>\n",
       "      <td>-5.168518</td>\n",
       "      <td>3.845731</td>\n",
       "      <td>0.172720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.174026</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>1.158200</td>\n",
       "      <td>0.030272</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.289317</td>\n",
       "      <td>1.534440</td>\n",
       "      <td>-6.884829</td>\n",
       "      <td>3.707459</td>\n",
       "      <td>0.174026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.176072</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>1.271622</td>\n",
       "      <td>0.030546</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.299818</td>\n",
       "      <td>1.512130</td>\n",
       "      <td>-6.377614</td>\n",
       "      <td>3.739484</td>\n",
       "      <td>0.176072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.171679</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>1.286986</td>\n",
       "      <td>0.030105</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.339642</td>\n",
       "      <td>1.551462</td>\n",
       "      <td>-6.374514</td>\n",
       "      <td>3.696741</td>\n",
       "      <td>0.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.171986</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>1.178905</td>\n",
       "      <td>0.030349</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.296615</td>\n",
       "      <td>1.552474</td>\n",
       "      <td>-5.856139</td>\n",
       "      <td>3.799814</td>\n",
       "      <td>0.171986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.021253</td>\n",
       "      <td>1.216254</td>\n",
       "      <td>0.030280</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.233312</td>\n",
       "      <td>1.556838</td>\n",
       "      <td>-4.870560</td>\n",
       "      <td>3.859464</td>\n",
       "      <td>0.172727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.177076           0.022424           1.211708   \n",
       "1          2            0.174571           0.023203           1.229947   \n",
       "2          3            0.171087           0.026813           1.260057   \n",
       "3          4            0.172172           0.025586           1.308767   \n",
       "4          5            0.172720           0.020645           1.672848   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.174026           0.021626           1.158200   \n",
       "92        93            0.176072           0.021976           1.271622   \n",
       "93        94            0.171679           0.023134           1.286986   \n",
       "94        95            0.171986           0.022217           1.178905   \n",
       "95        96            0.172727           0.021253           1.216254   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.030956            0.003223            0.176491  1.533382   \n",
       "1              0.030062            0.003590            0.187393  1.576459   \n",
       "2              0.028845            0.003484            0.199236  1.625567   \n",
       "3              0.028484            0.003397            0.203061  1.636395   \n",
       "4              0.028300            0.003492            0.208911  1.653026   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.030272            0.003905            0.289317  1.534440   \n",
       "92             0.030546            0.003622            0.299818  1.512130   \n",
       "93             0.030105            0.003629            0.339642  1.551462   \n",
       "94             0.030349            0.003354            0.296615  1.552474   \n",
       "95             0.030280            0.003169            0.233312  1.556838   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -5.130505  3.781915      0.177076  \n",
       "1  -4.672855  3.849287      0.174571  \n",
       "2  -4.621095  3.881627      0.171087  \n",
       "3  -4.929359  3.822051      0.172172  \n",
       "4  -5.168518  3.845731      0.172720  \n",
       "..       ...       ...           ...  \n",
       "91 -6.884829  3.707459      0.174026  \n",
       "92 -6.377614  3.739484      0.176072  \n",
       "93 -6.374514  3.696741      0.171679  \n",
       "94 -5.856139  3.799814      0.171986  \n",
       "95 -4.870560  3.859464      0.172727  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182779</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>4.144601</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.357295</td>\n",
       "      <td>1.714674</td>\n",
       "      <td>-22.048296</td>\n",
       "      <td>4.087833</td>\n",
       "      <td>0.182779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.182779           0.020159           4.144601   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.028352            0.002734            0.357295  1.714674   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -22.048296  4.087833           0.182779  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.197566</td>\n",
       "      <td>0.131057</td>\n",
       "      <td>-0.452582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.185209</td>\n",
       "      <td>0.124767</td>\n",
       "      <td>-0.276310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.220739</td>\n",
       "      <td>0.145497</td>\n",
       "      <td>-0.826033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.172337</td>\n",
       "      <td>0.116527</td>\n",
       "      <td>-0.088154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.211078</td>\n",
       "      <td>0.138978</td>\n",
       "      <td>-0.663309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>-0.351559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.250614</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>-0.297950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.236827</td>\n",
       "      <td>0.095143</td>\n",
       "      <td>-0.134052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.229735</td>\n",
       "      <td>0.093310</td>\n",
       "      <td>-0.077951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.239989</td>\n",
       "      <td>0.099414</td>\n",
       "      <td>-0.257676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.197566        0.131057 -0.452582\n",
       "1             2       0.185209        0.124767 -0.276310\n",
       "2             3       0.220739        0.145497 -0.826033\n",
       "3             4       0.172337        0.116527 -0.088154\n",
       "4             5       0.211078        0.138978 -0.663309\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.253844        0.101345 -0.351559\n",
       "35036     35037       0.250614        0.101653 -0.297950\n",
       "35037     35038       0.236827        0.095143 -0.134052\n",
       "35038     35039       0.229735        0.093310 -0.077951\n",
       "35039     35040       0.239989        0.099414 -0.257676\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_1, ws_10m_loc_2, ws_10...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_1, ws_10m_loc_2, ws_10...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3054 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5282 val_loss=-0.3417 scale=1.0000 norm=1.0710\n",
      "[iter 2] loss=-0.5639 val_loss=-0.3723 scale=1.0000 norm=1.0382\n",
      "[iter 3] loss=-0.5940 val_loss=-0.4012 scale=1.0000 norm=1.0103\n",
      "[iter 4] loss=-0.6219 val_loss=-0.4272 scale=1.0000 norm=0.9848\n",
      "[iter 5] loss=-0.6467 val_loss=-0.4512 scale=1.0000 norm=0.9621\n",
      "[iter 6] loss=-0.6698 val_loss=-0.4735 scale=1.0000 norm=0.9410\n",
      "[iter 7] loss=-0.6914 val_loss=-0.4945 scale=1.0000 norm=0.9214\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9030\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5335 scale=1.0000 norm=0.8857\n",
      "[iter 10] loss=-0.7500 val_loss=-0.5518 scale=1.0000 norm=0.8695\n",
      "[iter 11] loss=-0.7679 val_loss=-0.5695 scale=1.0000 norm=0.8541\n",
      "[iter 12] loss=-0.7855 val_loss=-0.5867 scale=1.0000 norm=0.8392\n",
      "[iter 13] loss=-0.8024 val_loss=-0.6036 scale=1.0000 norm=0.8252\n",
      "[iter 14] loss=-0.8190 val_loss=-0.6358 scale=2.0000 norm=1.6235\n",
      "[iter 15] loss=-0.8507 val_loss=-0.6674 scale=2.0000 norm=1.5735\n",
      "[iter 16] loss=-0.8818 val_loss=-0.6968 scale=2.0000 norm=1.5270\n",
      "[iter 17] loss=-0.9112 val_loss=-0.7257 scale=2.0000 norm=1.4855\n",
      "[iter 18] loss=-0.9397 val_loss=-0.7539 scale=2.0000 norm=1.4478\n",
      "[iter 19] loss=-0.9678 val_loss=-0.7813 scale=2.0000 norm=1.4129\n",
      "[iter 20] loss=-0.9953 val_loss=-0.8079 scale=2.0000 norm=1.3806\n",
      "[iter 21] loss=-1.0218 val_loss=-0.8340 scale=2.0000 norm=1.3519\n",
      "[iter 22] loss=-1.0481 val_loss=-0.8593 scale=2.0000 norm=1.3252\n",
      "[iter 23] loss=-1.0740 val_loss=-0.8841 scale=2.0000 norm=1.3006\n",
      "[iter 24] loss=-1.0991 val_loss=-0.9085 scale=2.0000 norm=1.2787\n",
      "[iter 25] loss=-1.1239 val_loss=-0.9326 scale=2.0000 norm=1.2586\n",
      "[iter 26] loss=-1.1485 val_loss=-0.9559 scale=2.0000 norm=1.2399\n",
      "[iter 27] loss=-1.1725 val_loss=-0.9795 scale=2.0000 norm=1.2231\n",
      "[iter 28] loss=-1.1964 val_loss=-1.0021 scale=2.0000 norm=1.2074\n",
      "[iter 29] loss=-1.2197 val_loss=-1.0243 scale=2.0000 norm=1.1932\n",
      "[iter 30] loss=-1.2426 val_loss=-1.0466 scale=2.0000 norm=1.1803\n",
      "[iter 31] loss=-1.2655 val_loss=-1.0685 scale=2.0000 norm=1.1681\n",
      "[iter 32] loss=-1.2877 val_loss=-1.0897 scale=2.0000 norm=1.1572\n",
      "[iter 33] loss=-1.3097 val_loss=-1.1107 scale=2.0000 norm=1.1471\n",
      "[iter 34] loss=-1.3313 val_loss=-1.1311 scale=2.0000 norm=1.1378\n",
      "[iter 35] loss=-1.3525 val_loss=-1.1513 scale=2.0000 norm=1.1294\n",
      "[iter 36] loss=-1.3734 val_loss=-1.1712 scale=2.0000 norm=1.1215\n",
      "[iter 37] loss=-1.3939 val_loss=-1.1907 scale=2.0000 norm=1.1143\n",
      "[iter 38] loss=-1.4140 val_loss=-1.2095 scale=2.0000 norm=1.1077\n",
      "[iter 39] loss=-1.4336 val_loss=-1.2281 scale=2.0000 norm=1.1016\n",
      "[iter 40] loss=-1.4530 val_loss=-1.2464 scale=2.0000 norm=1.0958\n",
      "[iter 41] loss=-1.4719 val_loss=-1.2640 scale=2.0000 norm=1.0907\n",
      "[iter 42] loss=-1.4905 val_loss=-1.2812 scale=2.0000 norm=1.0859\n",
      "[iter 43] loss=-1.5086 val_loss=-1.2980 scale=2.0000 norm=1.0816\n",
      "[iter 44] loss=-1.5262 val_loss=-1.3145 scale=2.0000 norm=1.0776\n",
      "[iter 45] loss=-1.5435 val_loss=-1.3306 scale=2.0000 norm=1.0739\n",
      "[iter 46] loss=-1.5604 val_loss=-1.3463 scale=2.0000 norm=1.0704\n",
      "[iter 47] loss=-1.5768 val_loss=-1.3615 scale=2.0000 norm=1.0673\n",
      "[iter 48] loss=-1.5930 val_loss=-1.3762 scale=2.0000 norm=1.0644\n",
      "[iter 49] loss=-1.6086 val_loss=-1.3907 scale=2.0000 norm=1.0619\n",
      "[iter 50] loss=-1.6238 val_loss=-1.4048 scale=2.0000 norm=1.0595\n",
      "[iter 51] loss=-1.6386 val_loss=-1.4184 scale=2.0000 norm=1.0575\n",
      "[iter 52] loss=-1.6531 val_loss=-1.4316 scale=2.0000 norm=1.0557\n",
      "[iter 53] loss=-1.6672 val_loss=-1.4442 scale=2.0000 norm=1.0541\n",
      "[iter 54] loss=-1.6809 val_loss=-1.4563 scale=2.0000 norm=1.0525\n",
      "[iter 55] loss=-1.6941 val_loss=-1.4682 scale=2.0000 norm=1.0514\n",
      "[iter 56] loss=-1.7069 val_loss=-1.4800 scale=2.0000 norm=1.0504\n",
      "[iter 57] loss=-1.7194 val_loss=-1.4911 scale=2.0000 norm=1.0496\n",
      "[iter 58] loss=-1.7314 val_loss=-1.5022 scale=2.0000 norm=1.0490\n",
      "[iter 59] loss=-1.7432 val_loss=-1.5128 scale=2.0000 norm=1.0484\n",
      "[iter 60] loss=-1.7544 val_loss=-1.5231 scale=2.0000 norm=1.0483\n",
      "[iter 61] loss=-1.7653 val_loss=-1.5325 scale=2.0000 norm=1.0482\n",
      "[iter 62] loss=-1.7758 val_loss=-1.5421 scale=2.0000 norm=1.0484\n",
      "[iter 63] loss=-1.7859 val_loss=-1.5511 scale=2.0000 norm=1.0487\n",
      "[iter 64] loss=-1.7957 val_loss=-1.5599 scale=2.0000 norm=1.0491\n",
      "[iter 65] loss=-1.8051 val_loss=-1.5683 scale=2.0000 norm=1.0496\n",
      "[iter 66] loss=-1.8143 val_loss=-1.5761 scale=2.0000 norm=1.0501\n",
      "[iter 67] loss=-1.8230 val_loss=-1.5838 scale=2.0000 norm=1.0510\n",
      "[iter 68] loss=-1.8314 val_loss=-1.5909 scale=2.0000 norm=1.0521\n",
      "[iter 69] loss=-1.8395 val_loss=-1.5982 scale=2.0000 norm=1.0532\n",
      "[iter 70] loss=-1.8473 val_loss=-1.6049 scale=2.0000 norm=1.0543\n",
      "[iter 71] loss=-1.8547 val_loss=-1.6117 scale=2.0000 norm=1.0556\n",
      "[iter 72] loss=-1.8619 val_loss=-1.6181 scale=2.0000 norm=1.0570\n",
      "[iter 73] loss=-1.8687 val_loss=-1.6242 scale=2.0000 norm=1.0585\n",
      "[iter 74] loss=-1.8753 val_loss=-1.6297 scale=2.0000 norm=1.0601\n",
      "[iter 75] loss=-1.8815 val_loss=-1.6353 scale=2.0000 norm=1.0618\n",
      "[iter 76] loss=-1.8876 val_loss=-1.6403 scale=2.0000 norm=1.0636\n",
      "[iter 77] loss=-1.8933 val_loss=-1.6451 scale=2.0000 norm=1.0655\n",
      "[iter 78] loss=-1.8988 val_loss=-1.6496 scale=2.0000 norm=1.0674\n",
      "[iter 79] loss=-1.9040 val_loss=-1.6540 scale=2.0000 norm=1.0693\n",
      "[iter 80] loss=-1.9091 val_loss=-1.6578 scale=2.0000 norm=1.0713\n",
      "[iter 81] loss=-1.9138 val_loss=-1.6621 scale=2.0000 norm=1.0733\n",
      "[iter 82] loss=-1.9184 val_loss=-1.6656 scale=2.0000 norm=1.0753\n",
      "[iter 83] loss=-1.9227 val_loss=-1.6691 scale=2.0000 norm=1.0775\n",
      "[iter 84] loss=-1.9268 val_loss=-1.6728 scale=2.0000 norm=1.0796\n",
      "[iter 85] loss=-1.9309 val_loss=-1.6757 scale=2.0000 norm=1.0817\n",
      "[iter 86] loss=-1.9346 val_loss=-1.6789 scale=2.0000 norm=1.0839\n",
      "[iter 87] loss=-1.9382 val_loss=-1.6816 scale=2.0000 norm=1.0860\n",
      "[iter 88] loss=-1.9416 val_loss=-1.6841 scale=2.0000 norm=1.0881\n",
      "[iter 89] loss=-1.9449 val_loss=-1.6869 scale=2.0000 norm=1.0904\n",
      "[iter 90] loss=-1.9481 val_loss=-1.6895 scale=2.0000 norm=1.0924\n",
      "[iter 91] loss=-1.9511 val_loss=-1.6914 scale=2.0000 norm=1.0945\n",
      "[iter 92] loss=-1.9538 val_loss=-1.6937 scale=2.0000 norm=1.0968\n",
      "[iter 93] loss=-1.9564 val_loss=-1.6956 scale=2.0000 norm=1.0990\n",
      "[iter 94] loss=-1.9589 val_loss=-1.6970 scale=2.0000 norm=1.1012\n",
      "[iter 95] loss=-1.9611 val_loss=-1.6987 scale=2.0000 norm=1.1034\n",
      "[iter 96] loss=-1.9633 val_loss=-1.7003 scale=2.0000 norm=1.1056\n",
      "[iter 97] loss=-1.9655 val_loss=-1.7014 scale=2.0000 norm=1.1078\n",
      "[iter 98] loss=-1.9674 val_loss=-1.7032 scale=2.0000 norm=1.1098\n",
      "[iter 99] loss=-1.9695 val_loss=-1.7043 scale=2.0000 norm=1.1117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.175829</td>\n",
       "      <td>0.038148</td>\n",
       "      <td>1.117058</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.155610</td>\n",
       "      <td>1.545846</td>\n",
       "      <td>-4.761534</td>\n",
       "      <td>4.215046</td>\n",
       "      <td>-1.545846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.176617</td>\n",
       "      <td>0.038518</td>\n",
       "      <td>1.263309</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.160704</td>\n",
       "      <td>1.558906</td>\n",
       "      <td>-3.997456</td>\n",
       "      <td>4.404543</td>\n",
       "      <td>-1.558906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.173037</td>\n",
       "      <td>0.038551</td>\n",
       "      <td>1.258002</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.175959</td>\n",
       "      <td>1.590409</td>\n",
       "      <td>-3.332317</td>\n",
       "      <td>4.414499</td>\n",
       "      <td>-1.590409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173785</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>1.415674</td>\n",
       "      <td>0.029588</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.193886</td>\n",
       "      <td>1.608170</td>\n",
       "      <td>-3.164027</td>\n",
       "      <td>4.447552</td>\n",
       "      <td>-1.608170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.175685</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>1.563752</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.207698</td>\n",
       "      <td>1.607669</td>\n",
       "      <td>-3.817663</td>\n",
       "      <td>4.467974</td>\n",
       "      <td>-1.607669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.178285</td>\n",
       "      <td>0.039121</td>\n",
       "      <td>1.358801</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.310332</td>\n",
       "      <td>1.504342</td>\n",
       "      <td>-5.587657</td>\n",
       "      <td>4.086741</td>\n",
       "      <td>-1.504342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.179326</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>1.300189</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.324806</td>\n",
       "      <td>1.497556</td>\n",
       "      <td>-4.816944</td>\n",
       "      <td>4.189585</td>\n",
       "      <td>-1.497556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.175256</td>\n",
       "      <td>0.040386</td>\n",
       "      <td>1.172254</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.361505</td>\n",
       "      <td>1.533636</td>\n",
       "      <td>-5.043850</td>\n",
       "      <td>4.176753</td>\n",
       "      <td>-1.533636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.171501</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>1.142880</td>\n",
       "      <td>0.030961</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.256387</td>\n",
       "      <td>1.557580</td>\n",
       "      <td>-3.557047</td>\n",
       "      <td>4.230513</td>\n",
       "      <td>-1.557580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.173765</td>\n",
       "      <td>0.038894</td>\n",
       "      <td>1.109762</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.210514</td>\n",
       "      <td>1.552267</td>\n",
       "      <td>-4.080012</td>\n",
       "      <td>4.359515</td>\n",
       "      <td>-1.552267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.175829           0.038148           1.117058   \n",
       "1          2            0.176617           0.038518           1.263309   \n",
       "2          3            0.173037           0.038551           1.258002   \n",
       "3          4            0.173785           0.037935           1.415674   \n",
       "4          5            0.175685           0.040427           1.563752   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.178285           0.039121           1.358801   \n",
       "92        93            0.179326           0.039299           1.300189   \n",
       "93        94            0.175256           0.040386           1.172254   \n",
       "94        95            0.171501           0.039683           1.142880   \n",
       "95        96            0.173765           0.038894           1.109762   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.031442            0.001966            0.155610  1.545846   \n",
       "1              0.030852            0.002212            0.160704  1.558906   \n",
       "2              0.030113            0.002393            0.175959  1.590409   \n",
       "3              0.029588            0.002271            0.193886  1.608170   \n",
       "4              0.029703            0.002180            0.207698  1.607669   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.031757            0.001928            0.310332  1.504342   \n",
       "92             0.032081            0.002030            0.324806  1.497556   \n",
       "93             0.031502            0.002029            0.361505  1.533636   \n",
       "94             0.030961            0.002589            0.256387  1.557580   \n",
       "95             0.031148            0.002183            0.210514  1.552267   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -4.761534  4.215046     -1.545846  \n",
       "1  -3.997456  4.404543     -1.558906  \n",
       "2  -3.332317  4.414499     -1.590409  \n",
       "3  -3.164027  4.447552     -1.608170  \n",
       "4  -3.817663  4.467974     -1.607669  \n",
       "..       ...       ...           ...  \n",
       "91 -5.587657  4.086741     -1.504342  \n",
       "92 -4.816944  4.189585     -1.497556  \n",
       "93 -5.043850  4.176753     -1.533636  \n",
       "94 -3.557047  4.230513     -1.557580  \n",
       "95 -4.080012  4.359515     -1.552267  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182838</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>4.066981</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.361505</td>\n",
       "      <td>1.704331</td>\n",
       "      <td>-9.897822</td>\n",
       "      <td>5.258404</td>\n",
       "      <td>-1.704331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.182838           0.035524           4.066981   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.029525            0.000958            0.361505  1.704331   \n",
       "\n",
       "    NLL_min   NLL_max  model_scores_mean  \n",
       "0 -9.897822  5.258404          -1.704331  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.149164</td>\n",
       "      <td>0.099364</td>\n",
       "      <td>0.506768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.133439</td>\n",
       "      <td>0.090114</td>\n",
       "      <td>0.613282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.156476</td>\n",
       "      <td>0.102871</td>\n",
       "      <td>0.462424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.119907</td>\n",
       "      <td>0.081202</td>\n",
       "      <td>0.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.146436</td>\n",
       "      <td>0.096152</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.226275</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>0.108893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.241319</td>\n",
       "      <td>0.097446</td>\n",
       "      <td>-0.028520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.228734</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.099090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.227761</td>\n",
       "      <td>0.091697</td>\n",
       "      <td>0.112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.242663</td>\n",
       "      <td>0.099312</td>\n",
       "      <td>-0.037654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.149164        0.099364  0.506768\n",
       "1             2       0.133439        0.090114  0.613282\n",
       "2             3       0.156476        0.102871  0.462424\n",
       "3             4       0.119907        0.081202  0.710100\n",
       "4             5       0.146436        0.096152  0.542360\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.226275        0.090508  0.108893\n",
       "35036     35037       0.241319        0.097446 -0.028520\n",
       "35037     35038       0.228734        0.091421  0.099090\n",
       "35038     35039       0.227761        0.091697  0.112676\n",
       "35039     35040       0.242663        0.099312 -0.037654\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_1, ws_10m_loc_2, ws_10...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_1, ws_10m_loc_2, ws_10...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2397 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2365 scale=1.0000 norm=1.5731\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6121\n",
      "[iter 55] loss=0.2148 val_loss=0.2305 scale=1.0000 norm=1.6527\n",
      "[iter 56] loss=0.2121 val_loss=0.2277 scale=1.0000 norm=1.6943\n",
      "[iter 57] loss=0.2096 val_loss=0.2251 scale=1.0000 norm=1.7379\n",
      "[iter 58] loss=0.2072 val_loss=0.2225 scale=1.0000 norm=1.7827\n",
      "[iter 59] loss=0.2049 val_loss=0.2202 scale=1.0000 norm=1.8285\n",
      "[iter 60] loss=0.2027 val_loss=0.2179 scale=1.0000 norm=1.8758\n",
      "[iter 61] loss=0.2006 val_loss=0.2157 scale=1.0000 norm=1.9236\n",
      "[iter 62] loss=0.1987 val_loss=0.2136 scale=1.0000 norm=1.9726\n",
      "[iter 63] loss=0.1968 val_loss=0.2117 scale=1.0000 norm=2.0222\n",
      "[iter 64] loss=0.1950 val_loss=0.2097 scale=1.0000 norm=2.0716\n",
      "[iter 65] loss=0.1934 val_loss=0.2079 scale=1.0000 norm=2.1198\n",
      "[iter 66] loss=0.1918 val_loss=0.2062 scale=1.0000 norm=2.1685\n",
      "[iter 67] loss=0.1903 val_loss=0.2045 scale=1.0000 norm=2.2166\n",
      "[iter 68] loss=0.1888 val_loss=0.2030 scale=1.0000 norm=2.2621\n",
      "[iter 69] loss=0.1874 val_loss=0.2016 scale=1.0000 norm=2.3092\n",
      "[iter 70] loss=0.1861 val_loss=0.2002 scale=1.0000 norm=2.3542\n",
      "[iter 71] loss=0.1849 val_loss=0.1988 scale=1.0000 norm=2.4003\n",
      "[iter 72] loss=0.1837 val_loss=0.1975 scale=1.0000 norm=2.4434\n",
      "[iter 73] loss=0.1826 val_loss=0.1964 scale=1.0000 norm=2.4850\n",
      "[iter 74] loss=0.1816 val_loss=0.1953 scale=1.0000 norm=2.5247\n",
      "[iter 75] loss=0.1806 val_loss=0.1942 scale=1.0000 norm=2.5634\n",
      "[iter 76] loss=0.1796 val_loss=0.1931 scale=1.0000 norm=2.6012\n",
      "[iter 77] loss=0.1787 val_loss=0.1921 scale=1.0000 norm=2.6392\n",
      "[iter 78] loss=0.1778 val_loss=0.1912 scale=1.0000 norm=2.6753\n",
      "[iter 79] loss=0.1770 val_loss=0.1908 scale=0.5000 norm=1.3554\n",
      "[iter 80] loss=0.1766 val_loss=0.1904 scale=0.5000 norm=1.3637\n",
      "[iter 81] loss=0.1762 val_loss=0.1896 scale=1.0000 norm=2.7448\n",
      "[iter 82] loss=0.1755 val_loss=0.1892 scale=0.5000 norm=1.3885\n",
      "[iter 83] loss=0.1752 val_loss=0.1885 scale=1.0000 norm=2.7917\n",
      "[iter 84] loss=0.1745 val_loss=0.1881 scale=0.5000 norm=1.4103\n",
      "[iter 85] loss=0.1741 val_loss=0.1874 scale=1.0000 norm=2.8352\n",
      "[iter 86] loss=0.1735 val_loss=0.1871 scale=0.5000 norm=1.4310\n",
      "[iter 87] loss=0.1732 val_loss=0.1868 scale=0.5000 norm=1.4379\n",
      "[iter 88] loss=0.1729 val_loss=0.1865 scale=0.5000 norm=1.4448\n",
      "[iter 89] loss=0.1726 val_loss=0.1859 scale=1.0000 norm=2.9025\n",
      "[iter 90] loss=0.1721 val_loss=0.1856 scale=0.5000 norm=1.4639\n",
      "[iter 91] loss=0.1718 val_loss=0.1852 scale=1.0000 norm=2.9406\n",
      "[iter 92] loss=0.1713 val_loss=0.1850 scale=0.5000 norm=1.4827\n",
      "[iter 93] loss=0.1711 val_loss=0.1848 scale=0.5000 norm=1.4891\n",
      "[iter 94] loss=0.1709 val_loss=0.1845 scale=0.5000 norm=1.4961\n",
      "[iter 95] loss=0.1706 val_loss=0.1844 scale=0.5000 norm=1.5023\n",
      "[iter 96] loss=0.1704 val_loss=0.1839 scale=1.0000 norm=3.0181\n",
      "[iter 97] loss=0.1700 val_loss=0.1837 scale=1.0000 norm=3.0428\n",
      "[iter 98] loss=0.1696 val_loss=0.1835 scale=0.5000 norm=1.5336\n",
      "[iter 99] loss=0.1695 val_loss=0.1834 scale=0.5000 norm=1.5405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.179121</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>1.209181</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.173216</td>\n",
       "      <td>1.525175</td>\n",
       "      <td>-4.992516</td>\n",
       "      <td>3.737618</td>\n",
       "      <td>0.179121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.027752</td>\n",
       "      <td>1.251602</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.182676</td>\n",
       "      <td>1.577816</td>\n",
       "      <td>-5.071438</td>\n",
       "      <td>3.817570</td>\n",
       "      <td>0.174966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.172346</td>\n",
       "      <td>0.029181</td>\n",
       "      <td>1.230794</td>\n",
       "      <td>0.029307</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.201156</td>\n",
       "      <td>1.613788</td>\n",
       "      <td>-5.324899</td>\n",
       "      <td>3.830098</td>\n",
       "      <td>0.172346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173594</td>\n",
       "      <td>0.027057</td>\n",
       "      <td>1.360593</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.209069</td>\n",
       "      <td>1.628338</td>\n",
       "      <td>-5.532285</td>\n",
       "      <td>3.777957</td>\n",
       "      <td>0.173594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.174370</td>\n",
       "      <td>0.023169</td>\n",
       "      <td>1.743915</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.216978</td>\n",
       "      <td>1.637097</td>\n",
       "      <td>-4.923237</td>\n",
       "      <td>3.816740</td>\n",
       "      <td>0.174370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.174575</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>1.188012</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.332640</td>\n",
       "      <td>1.519523</td>\n",
       "      <td>-7.394523</td>\n",
       "      <td>3.655408</td>\n",
       "      <td>0.174575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.027359</td>\n",
       "      <td>1.292626</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.349515</td>\n",
       "      <td>1.496291</td>\n",
       "      <td>-7.060641</td>\n",
       "      <td>3.699331</td>\n",
       "      <td>0.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.172869</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>1.280126</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.334727</td>\n",
       "      <td>1.536134</td>\n",
       "      <td>-6.108559</td>\n",
       "      <td>3.672218</td>\n",
       "      <td>0.172869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.173467</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>1.202586</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>1.535249</td>\n",
       "      <td>-6.205893</td>\n",
       "      <td>3.743309</td>\n",
       "      <td>0.173467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.173984</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>1.195445</td>\n",
       "      <td>0.030507</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.216644</td>\n",
       "      <td>1.548839</td>\n",
       "      <td>-5.618845</td>\n",
       "      <td>3.819269</td>\n",
       "      <td>0.173984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.179121           0.027055           1.209181   \n",
       "1          2            0.174966           0.027752           1.251602   \n",
       "2          3            0.172346           0.029181           1.230794   \n",
       "3          4            0.173594           0.027057           1.360593   \n",
       "4          5            0.174370           0.023169           1.743915   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.174575           0.027414           1.188012   \n",
       "92        93            0.177200           0.027359           1.292626   \n",
       "93        94            0.172869           0.028389           1.280126   \n",
       "94        95            0.173467           0.026941           1.202586   \n",
       "95        96            0.173984           0.025852           1.195445   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.031229            0.003592            0.173216  1.525175   \n",
       "1              0.030172            0.003601            0.182676  1.577816   \n",
       "2              0.029307            0.003332            0.201156  1.613788   \n",
       "3              0.028786            0.003457            0.209069  1.628338   \n",
       "4              0.028755            0.003215            0.216978  1.637097   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.030692            0.003942            0.332640  1.519523   \n",
       "92             0.031123            0.003788            0.349515  1.496291   \n",
       "93             0.030599            0.003493            0.334727  1.536134   \n",
       "94             0.030708            0.003340            0.282736  1.535249   \n",
       "95             0.030507            0.003644            0.216644  1.548839   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -4.992516  3.737618      0.179121  \n",
       "1  -5.071438  3.817570      0.174966  \n",
       "2  -5.324899  3.830098      0.172346  \n",
       "3  -5.532285  3.777957      0.173594  \n",
       "4  -4.923237  3.816740      0.174370  \n",
       "..       ...       ...           ...  \n",
       "91 -7.394523  3.655408      0.174575  \n",
       "92 -7.060641  3.699331      0.177200  \n",
       "93 -6.108559  3.672218      0.172869  \n",
       "94 -6.205893  3.743309      0.173467  \n",
       "95 -5.618845  3.819269      0.173984  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183389</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>4.164072</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.354697</td>\n",
       "      <td>1.713057</td>\n",
       "      <td>-15.890658</td>\n",
       "      <td>4.043016</td>\n",
       "      <td>0.183389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.183389           0.021488           4.164072   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.028494            0.002954            0.354697  1.713057   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -15.890658  4.043016           0.183389  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.181373</td>\n",
       "      <td>0.120383</td>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.168156</td>\n",
       "      <td>0.113316</td>\n",
       "      <td>0.148110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.202171</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>-0.249565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.160059</td>\n",
       "      <td>0.108482</td>\n",
       "      <td>0.236545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.192656</td>\n",
       "      <td>0.126782</td>\n",
       "      <td>-0.126919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.258377</td>\n",
       "      <td>0.102980</td>\n",
       "      <td>-0.403313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.277321</td>\n",
       "      <td>0.111418</td>\n",
       "      <td>-0.617665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.245464</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>-0.239932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.242244</td>\n",
       "      <td>0.097878</td>\n",
       "      <td>-0.196059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.245912</td>\n",
       "      <td>0.101880</td>\n",
       "      <td>-0.405367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.181373        0.120383  0.004713\n",
       "1             2       0.168156        0.113316  0.148110\n",
       "2             3       0.202171        0.133162 -0.249565\n",
       "3             4       0.160059        0.108482  0.236545\n",
       "4             5       0.192656        0.126782 -0.126919\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.258377        0.102980 -0.403313\n",
       "35036     35037       0.277321        0.111418 -0.617665\n",
       "35037     35038       0.245464        0.098343 -0.239932\n",
       "35038     35039       0.242244        0.097878 -0.196059\n",
       "35039     35040       0.245912        0.101880 -0.405367\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3056 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5283 val_loss=-0.3417 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=-0.5638 val_loss=-0.3725 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=-0.5939 val_loss=-0.4014 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=-0.6217 val_loss=-0.4271 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=-0.6465 val_loss=-0.4512 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=-0.6699 val_loss=-0.4735 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=-0.6915 val_loss=-0.4946 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5336 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=-0.7501 val_loss=-0.5700 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=-0.7856 val_loss=-0.5871 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=-0.8025 val_loss=-0.6209 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=-0.8358 val_loss=-0.6521 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=-0.8668 val_loss=-0.6821 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=-0.8967 val_loss=-0.7114 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=-0.9259 val_loss=-0.7397 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=-0.9540 val_loss=-0.7674 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=-0.9816 val_loss=-0.7945 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=-1.0087 val_loss=-0.8209 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=-1.0353 val_loss=-0.8466 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=-1.0612 val_loss=-0.8716 scale=2.0000 norm=1.3122\n",
      "[iter 22] loss=-1.0866 val_loss=-0.8961 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=-1.1117 val_loss=-0.9207 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=-1.1367 val_loss=-0.9446 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=-1.1610 val_loss=-0.9681 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=-1.1848 val_loss=-0.9910 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=-1.2083 val_loss=-1.0135 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=-1.2315 val_loss=-1.0355 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=-1.2543 val_loss=-1.0576 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=-1.2769 val_loss=-1.0790 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=-1.2988 val_loss=-1.1003 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=-1.3206 val_loss=-1.1211 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=-1.3419 val_loss=-1.1416 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=-1.3630 val_loss=-1.1615 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=-1.3837 val_loss=-1.1812 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=-1.4040 val_loss=-1.2005 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=-1.4240 val_loss=-1.2194 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=-1.4435 val_loss=-1.2379 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=-1.4628 val_loss=-1.2558 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=-1.4814 val_loss=-1.2733 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=-1.4997 val_loss=-1.2904 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=-1.5176 val_loss=-1.3072 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=-1.5351 val_loss=-1.3235 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=-1.5522 val_loss=-1.3393 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=-1.5688 val_loss=-1.3549 scale=2.0000 norm=1.0687\n",
      "[iter 46] loss=-1.5851 val_loss=-1.3699 scale=2.0000 norm=1.0657\n",
      "[iter 47] loss=-1.6009 val_loss=-1.3845 scale=2.0000 norm=1.0631\n",
      "[iter 48] loss=-1.6164 val_loss=-1.3988 scale=2.0000 norm=1.0606\n",
      "[iter 49] loss=-1.6314 val_loss=-1.4126 scale=2.0000 norm=1.0584\n",
      "[iter 50] loss=-1.6461 val_loss=-1.4261 scale=2.0000 norm=1.0565\n",
      "[iter 51] loss=-1.6603 val_loss=-1.4391 scale=2.0000 norm=1.0548\n",
      "[iter 52] loss=-1.6741 val_loss=-1.4515 scale=2.0000 norm=1.0533\n",
      "[iter 53] loss=-1.6876 val_loss=-1.4636 scale=2.0000 norm=1.0518\n",
      "[iter 54] loss=-1.7007 val_loss=-1.4755 scale=2.0000 norm=1.0508\n",
      "[iter 55] loss=-1.7134 val_loss=-1.4868 scale=2.0000 norm=1.0498\n",
      "[iter 56] loss=-1.7257 val_loss=-1.4979 scale=2.0000 norm=1.0491\n",
      "[iter 57] loss=-1.7375 val_loss=-1.5086 scale=2.0000 norm=1.0486\n",
      "[iter 58] loss=-1.7489 val_loss=-1.5189 scale=2.0000 norm=1.0483\n",
      "[iter 59] loss=-1.7600 val_loss=-1.5285 scale=2.0000 norm=1.0481\n",
      "[iter 60] loss=-1.7707 val_loss=-1.5381 scale=2.0000 norm=1.0482\n",
      "[iter 61] loss=-1.7810 val_loss=-1.5473 scale=2.0000 norm=1.0484\n",
      "[iter 62] loss=-1.7910 val_loss=-1.5562 scale=2.0000 norm=1.0487\n",
      "[iter 63] loss=-1.8005 val_loss=-1.5648 scale=2.0000 norm=1.0492\n",
      "[iter 64] loss=-1.8098 val_loss=-1.5732 scale=2.0000 norm=1.0499\n",
      "[iter 65] loss=-1.8187 val_loss=-1.5813 scale=2.0000 norm=1.0507\n",
      "[iter 66] loss=-1.8273 val_loss=-1.5891 scale=2.0000 norm=1.0515\n",
      "[iter 67] loss=-1.8357 val_loss=-1.5967 scale=2.0000 norm=1.0524\n",
      "[iter 68] loss=-1.8436 val_loss=-1.6034 scale=2.0000 norm=1.0534\n",
      "[iter 69] loss=-1.8512 val_loss=-1.6101 scale=2.0000 norm=1.0548\n",
      "[iter 70] loss=-1.8585 val_loss=-1.6161 scale=2.0000 norm=1.0562\n",
      "[iter 71] loss=-1.8655 val_loss=-1.6221 scale=2.0000 norm=1.0577\n",
      "[iter 72] loss=-1.8722 val_loss=-1.6280 scale=2.0000 norm=1.0593\n",
      "[iter 73] loss=-1.8786 val_loss=-1.6334 scale=2.0000 norm=1.0609\n",
      "[iter 74] loss=-1.8848 val_loss=-1.6387 scale=2.0000 norm=1.0626\n",
      "[iter 75] loss=-1.8907 val_loss=-1.6436 scale=2.0000 norm=1.0644\n",
      "[iter 76] loss=-1.8963 val_loss=-1.6488 scale=2.0000 norm=1.0665\n",
      "[iter 77] loss=-1.9017 val_loss=-1.6531 scale=2.0000 norm=1.0684\n",
      "[iter 78] loss=-1.9067 val_loss=-1.6572 scale=2.0000 norm=1.0704\n",
      "[iter 79] loss=-1.9116 val_loss=-1.6613 scale=2.0000 norm=1.0724\n",
      "[iter 80] loss=-1.9163 val_loss=-1.6651 scale=2.0000 norm=1.0744\n",
      "[iter 81] loss=-1.9208 val_loss=-1.6686 scale=2.0000 norm=1.0764\n",
      "[iter 82] loss=-1.9250 val_loss=-1.6724 scale=2.0000 norm=1.0786\n",
      "[iter 83] loss=-1.9292 val_loss=-1.6753 scale=2.0000 norm=1.0806\n",
      "[iter 84] loss=-1.9330 val_loss=-1.6782 scale=2.0000 norm=1.0827\n",
      "[iter 85] loss=-1.9365 val_loss=-1.6813 scale=2.0000 norm=1.0849\n",
      "[iter 86] loss=-1.9401 val_loss=-1.6840 scale=2.0000 norm=1.0869\n",
      "[iter 87] loss=-1.9434 val_loss=-1.6867 scale=2.0000 norm=1.0891\n",
      "[iter 88] loss=-1.9465 val_loss=-1.6892 scale=2.0000 norm=1.0913\n",
      "[iter 89] loss=-1.9496 val_loss=-1.6913 scale=2.0000 norm=1.0934\n",
      "[iter 90] loss=-1.9525 val_loss=-1.6933 scale=2.0000 norm=1.0956\n",
      "[iter 91] loss=-1.9552 val_loss=-1.6953 scale=2.0000 norm=1.0978\n",
      "[iter 92] loss=-1.9577 val_loss=-1.6966 scale=2.0000 norm=1.1000\n",
      "[iter 93] loss=-1.9602 val_loss=-1.6983 scale=2.0000 norm=1.1020\n",
      "[iter 94] loss=-1.9624 val_loss=-1.7003 scale=2.0000 norm=1.1041\n",
      "[iter 95] loss=-1.9648 val_loss=-1.7018 scale=2.0000 norm=1.1062\n",
      "[iter 96] loss=-1.9668 val_loss=-1.7032 scale=2.0000 norm=1.1084\n",
      "[iter 97] loss=-1.9687 val_loss=-1.7041 scale=2.0000 norm=1.1104\n",
      "[iter 98] loss=-1.9706 val_loss=-1.7055 scale=2.0000 norm=1.1124\n",
      "[iter 99] loss=-1.9725 val_loss=-1.7069 scale=2.0000 norm=1.1144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.178169</td>\n",
       "      <td>0.038029</td>\n",
       "      <td>1.184753</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.151036</td>\n",
       "      <td>1.534851</td>\n",
       "      <td>-5.312266</td>\n",
       "      <td>4.217456</td>\n",
       "      <td>-1.534851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>1.253203</td>\n",
       "      <td>0.031059</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.171275</td>\n",
       "      <td>1.557586</td>\n",
       "      <td>-4.155692</td>\n",
       "      <td>4.422803</td>\n",
       "      <td>-1.557586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.172996</td>\n",
       "      <td>0.039860</td>\n",
       "      <td>1.324569</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.175911</td>\n",
       "      <td>1.599451</td>\n",
       "      <td>-4.379843</td>\n",
       "      <td>4.413207</td>\n",
       "      <td>-1.599451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175010</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>1.355670</td>\n",
       "      <td>0.029685</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.187715</td>\n",
       "      <td>1.607184</td>\n",
       "      <td>-3.100128</td>\n",
       "      <td>4.468014</td>\n",
       "      <td>-1.607184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.176349</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>1.552844</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.207818</td>\n",
       "      <td>1.609195</td>\n",
       "      <td>-4.037515</td>\n",
       "      <td>4.471000</td>\n",
       "      <td>-1.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.177790</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>1.270670</td>\n",
       "      <td>0.031717</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.333711</td>\n",
       "      <td>1.510412</td>\n",
       "      <td>-5.663024</td>\n",
       "      <td>4.080989</td>\n",
       "      <td>-1.510412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.180427</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>1.282409</td>\n",
       "      <td>0.032297</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.330069</td>\n",
       "      <td>1.490699</td>\n",
       "      <td>-5.489529</td>\n",
       "      <td>4.162583</td>\n",
       "      <td>-1.490699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.174646</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>1.219714</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.360213</td>\n",
       "      <td>1.533654</td>\n",
       "      <td>-5.119319</td>\n",
       "      <td>4.199768</td>\n",
       "      <td>-1.533654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.173535</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>1.155947</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.257108</td>\n",
       "      <td>1.547640</td>\n",
       "      <td>-3.734538</td>\n",
       "      <td>4.264084</td>\n",
       "      <td>-1.547640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.175563</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>1.128913</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.239198</td>\n",
       "      <td>1.548813</td>\n",
       "      <td>-3.967850</td>\n",
       "      <td>4.324281</td>\n",
       "      <td>-1.548813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.178169           0.038029           1.184753   \n",
       "1          2            0.177840           0.038137           1.253203   \n",
       "2          3            0.172996           0.039860           1.324569   \n",
       "3          4            0.175010           0.037047           1.355670   \n",
       "4          5            0.176349           0.037241           1.552844   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.177790           0.038247           1.270670   \n",
       "92        93            0.180427           0.038298           1.282409   \n",
       "93        94            0.174646           0.039109           1.219714   \n",
       "94        95            0.173535           0.038604           1.155947   \n",
       "95        96            0.175563           0.038013           1.128913   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.031700            0.002227            0.151036  1.534851   \n",
       "1              0.031059            0.002392            0.171275  1.557586   \n",
       "2              0.029883            0.002500            0.175911  1.599451   \n",
       "3              0.029685            0.002104            0.187715  1.607184   \n",
       "4              0.029621            0.002148            0.207818  1.609195   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.031717            0.001677            0.333711  1.510412   \n",
       "92             0.032297            0.001754            0.330069  1.490699   \n",
       "93             0.031446            0.001715            0.360213  1.533654   \n",
       "94             0.031039            0.002514            0.257108  1.547640   \n",
       "95             0.031193            0.002220            0.239198  1.548813   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -5.312266  4.217456     -1.534851  \n",
       "1  -4.155692  4.422803     -1.557586  \n",
       "2  -4.379843  4.413207     -1.599451  \n",
       "3  -3.100128  4.468014     -1.607184  \n",
       "4  -4.037515  4.471000     -1.609195  \n",
       "..       ...       ...           ...  \n",
       "91 -5.663024  4.080989     -1.510412  \n",
       "92 -5.489529  4.162583     -1.490699  \n",
       "93 -5.119319  4.199768     -1.533654  \n",
       "94 -3.734538  4.264084     -1.547640  \n",
       "95 -3.967850  4.324281     -1.548813  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182783</td>\n",
       "      <td>0.034712</td>\n",
       "      <td>4.123051</td>\n",
       "      <td>0.029426</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.360213</td>\n",
       "      <td>1.706868</td>\n",
       "      <td>-10.243708</td>\n",
       "      <td>5.234022</td>\n",
       "      <td>-1.706868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.182783           0.034712           4.123051   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.029426            0.000709            0.360213  1.706868   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -10.243708  5.234022          -1.706868  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.100617</td>\n",
       "      <td>0.477488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.135213</td>\n",
       "      <td>0.091125</td>\n",
       "      <td>0.594954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.158860</td>\n",
       "      <td>0.104269</td>\n",
       "      <td>0.429735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.119152</td>\n",
       "      <td>0.080472</td>\n",
       "      <td>0.718087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.146431</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.534611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.214751</td>\n",
       "      <td>0.086341</td>\n",
       "      <td>0.197117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.267074</td>\n",
       "      <td>0.106986</td>\n",
       "      <td>-0.296853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.233532</td>\n",
       "      <td>0.093332</td>\n",
       "      <td>0.030637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.211973</td>\n",
       "      <td>0.086051</td>\n",
       "      <td>0.215467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.217120</td>\n",
       "      <td>0.089940</td>\n",
       "      <td>0.144952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.151351        0.100617  0.477488\n",
       "1             2       0.135213        0.091125  0.594954\n",
       "2             3       0.158860        0.104269  0.429735\n",
       "3             4       0.119152        0.080472  0.718087\n",
       "4             5       0.146431        0.095901  0.534611\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.214751        0.086341  0.197117\n",
       "35036     35037       0.267074        0.106986 -0.296853\n",
       "35037     35038       0.233532        0.093332  0.030637\n",
       "35038     35039       0.211973        0.086051  0.215467\n",
       "35039     35040       0.217120        0.089940  0.144952\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=0.6450 val_loss=0.6712 scale=1.0000 norm=1.1166\n",
      "[iter 1] loss=0.6277 val_loss=0.6532 scale=1.0000 norm=1.0953\n",
      "[iter 2] loss=0.6112 val_loss=0.6362 scale=1.0000 norm=1.0762\n",
      "[iter 3] loss=0.5955 val_loss=0.6199 scale=1.0000 norm=1.0591\n",
      "[iter 4] loss=0.5804 val_loss=0.6044 scale=1.0000 norm=1.0439\n",
      "[iter 5] loss=0.5660 val_loss=0.5896 scale=1.0000 norm=1.0303\n",
      "[iter 6] loss=0.5523 val_loss=0.5755 scale=1.0000 norm=1.0184\n",
      "[iter 7] loss=0.5391 val_loss=0.5620 scale=1.0000 norm=1.0079\n",
      "[iter 8] loss=0.5264 val_loss=0.5490 scale=1.0000 norm=0.9987\n",
      "[iter 9] loss=0.5142 val_loss=0.5365 scale=1.0000 norm=0.9907\n",
      "[iter 10] loss=0.5023 val_loss=0.5244 scale=1.0000 norm=0.9837\n",
      "[iter 11] loss=0.4909 val_loss=0.5128 scale=1.0000 norm=0.9780\n",
      "[iter 12] loss=0.4799 val_loss=0.5017 scale=1.0000 norm=0.9733\n",
      "[iter 13] loss=0.4694 val_loss=0.4908 scale=1.0000 norm=0.9697\n",
      "[iter 14] loss=0.4591 val_loss=0.4802 scale=1.0000 norm=0.9670\n",
      "[iter 15] loss=0.4491 val_loss=0.4701 scale=1.0000 norm=0.9652\n",
      "[iter 16] loss=0.4395 val_loss=0.4602 scale=1.0000 norm=0.9643\n",
      "[iter 17] loss=0.4301 val_loss=0.4507 scale=1.0000 norm=0.9643\n",
      "[iter 18] loss=0.4211 val_loss=0.4415 scale=1.0000 norm=0.9652\n",
      "[iter 19] loss=0.4122 val_loss=0.4325 scale=1.0000 norm=0.9668\n",
      "[iter 20] loss=0.4037 val_loss=0.4237 scale=1.0000 norm=0.9694\n",
      "[iter 21] loss=0.3953 val_loss=0.4152 scale=1.0000 norm=0.9727\n",
      "[iter 22] loss=0.3872 val_loss=0.4069 scale=1.0000 norm=0.9769\n",
      "[iter 23] loss=0.3793 val_loss=0.3988 scale=1.0000 norm=0.9819\n",
      "[iter 24] loss=0.3715 val_loss=0.3910 scale=1.0000 norm=0.9878\n",
      "[iter 25] loss=0.3641 val_loss=0.3832 scale=1.0000 norm=0.9945\n",
      "[iter 26] loss=0.3568 val_loss=0.3758 scale=1.0000 norm=1.0020\n",
      "[iter 27] loss=0.3496 val_loss=0.3685 scale=1.0000 norm=1.0104\n",
      "[iter 28] loss=0.3427 val_loss=0.3614 scale=1.0000 norm=1.0196\n",
      "[iter 29] loss=0.3359 val_loss=0.3545 scale=1.0000 norm=1.0295\n",
      "[iter 30] loss=0.3293 val_loss=0.3478 scale=1.0000 norm=1.0403\n",
      "[iter 31] loss=0.3229 val_loss=0.3412 scale=1.0000 norm=1.0521\n",
      "[iter 32] loss=0.3166 val_loss=0.3348 scale=1.0000 norm=1.0646\n",
      "[iter 33] loss=0.3105 val_loss=0.3284 scale=1.0000 norm=1.0782\n",
      "[iter 34] loss=0.3045 val_loss=0.3224 scale=1.0000 norm=1.0925\n",
      "[iter 35] loss=0.2988 val_loss=0.3166 scale=1.0000 norm=1.1077\n",
      "[iter 36] loss=0.2931 val_loss=0.3109 scale=1.0000 norm=1.1239\n",
      "[iter 37] loss=0.2876 val_loss=0.3052 scale=1.0000 norm=1.1412\n",
      "[iter 38] loss=0.2823 val_loss=0.2998 scale=1.0000 norm=1.1595\n",
      "[iter 39] loss=0.2772 val_loss=0.2945 scale=1.0000 norm=1.1786\n",
      "[iter 40] loss=0.2721 val_loss=0.2895 scale=1.0000 norm=1.1988\n",
      "[iter 41] loss=0.2673 val_loss=0.2845 scale=1.0000 norm=1.2202\n",
      "[iter 42] loss=0.2626 val_loss=0.2797 scale=1.0000 norm=1.2426\n",
      "[iter 43] loss=0.2580 val_loss=0.2750 scale=1.0000 norm=1.2662\n",
      "[iter 44] loss=0.2536 val_loss=0.2706 scale=1.0000 norm=1.2909\n",
      "[iter 45] loss=0.2494 val_loss=0.2662 scale=1.0000 norm=1.3168\n",
      "[iter 46] loss=0.2453 val_loss=0.2620 scale=1.0000 norm=1.3441\n",
      "[iter 47] loss=0.2413 val_loss=0.2579 scale=1.0000 norm=1.3725\n",
      "[iter 48] loss=0.2375 val_loss=0.2540 scale=1.0000 norm=1.4025\n",
      "[iter 49] loss=0.2338 val_loss=0.2502 scale=1.0000 norm=1.4337\n",
      "[iter 50] loss=0.2303 val_loss=0.2466 scale=1.0000 norm=1.4662\n",
      "[iter 51] loss=0.2269 val_loss=0.2431 scale=1.0000 norm=1.5003\n",
      "[iter 52] loss=0.2237 val_loss=0.2398 scale=1.0000 norm=1.5360\n",
      "[iter 53] loss=0.2206 val_loss=0.2366 scale=1.0000 norm=1.5728\n",
      "[iter 54] loss=0.2176 val_loss=0.2335 scale=1.0000 norm=1.6117\n",
      "[iter 55] loss=0.2148 val_loss=0.2306 scale=1.0000 norm=1.6521\n",
      "[iter 56] loss=0.2121 val_loss=0.2279 scale=1.0000 norm=1.6938\n",
      "[iter 57] loss=0.2095 val_loss=0.2252 scale=1.0000 norm=1.7368\n",
      "[iter 58] loss=0.2071 val_loss=0.2226 scale=1.0000 norm=1.7815\n",
      "[iter 59] loss=0.2048 val_loss=0.2202 scale=1.0000 norm=1.8280\n",
      "[iter 60] loss=0.2025 val_loss=0.2179 scale=1.0000 norm=1.8747\n",
      "[iter 61] loss=0.2005 val_loss=0.2157 scale=1.0000 norm=1.9225\n",
      "[iter 62] loss=0.1985 val_loss=0.2136 scale=1.0000 norm=1.9715\n",
      "[iter 63] loss=0.1966 val_loss=0.2116 scale=1.0000 norm=2.0201\n",
      "[iter 64] loss=0.1948 val_loss=0.2097 scale=1.0000 norm=2.0695\n",
      "[iter 65] loss=0.1931 val_loss=0.2079 scale=1.0000 norm=2.1185\n",
      "[iter 66] loss=0.1915 val_loss=0.2061 scale=1.0000 norm=2.1670\n",
      "[iter 67] loss=0.1899 val_loss=0.2045 scale=1.0000 norm=2.2159\n",
      "[iter 68] loss=0.1885 val_loss=0.2029 scale=1.0000 norm=2.2634\n",
      "[iter 69] loss=0.1871 val_loss=0.2015 scale=1.0000 norm=2.3105\n",
      "[iter 70] loss=0.1858 val_loss=0.2000 scale=1.0000 norm=2.3566\n",
      "[iter 71] loss=0.1845 val_loss=0.1986 scale=1.0000 norm=2.4010\n",
      "[iter 72] loss=0.1833 val_loss=0.1972 scale=1.0000 norm=2.4445\n",
      "[iter 73] loss=0.1822 val_loss=0.1961 scale=1.0000 norm=2.4863\n",
      "[iter 74] loss=0.1811 val_loss=0.1950 scale=1.0000 norm=2.5263\n",
      "[iter 75] loss=0.1801 val_loss=0.1939 scale=1.0000 norm=2.5651\n",
      "[iter 76] loss=0.1791 val_loss=0.1934 scale=0.5000 norm=1.3018\n",
      "[iter 77] loss=0.1786 val_loss=0.1928 scale=0.5000 norm=1.3107\n",
      "[iter 78] loss=0.1781 val_loss=0.1919 scale=1.0000 norm=2.6394\n",
      "[iter 79] loss=0.1773 val_loss=0.1914 scale=0.5000 norm=1.3388\n",
      "[iter 80] loss=0.1768 val_loss=0.1904 scale=1.0000 norm=2.6951\n",
      "[iter 81] loss=0.1760 val_loss=0.1899 scale=0.5000 norm=1.3646\n",
      "[iter 82] loss=0.1756 val_loss=0.1895 scale=0.5000 norm=1.3732\n",
      "[iter 83] loss=0.1752 val_loss=0.1887 scale=1.0000 norm=2.7620\n",
      "[iter 84] loss=0.1745 val_loss=0.1884 scale=0.5000 norm=1.3976\n",
      "[iter 85] loss=0.1742 val_loss=0.1880 scale=0.5000 norm=1.4048\n",
      "[iter 86] loss=0.1738 val_loss=0.1877 scale=0.5000 norm=1.4127\n",
      "[iter 87] loss=0.1735 val_loss=0.1873 scale=0.5000 norm=1.4203\n",
      "[iter 88] loss=0.1732 val_loss=0.1870 scale=0.5000 norm=1.4272\n",
      "[iter 89] loss=0.1729 val_loss=0.1866 scale=0.5000 norm=1.4342\n",
      "[iter 90] loss=0.1726 val_loss=0.1863 scale=0.5000 norm=1.4411\n",
      "[iter 91] loss=0.1723 val_loss=0.1860 scale=0.5000 norm=1.4474\n",
      "[iter 92] loss=0.1720 val_loss=0.1857 scale=0.5000 norm=1.4536\n",
      "[iter 93] loss=0.1717 val_loss=0.1851 scale=1.0000 norm=2.9208\n",
      "[iter 94] loss=0.1711 val_loss=0.1849 scale=0.5000 norm=1.4734\n",
      "[iter 95] loss=0.1709 val_loss=0.1847 scale=0.5000 norm=1.4792\n",
      "[iter 96] loss=0.1706 val_loss=0.1842 scale=1.0000 norm=2.9721\n",
      "[iter 97] loss=0.1701 val_loss=0.1840 scale=0.5000 norm=1.4982\n",
      "[iter 98] loss=0.1699 val_loss=0.1838 scale=0.5000 norm=1.5045\n",
      "[iter 99] loss=0.1697 val_loss=0.1836 scale=0.5000 norm=1.5113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187359</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>1.242805</td>\n",
       "      <td>0.033236</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.180066</td>\n",
       "      <td>1.447614</td>\n",
       "      <td>-4.902627</td>\n",
       "      <td>3.732604</td>\n",
       "      <td>0.187359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>1.276275</td>\n",
       "      <td>0.032025</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.186674</td>\n",
       "      <td>1.499161</td>\n",
       "      <td>-5.574791</td>\n",
       "      <td>3.804623</td>\n",
       "      <td>0.183309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180570</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>1.261597</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.202221</td>\n",
       "      <td>1.539715</td>\n",
       "      <td>-5.925210</td>\n",
       "      <td>3.808504</td>\n",
       "      <td>0.180570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.181470</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>1.366303</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.209256</td>\n",
       "      <td>1.554281</td>\n",
       "      <td>-6.054287</td>\n",
       "      <td>3.801946</td>\n",
       "      <td>0.181470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.181890</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>1.777764</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.218246</td>\n",
       "      <td>1.563996</td>\n",
       "      <td>-5.395435</td>\n",
       "      <td>3.803171</td>\n",
       "      <td>0.181890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>1.166702</td>\n",
       "      <td>0.030042</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.331374</td>\n",
       "      <td>1.549593</td>\n",
       "      <td>-6.907003</td>\n",
       "      <td>3.648384</td>\n",
       "      <td>0.170613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.173528</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>1.310493</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.344137</td>\n",
       "      <td>1.520153</td>\n",
       "      <td>-6.567456</td>\n",
       "      <td>3.681160</td>\n",
       "      <td>0.173528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.168380</td>\n",
       "      <td>0.029265</td>\n",
       "      <td>1.304247</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.327877</td>\n",
       "      <td>1.563779</td>\n",
       "      <td>-5.731185</td>\n",
       "      <td>3.654294</td>\n",
       "      <td>0.168380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.168914</td>\n",
       "      <td>0.028313</td>\n",
       "      <td>1.216650</td>\n",
       "      <td>0.029943</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.285835</td>\n",
       "      <td>1.565079</td>\n",
       "      <td>-5.894972</td>\n",
       "      <td>3.680665</td>\n",
       "      <td>0.168914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>1.255650</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.215278</td>\n",
       "      <td>1.576873</td>\n",
       "      <td>-5.171151</td>\n",
       "      <td>3.778583</td>\n",
       "      <td>0.169517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.187359           0.027213           1.242805   \n",
       "1          2            0.183309           0.030142           1.276275   \n",
       "2          3            0.180570           0.030806           1.261597   \n",
       "3          4            0.181470           0.028249           1.366303   \n",
       "4          5            0.181890           0.025968           1.777764   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.170613           0.027771           1.166702   \n",
       "92        93            0.173528           0.028062           1.310493   \n",
       "93        94            0.168380           0.029265           1.304247   \n",
       "94        95            0.168914           0.028313           1.216650   \n",
       "95        96            0.169517           0.026090           1.255650   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.033236            0.003582            0.180066  1.447614   \n",
       "1              0.032025            0.003599            0.186674  1.499161   \n",
       "2              0.031090            0.003311            0.202221  1.539715   \n",
       "3              0.030578            0.003465            0.209256  1.554281   \n",
       "4              0.030555            0.003138            0.218246  1.563996   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.030042            0.004123            0.331374  1.549593   \n",
       "92             0.030509            0.003848            0.344137  1.520153   \n",
       "93             0.029837            0.003525            0.327877  1.563779   \n",
       "94             0.029943            0.003442            0.285835  1.565079   \n",
       "95             0.029735            0.003829            0.215278  1.576873   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -4.902627  3.732604      0.187359  \n",
       "1  -5.574791  3.804623      0.183309  \n",
       "2  -5.925210  3.808504      0.180570  \n",
       "3  -6.054287  3.801946      0.181470  \n",
       "4  -5.395435  3.803171      0.181890  \n",
       "..       ...       ...           ...  \n",
       "91 -6.907003  3.648384      0.170613  \n",
       "92 -6.567456  3.681160      0.173528  \n",
       "93 -5.731185  3.654294      0.168380  \n",
       "94 -5.894972  3.680665      0.168914  \n",
       "95 -5.171151  3.778583      0.169517  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183625</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>4.185913</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.344415</td>\n",
       "      <td>1.707729</td>\n",
       "      <td>-13.281745</td>\n",
       "      <td>4.013085</td>\n",
       "      <td>0.183625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.183625           0.021821           4.185913   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.028695            0.002956            0.344415  1.707729   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores_mean  \n",
       "0 -13.281745  4.013085           0.183625  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>0.109887</td>\n",
       "      <td>0.325691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.150321</td>\n",
       "      <td>0.101555</td>\n",
       "      <td>0.445656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.181013</td>\n",
       "      <td>0.119368</td>\n",
       "      <td>0.183357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.137799</td>\n",
       "      <td>0.093448</td>\n",
       "      <td>0.552358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.173414</td>\n",
       "      <td>0.114351</td>\n",
       "      <td>0.256454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.253795</td>\n",
       "      <td>0.101586</td>\n",
       "      <td>-0.441114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.272171</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>-0.614304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.240283</td>\n",
       "      <td>0.096597</td>\n",
       "      <td>-0.225651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.236011</td>\n",
       "      <td>0.095744</td>\n",
       "      <td>-0.174640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.239033</td>\n",
       "      <td>0.099350</td>\n",
       "      <td>-0.344131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.165027        0.109887  0.325691\n",
       "1             2       0.150321        0.101555  0.445656\n",
       "2             3       0.181013        0.119368  0.183357\n",
       "3             4       0.137799        0.093448  0.552358\n",
       "4             5       0.173414        0.114351  0.256454\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.253795        0.101586 -0.441114\n",
       "35036     35037       0.272171        0.109718 -0.614304\n",
       "35037     35038       0.240283        0.096597 -0.225651\n",
       "35038     35039       0.236011        0.095744 -0.174640\n",
       "35039     35040       0.239033        0.099350 -0.344131\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.CRPScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and transformed successfully. Shape of DataFrame: (78912, 22)\n",
      "# of training observations: 245376 | 77.76%\n",
      "# of validation observations: 35040 | 11.10%\n",
      "# of test observations: 35133 | 11.13%\n",
      "[iter 0] loss=-0.4862 val_loss=-0.3056 scale=1.0000 norm=1.1098\n",
      "[iter 1] loss=-0.5283 val_loss=-0.3417 scale=1.0000 norm=1.0709\n",
      "[iter 2] loss=-0.5638 val_loss=-0.3725 scale=1.0000 norm=1.0384\n",
      "[iter 3] loss=-0.5939 val_loss=-0.4014 scale=1.0000 norm=1.0107\n",
      "[iter 4] loss=-0.6217 val_loss=-0.4271 scale=1.0000 norm=0.9852\n",
      "[iter 5] loss=-0.6465 val_loss=-0.4512 scale=1.0000 norm=0.9624\n",
      "[iter 6] loss=-0.6699 val_loss=-0.4735 scale=1.0000 norm=0.9411\n",
      "[iter 7] loss=-0.6915 val_loss=-0.4946 scale=1.0000 norm=0.9216\n",
      "[iter 8] loss=-0.7120 val_loss=-0.5145 scale=1.0000 norm=0.9031\n",
      "[iter 9] loss=-0.7315 val_loss=-0.5336 scale=1.0000 norm=0.8859\n",
      "[iter 10] loss=-0.7501 val_loss=-0.5700 scale=2.0000 norm=1.7391\n",
      "[iter 11] loss=-0.7856 val_loss=-0.5871 scale=1.0000 norm=0.8390\n",
      "[iter 12] loss=-0.8025 val_loss=-0.6209 scale=2.0000 norm=1.6500\n",
      "[iter 13] loss=-0.8358 val_loss=-0.6521 scale=2.0000 norm=1.5964\n",
      "[iter 14] loss=-0.8668 val_loss=-0.6821 scale=2.0000 norm=1.5490\n",
      "[iter 15] loss=-0.8967 val_loss=-0.7114 scale=2.0000 norm=1.5055\n",
      "[iter 16] loss=-0.9259 val_loss=-0.7397 scale=2.0000 norm=1.4653\n",
      "[iter 17] loss=-0.9540 val_loss=-0.7674 scale=2.0000 norm=1.4292\n",
      "[iter 18] loss=-0.9816 val_loss=-0.7945 scale=2.0000 norm=1.3962\n",
      "[iter 19] loss=-1.0087 val_loss=-0.8209 scale=2.0000 norm=1.3656\n",
      "[iter 20] loss=-1.0353 val_loss=-0.8466 scale=2.0000 norm=1.3375\n",
      "[iter 21] loss=-1.0612 val_loss=-0.8716 scale=2.0000 norm=1.3122\n",
      "[iter 22] loss=-1.0866 val_loss=-0.8961 scale=2.0000 norm=1.2894\n",
      "[iter 23] loss=-1.1117 val_loss=-0.9207 scale=2.0000 norm=1.2682\n",
      "[iter 24] loss=-1.1367 val_loss=-0.9446 scale=2.0000 norm=1.2485\n",
      "[iter 25] loss=-1.1610 val_loss=-0.9681 scale=2.0000 norm=1.2308\n",
      "[iter 26] loss=-1.1848 val_loss=-0.9910 scale=2.0000 norm=1.2145\n",
      "[iter 27] loss=-1.2083 val_loss=-1.0135 scale=2.0000 norm=1.1998\n",
      "[iter 28] loss=-1.2315 val_loss=-1.0355 scale=2.0000 norm=1.1862\n",
      "[iter 29] loss=-1.2543 val_loss=-1.0576 scale=2.0000 norm=1.1739\n",
      "[iter 30] loss=-1.2769 val_loss=-1.0790 scale=2.0000 norm=1.1623\n",
      "[iter 31] loss=-1.2988 val_loss=-1.1003 scale=2.0000 norm=1.1519\n",
      "[iter 32] loss=-1.3206 val_loss=-1.1211 scale=2.0000 norm=1.1422\n",
      "[iter 33] loss=-1.3419 val_loss=-1.1416 scale=2.0000 norm=1.1334\n",
      "[iter 34] loss=-1.3630 val_loss=-1.1615 scale=2.0000 norm=1.1252\n",
      "[iter 35] loss=-1.3837 val_loss=-1.1812 scale=2.0000 norm=1.1178\n",
      "[iter 36] loss=-1.4040 val_loss=-1.2005 scale=2.0000 norm=1.1109\n",
      "[iter 37] loss=-1.4240 val_loss=-1.2194 scale=2.0000 norm=1.1045\n",
      "[iter 38] loss=-1.4435 val_loss=-1.2379 scale=2.0000 norm=1.0986\n",
      "[iter 39] loss=-1.4628 val_loss=-1.2558 scale=2.0000 norm=1.0932\n",
      "[iter 40] loss=-1.4814 val_loss=-1.2733 scale=2.0000 norm=1.0881\n",
      "[iter 41] loss=-1.4997 val_loss=-1.2904 scale=2.0000 norm=1.0835\n",
      "[iter 42] loss=-1.5176 val_loss=-1.3072 scale=2.0000 norm=1.0792\n",
      "[iter 43] loss=-1.5351 val_loss=-1.3235 scale=2.0000 norm=1.0754\n",
      "[iter 44] loss=-1.5522 val_loss=-1.3393 scale=2.0000 norm=1.0719\n",
      "[iter 45] loss=-1.5689 val_loss=-1.3550 scale=2.0000 norm=1.0686\n",
      "[iter 46] loss=-1.5853 val_loss=-1.3699 scale=2.0000 norm=1.0656\n",
      "[iter 47] loss=-1.6011 val_loss=-1.3846 scale=2.0000 norm=1.0629\n",
      "[iter 48] loss=-1.6167 val_loss=-1.3989 scale=2.0000 norm=1.0604\n",
      "[iter 49] loss=-1.6318 val_loss=-1.4126 scale=2.0000 norm=1.0582\n",
      "[iter 50] loss=-1.6465 val_loss=-1.4263 scale=2.0000 norm=1.0562\n",
      "[iter 51] loss=-1.6608 val_loss=-1.4391 scale=2.0000 norm=1.0543\n",
      "[iter 52] loss=-1.6747 val_loss=-1.4518 scale=2.0000 norm=1.0526\n",
      "[iter 53] loss=-1.6883 val_loss=-1.4642 scale=2.0000 norm=1.0513\n",
      "[iter 54] loss=-1.7015 val_loss=-1.4760 scale=2.0000 norm=1.0501\n",
      "[iter 55] loss=-1.7142 val_loss=-1.4876 scale=2.0000 norm=1.0490\n",
      "[iter 56] loss=-1.7265 val_loss=-1.4985 scale=2.0000 norm=1.0482\n",
      "[iter 57] loss=-1.7384 val_loss=-1.5095 scale=2.0000 norm=1.0477\n",
      "[iter 58] loss=-1.7501 val_loss=-1.5198 scale=2.0000 norm=1.0471\n",
      "[iter 59] loss=-1.7613 val_loss=-1.5300 scale=2.0000 norm=1.0469\n",
      "[iter 60] loss=-1.7722 val_loss=-1.5397 scale=2.0000 norm=1.0467\n",
      "[iter 61] loss=-1.7826 val_loss=-1.5491 scale=2.0000 norm=1.0468\n",
      "[iter 62] loss=-1.7928 val_loss=-1.5582 scale=2.0000 norm=1.0470\n",
      "[iter 63] loss=-1.8025 val_loss=-1.5667 scale=2.0000 norm=1.0474\n",
      "[iter 64] loss=-1.8119 val_loss=-1.5748 scale=2.0000 norm=1.0481\n",
      "[iter 65] loss=-1.8209 val_loss=-1.5826 scale=2.0000 norm=1.0487\n",
      "[iter 66] loss=-1.8296 val_loss=-1.5906 scale=2.0000 norm=1.0496\n",
      "[iter 67] loss=-1.8380 val_loss=-1.5980 scale=2.0000 norm=1.0503\n",
      "[iter 68] loss=-1.8460 val_loss=-1.6052 scale=2.0000 norm=1.0512\n",
      "[iter 69] loss=-1.8538 val_loss=-1.6119 scale=2.0000 norm=1.0525\n",
      "[iter 70] loss=-1.8612 val_loss=-1.6187 scale=2.0000 norm=1.0537\n",
      "[iter 71] loss=-1.8684 val_loss=-1.6248 scale=2.0000 norm=1.0550\n",
      "[iter 72] loss=-1.8752 val_loss=-1.6307 scale=2.0000 norm=1.0563\n",
      "[iter 73] loss=-1.8818 val_loss=-1.6363 scale=2.0000 norm=1.0579\n",
      "[iter 74] loss=-1.8881 val_loss=-1.6415 scale=2.0000 norm=1.0595\n",
      "[iter 75] loss=-1.8941 val_loss=-1.6459 scale=2.0000 norm=1.0612\n",
      "[iter 76] loss=-1.8997 val_loss=-1.6510 scale=2.0000 norm=1.0629\n",
      "[iter 77] loss=-1.9052 val_loss=-1.6560 scale=2.0000 norm=1.0648\n",
      "[iter 78] loss=-1.9106 val_loss=-1.6600 scale=2.0000 norm=1.0667\n",
      "[iter 79] loss=-1.9155 val_loss=-1.6640 scale=2.0000 norm=1.0687\n",
      "[iter 80] loss=-1.9202 val_loss=-1.6686 scale=2.0000 norm=1.0707\n",
      "[iter 81] loss=-1.9250 val_loss=-1.6720 scale=2.0000 norm=1.0727\n",
      "[iter 82] loss=-1.9293 val_loss=-1.6751 scale=2.0000 norm=1.0748\n",
      "[iter 83] loss=-1.9333 val_loss=-1.6785 scale=2.0000 norm=1.0769\n",
      "[iter 84] loss=-1.9373 val_loss=-1.6813 scale=2.0000 norm=1.0790\n",
      "[iter 85] loss=-1.9409 val_loss=-1.6843 scale=2.0000 norm=1.0812\n",
      "[iter 86] loss=-1.9444 val_loss=-1.6871 scale=2.0000 norm=1.0834\n",
      "[iter 87] loss=-1.9478 val_loss=-1.6898 scale=2.0000 norm=1.0856\n",
      "[iter 88] loss=-1.9510 val_loss=-1.6926 scale=2.0000 norm=1.0878\n",
      "[iter 89] loss=-1.9542 val_loss=-1.6949 scale=2.0000 norm=1.0897\n",
      "[iter 90] loss=-1.9572 val_loss=-1.6964 scale=2.0000 norm=1.0919\n",
      "[iter 91] loss=-1.9599 val_loss=-1.6983 scale=2.0000 norm=1.0939\n",
      "[iter 92] loss=-1.9625 val_loss=-1.6999 scale=2.0000 norm=1.0962\n",
      "[iter 93] loss=-1.9650 val_loss=-1.7017 scale=2.0000 norm=1.0983\n",
      "[iter 94] loss=-1.9673 val_loss=-1.7031 scale=2.0000 norm=1.1005\n",
      "[iter 95] loss=-1.9695 val_loss=-1.7055 scale=2.0000 norm=1.1025\n",
      "[iter 96] loss=-1.9720 val_loss=-1.7066 scale=2.0000 norm=1.1044\n",
      "[iter 97] loss=-1.9739 val_loss=-1.7080 scale=2.0000 norm=1.1064\n",
      "[iter 98] loss=-1.9759 val_loss=-1.7085 scale=2.0000 norm=1.1084\n",
      "[iter 99] loss=-1.9776 val_loss=-1.7097 scale=2.0000 norm=1.1104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187704</td>\n",
       "      <td>0.038029</td>\n",
       "      <td>1.164785</td>\n",
       "      <td>0.033303</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.156425</td>\n",
       "      <td>1.473215</td>\n",
       "      <td>-6.075313</td>\n",
       "      <td>4.263320</td>\n",
       "      <td>-1.473215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>0.038372</td>\n",
       "      <td>1.246101</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.178364</td>\n",
       "      <td>1.494113</td>\n",
       "      <td>-4.719543</td>\n",
       "      <td>4.484756</td>\n",
       "      <td>-1.494113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.182307</td>\n",
       "      <td>0.040349</td>\n",
       "      <td>1.336160</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.185239</td>\n",
       "      <td>1.541484</td>\n",
       "      <td>-4.821566</td>\n",
       "      <td>4.479520</td>\n",
       "      <td>-1.541484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.184142</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>1.496363</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.201854</td>\n",
       "      <td>1.548836</td>\n",
       "      <td>-4.184379</td>\n",
       "      <td>4.534267</td>\n",
       "      <td>-1.548836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.184317</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>1.628630</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.218838</td>\n",
       "      <td>1.555159</td>\n",
       "      <td>-4.703335</td>\n",
       "      <td>4.541864</td>\n",
       "      <td>-1.555159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.173753</td>\n",
       "      <td>0.038429</td>\n",
       "      <td>1.334697</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.336356</td>\n",
       "      <td>1.535138</td>\n",
       "      <td>-5.305507</td>\n",
       "      <td>3.883163</td>\n",
       "      <td>-1.535138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.176047</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>1.352622</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.332419</td>\n",
       "      <td>1.516063</td>\n",
       "      <td>-5.038930</td>\n",
       "      <td>4.063579</td>\n",
       "      <td>-1.516063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.170049</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>1.289128</td>\n",
       "      <td>0.030654</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>1.563181</td>\n",
       "      <td>-4.799214</td>\n",
       "      <td>4.152831</td>\n",
       "      <td>-1.563181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.168666</td>\n",
       "      <td>0.038720</td>\n",
       "      <td>1.196543</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.254798</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>-3.481848</td>\n",
       "      <td>4.170091</td>\n",
       "      <td>-1.578751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.170998</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>1.191742</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.238409</td>\n",
       "      <td>1.577633</td>\n",
       "      <td>-3.721131</td>\n",
       "      <td>4.189348</td>\n",
       "      <td>-1.577633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interval  CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0          1            0.187704           0.038029           1.164785   \n",
       "1          2            0.187533           0.038372           1.246101   \n",
       "2          3            0.182307           0.040349           1.336160   \n",
       "3          4            0.184142           0.037082           1.496363   \n",
       "4          5            0.184317           0.037989           1.628630   \n",
       "..       ...                 ...                ...                ...   \n",
       "91        92            0.173753           0.038429           1.334697   \n",
       "92        93            0.176047           0.038493           1.352622   \n",
       "93        94            0.170049           0.039501           1.289128   \n",
       "94        95            0.168666           0.038720           1.196543   \n",
       "95        96            0.170998           0.038377           1.191742   \n",
       "\n",
       "    CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0              0.033303            0.002158            0.156425  1.473215   \n",
       "1              0.032628            0.002150            0.178364  1.494113   \n",
       "2              0.031388            0.002226            0.185239  1.541484   \n",
       "3              0.031137            0.001851            0.201854  1.548836   \n",
       "4              0.030952            0.001867            0.218838  1.555159   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "91             0.031001            0.001916            0.336356  1.535138   \n",
       "92             0.031599            0.001543            0.332419  1.516063   \n",
       "93             0.030654            0.001396            0.357609  1.563181   \n",
       "94             0.030240            0.002529            0.254798  1.578751   \n",
       "95             0.030445            0.002249            0.238409  1.577633   \n",
       "\n",
       "     NLL_min   NLL_max  model_scores  \n",
       "0  -6.075313  4.263320     -1.473215  \n",
       "1  -4.719543  4.484756     -1.494113  \n",
       "2  -4.821566  4.479520     -1.541484  \n",
       "3  -4.184379  4.534267     -1.548836  \n",
       "4  -4.703335  4.541864     -1.555159  \n",
       "..       ...       ...           ...  \n",
       "91 -5.305507  3.883163     -1.535138  \n",
       "92 -5.038930  4.063579     -1.516063  \n",
       "93 -4.799214  4.152831     -1.563181  \n",
       "94 -3.481848  4.170091     -1.578751  \n",
       "95 -3.721131  4.189348     -1.577633  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>CRPS_gaussian_min</th>\n",
       "      <th>CRPS_gaussian_max</th>\n",
       "      <th>CRPS_lognormal_mean</th>\n",
       "      <th>CRPS_lognormal_min</th>\n",
       "      <th>CRPS_lognormal_max</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>NLL_max</th>\n",
       "      <th>model_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>4.081012</td>\n",
       "      <td>0.029501</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>1.709748</td>\n",
       "      <td>-10.35608</td>\n",
       "      <td>5.25084</td>\n",
       "      <td>-1.709748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRPS_gaussian_mean  CRPS_gaussian_min  CRPS_gaussian_max  \\\n",
       "0            0.181416           0.035303           4.081012   \n",
       "\n",
       "   CRPS_lognormal_mean  CRPS_lognormal_min  CRPS_lognormal_max  NLL_mean  \\\n",
       "0             0.029501            0.000928            0.357609  1.709748   \n",
       "\n",
       "    NLL_min  NLL_max  model_scores_mean  \n",
       "0 -10.35608  5.25084          -1.709748  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_no</th>\n",
       "      <th>CRPS_gaussian</th>\n",
       "      <th>CRPS_lognormal</th>\n",
       "      <th>NLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.144633</td>\n",
       "      <td>0.095899</td>\n",
       "      <td>0.536357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.128880</td>\n",
       "      <td>0.086633</td>\n",
       "      <td>0.647949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.152793</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>0.482264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.113857</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.760556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.140725</td>\n",
       "      <td>0.091927</td>\n",
       "      <td>0.582825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>35036</td>\n",
       "      <td>0.205726</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>0.283437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>35037</td>\n",
       "      <td>0.256158</td>\n",
       "      <td>0.102968</td>\n",
       "      <td>-0.180527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>35038</td>\n",
       "      <td>0.223055</td>\n",
       "      <td>0.089436</td>\n",
       "      <td>0.132752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>35039</td>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.309181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>35040</td>\n",
       "      <td>0.209879</td>\n",
       "      <td>0.087130</td>\n",
       "      <td>0.213970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35040 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Entry_no  CRPS_gaussian  CRPS_lognormal       NLL\n",
       "0             1       0.144633        0.095899  0.536357\n",
       "1             2       0.128880        0.086633  0.647949\n",
       "2             3       0.152793        0.100019  0.482264\n",
       "3             4       0.113857        0.076694  0.760556\n",
       "4             5       0.140725        0.091927  0.582825\n",
       "...         ...            ...             ...       ...\n",
       "35035     35036       0.205726        0.082926  0.283437\n",
       "35036     35037       0.256158        0.102968 -0.180527\n",
       "35037     35038       0.223055        0.089436  0.132752\n",
       "35038     35039       0.201806        0.082178  0.309181\n",
       "35039     35040       0.209879        0.087130  0.213970\n",
       "\n",
       "[35040 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_columns</th>\n",
       "      <th>distribution</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entsoe</td>\n",
       "      <td>[power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...</td>\n",
       "      <td>&lt;class 'ngboost.distns.lognormal.LogNormal'&gt;</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                                    feature_columns  \\\n",
       "0  entsoe  [power_t-96, ws_10m_loc_mean, ws_100m_loc_mean...   \n",
       "\n",
       "                                   distribution  \\\n",
       "0  <class 'ngboost.distns.lognormal.LogNormal'>   \n",
       "\n",
       "                       loss_function  iterations  learning_rate  random_state  \n",
       "0  <class 'ngboost.scores.LogScore'>         100           0.03            42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entsoe = load_entsoe()\n",
    "evaluate_model(entsoe, n_estimators=100, case=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge summary statistics into one excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed! The final file is 'Merged_Sheet.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Step 1: Get all Excel files in a folder\n",
    "file_paths = glob.glob(\"../results/NGBoost/*.xlsx\")  # Update with the correct path\n",
    "merged_data = []\n",
    "\n",
    "\n",
    "# Step 2: Loop through each file and extract both sheets\n",
    "for file in file_paths:\n",
    "    try:\n",
    "        # Read \"Summary_Scores\" sheet\n",
    "        df_scores = pd.read_excel(file, sheet_name=\"Summary_Scores\")\n",
    "        df_scores[\"Source_File\"] = file  # Optional: Track source file\n",
    "        \n",
    "        # Read \"Hyperparameters\" sheet\n",
    "        df_hyperparams = pd.read_excel(file, sheet_name=\"Hyperparameters\")\n",
    "        df_hyperparams[\"Source_File\"] = file  # Optional: Track source file\n",
    "\n",
    "        # Combine the two dataframes horizontally (side by side)\n",
    "        combined_df = pd.concat([df_scores, df_hyperparams], axis=1)\n",
    "        merged_data.append(combined_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {file}: {e}\")\n",
    "\n",
    "# Step 3: Merge all data into one DataFrame\n",
    "final_merged_df = pd.concat(merged_data, ignore_index=True)\n",
    "\n",
    "# Step 4: Save to a new Excel file\n",
    "final_merged_df.to_excel(\"../results/NGBoost/Merged_Sheet.xlsx\", index=False)\n",
    "\n",
    "print(\"Merge completed! The final file is 'Merged_Sheet.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRPS_gaussian_mean</th>\n",
       "      <th>NLL_mean</th>\n",
       "      <th>NLL_min</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>feature_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594162</td>\n",
       "      <td>0.357223</td>\n",
       "      <td>-76.403841</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['power_t-96']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182783</td>\n",
       "      <td>1.706868</td>\n",
       "      <td>-10.243708</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183625</td>\n",
       "      <td>1.707729</td>\n",
       "      <td>-13.281745</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181416</td>\n",
       "      <td>1.709748</td>\n",
       "      <td>-10.356080</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.598208</td>\n",
       "      <td>0.391899</td>\n",
       "      <td>-22.429360</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['power_t-96']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.274447</td>\n",
       "      <td>1.300109</td>\n",
       "      <td>-25.411731</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['ws_10m_loc_mean', 'ws_100m_loc_mean']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277985</td>\n",
       "      <td>1.296382</td>\n",
       "      <td>-19.878298</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['ws_10m_loc_mean', 'ws_100m_loc_mean']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267949</td>\n",
       "      <td>1.328880</td>\n",
       "      <td>-22.550611</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.269698</td>\n",
       "      <td>1.334739</td>\n",
       "      <td>-18.039244</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.182779</td>\n",
       "      <td>1.714674</td>\n",
       "      <td>-22.048296</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.182838</td>\n",
       "      <td>1.704331</td>\n",
       "      <td>-9.897822</td>\n",
       "      <td>&lt;class 'ngboost.scores.LogScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.183389</td>\n",
       "      <td>1.713057</td>\n",
       "      <td>-15.890658</td>\n",
       "      <td>&lt;class 'ngboost.scores.CRPScore'&gt;</td>\n",
       "      <td>['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRPS_gaussian_mean  NLL_mean    NLL_min  \\\n",
       "0             0.594162  0.357223 -76.403841   \n",
       "1             0.182783  1.706868 -10.243708   \n",
       "2             0.183625  1.707729 -13.281745   \n",
       "3             0.181416  1.709748 -10.356080   \n",
       "4             0.598208  0.391899 -22.429360   \n",
       "5             0.274447  1.300109 -25.411731   \n",
       "6             0.277985  1.296382 -19.878298   \n",
       "7             0.267949  1.328880 -22.550611   \n",
       "8             0.269698  1.334739 -18.039244   \n",
       "9             0.182779  1.714674 -22.048296   \n",
       "10            0.182838  1.704331  -9.897822   \n",
       "11            0.183389  1.713057 -15.890658   \n",
       "\n",
       "                        loss_function  \\\n",
       "0   <class 'ngboost.scores.CRPScore'>   \n",
       "1   <class 'ngboost.scores.LogScore'>   \n",
       "2   <class 'ngboost.scores.CRPScore'>   \n",
       "3   <class 'ngboost.scores.LogScore'>   \n",
       "4   <class 'ngboost.scores.LogScore'>   \n",
       "5   <class 'ngboost.scores.CRPScore'>   \n",
       "6   <class 'ngboost.scores.LogScore'>   \n",
       "7   <class 'ngboost.scores.CRPScore'>   \n",
       "8   <class 'ngboost.scores.LogScore'>   \n",
       "9   <class 'ngboost.scores.CRPScore'>   \n",
       "10  <class 'ngboost.scores.LogScore'>   \n",
       "11  <class 'ngboost.scores.CRPScore'>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                        feature_columns  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                        ['power_t-96']  \n",
       "1                     ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']  \n",
       "2   ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']  \n",
       "3   ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10', 'interval_index']  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                        ['power_t-96']  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                               ['ws_10m_loc_mean', 'ws_100m_loc_mean']  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                               ['ws_10m_loc_mean', 'ws_100m_loc_mean']  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                 ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']  \n",
       "8                                                                                                                                                                                                                                                                                                                                                                 ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean']  \n",
       "9                                                            ['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']  \n",
       "10                                                           ['power_t-96', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']  \n",
       "11                    ['power_t-96', 'ws_10m_loc_mean', 'ws_100m_loc_mean', 'ws_10m_loc_1', 'ws_10m_loc_2', 'ws_10m_loc_3', 'ws_10m_loc_4', 'ws_10m_loc_5', 'ws_10m_loc_6', 'ws_10m_loc_7', 'ws_10m_loc_8', 'ws_10m_loc_9', 'ws_10m_loc_10', 'ws_100m_loc_1', 'ws_100m_loc_2', 'ws_100m_loc_3', 'ws_100m_loc_4', 'ws_100m_loc_5', 'ws_100m_loc_6', 'ws_100m_loc_7', 'ws_100m_loc_8', 'ws_100m_loc_9', 'ws_100m_loc_10']  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # Do not truncate content in columns\n",
    "final_merged_df[['CRPS_gaussian_mean', 'NLL_mean', 'NLL_min', 'loss_function', 'feature_columns']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
