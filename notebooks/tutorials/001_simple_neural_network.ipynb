{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165c7654-73f4-44e5-ad4b-81a2f6dd67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6885\n",
      "Epoch [2/100], Loss: 0.6568\n",
      "Epoch [3/100], Loss: 0.6155\n",
      "Epoch [4/100], Loss: 0.5647\n",
      "Epoch [5/100], Loss: 0.5009\n",
      "Epoch [6/100], Loss: 0.4360\n",
      "Epoch [7/100], Loss: 0.3856\n",
      "Epoch [8/100], Loss: 0.3455\n",
      "Epoch [9/100], Loss: 0.3242\n",
      "Epoch [10/100], Loss: 0.3078\n",
      "Epoch [11/100], Loss: 0.2985\n",
      "Epoch [12/100], Loss: 0.2833\n",
      "Epoch [13/100], Loss: 0.2702\n",
      "Epoch [14/100], Loss: 0.2674\n",
      "Epoch [15/100], Loss: 0.2528\n",
      "Epoch [16/100], Loss: 0.2457\n",
      "Epoch [17/100], Loss: 0.2406\n",
      "Epoch [18/100], Loss: 0.2333\n",
      "Epoch [19/100], Loss: 0.2253\n",
      "Epoch [20/100], Loss: 0.2258\n",
      "Epoch [21/100], Loss: 0.2101\n",
      "Epoch [22/100], Loss: 0.2054\n",
      "Epoch [23/100], Loss: 0.2018\n",
      "Epoch [24/100], Loss: 0.1921\n",
      "Epoch [25/100], Loss: 0.1876\n",
      "Epoch [26/100], Loss: 0.1849\n",
      "Epoch [27/100], Loss: 0.1801\n",
      "Epoch [28/100], Loss: 0.1753\n",
      "Epoch [29/100], Loss: 0.1733\n",
      "Epoch [30/100], Loss: 0.1653\n",
      "Epoch [31/100], Loss: 0.1601\n",
      "Epoch [32/100], Loss: 0.1565\n",
      "Epoch [33/100], Loss: 0.1518\n",
      "Epoch [34/100], Loss: 0.1481\n",
      "Epoch [35/100], Loss: 0.1459\n",
      "Epoch [36/100], Loss: 0.1483\n",
      "Epoch [37/100], Loss: 0.1433\n",
      "Epoch [38/100], Loss: 0.1394\n",
      "Epoch [39/100], Loss: 0.1380\n",
      "Epoch [40/100], Loss: 0.1355\n",
      "Epoch [41/100], Loss: 0.1308\n",
      "Epoch [42/100], Loss: 0.1263\n",
      "Epoch [43/100], Loss: 0.1270\n",
      "Epoch [44/100], Loss: 0.1205\n",
      "Epoch [45/100], Loss: 0.1194\n",
      "Epoch [46/100], Loss: 0.1178\n",
      "Epoch [47/100], Loss: 0.1151\n",
      "Epoch [48/100], Loss: 0.1119\n",
      "Epoch [49/100], Loss: 0.1085\n",
      "Epoch [50/100], Loss: 0.1103\n",
      "Epoch [51/100], Loss: 0.1092\n",
      "Epoch [52/100], Loss: 0.1054\n",
      "Epoch [53/100], Loss: 0.1021\n",
      "Epoch [54/100], Loss: 0.1030\n",
      "Epoch [55/100], Loss: 0.1008\n",
      "Epoch [56/100], Loss: 0.1013\n",
      "Epoch [57/100], Loss: 0.0993\n",
      "Epoch [58/100], Loss: 0.0987\n",
      "Epoch [59/100], Loss: 0.0972\n",
      "Epoch [60/100], Loss: 0.0932\n",
      "Epoch [61/100], Loss: 0.0933\n",
      "Epoch [62/100], Loss: 0.0958\n",
      "Epoch [63/100], Loss: 0.0933\n",
      "Epoch [64/100], Loss: 0.0892\n",
      "Epoch [65/100], Loss: 0.0930\n",
      "Epoch [66/100], Loss: 0.0855\n",
      "Epoch [67/100], Loss: 0.0834\n",
      "Epoch [68/100], Loss: 0.0846\n",
      "Epoch [69/100], Loss: 0.0823\n",
      "Epoch [70/100], Loss: 0.0846\n",
      "Epoch [71/100], Loss: 0.0804\n",
      "Epoch [72/100], Loss: 0.0804\n",
      "Epoch [73/100], Loss: 0.0821\n",
      "Epoch [74/100], Loss: 0.0765\n",
      "Epoch [75/100], Loss: 0.0753\n",
      "Epoch [76/100], Loss: 0.0761\n",
      "Epoch [77/100], Loss: 0.0770\n",
      "Epoch [78/100], Loss: 0.0733\n",
      "Epoch [79/100], Loss: 0.0731\n",
      "Epoch [80/100], Loss: 0.0694\n",
      "Epoch [81/100], Loss: 0.0714\n",
      "Epoch [82/100], Loss: 0.0746\n",
      "Epoch [83/100], Loss: 0.0669\n",
      "Epoch [84/100], Loss: 0.0715\n",
      "Epoch [85/100], Loss: 0.0651\n",
      "Epoch [86/100], Loss: 0.0659\n",
      "Epoch [87/100], Loss: 0.0641\n",
      "Epoch [88/100], Loss: 0.0620\n",
      "Epoch [89/100], Loss: 0.0648\n",
      "Epoch [90/100], Loss: 0.0594\n",
      "Epoch [91/100], Loss: 0.0611\n",
      "Epoch [92/100], Loss: 0.0582\n",
      "Epoch [93/100], Loss: 0.0604\n",
      "Epoch [94/100], Loss: 0.0572\n",
      "Epoch [95/100], Loss: 0.0555\n",
      "Epoch [96/100], Loss: 0.0545\n",
      "Epoch [97/100], Loss: 0.0616\n",
      "Epoch [98/100], Loss: 0.0576\n",
      "Epoch [99/100], Loss: 0.0538\n",
      "Epoch [100/100], Loss: 0.0532\n",
      "Accuracy on test set: 0.9550\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Generate fake data\n",
    "# Generate a binary classification dataset using make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output is 1 because it's binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "model = SimpleNN(input_size)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch).squeeze()  # Remove extra dimension\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 4. Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor).squeeze()\n",
    "    predicted = (outputs > 0.5).float()  # Convert to binary prediction\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "\n",
    "# Optional: Plot the loss or accuracy if desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f55dba-b8c2-42d4-805f-993c3240a7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0009], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1.0 for _ in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c87843-072c-4b32-a3f7-d7f27d083c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "968f59dd-1f73-4db2-8b92-78125ba83e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.125100</td>\n",
       "      <td>1.178124</td>\n",
       "      <td>0.493516</td>\n",
       "      <td>0.790880</td>\n",
       "      <td>-0.614278</td>\n",
       "      <td>1.347020</td>\n",
       "      <td>1.419515</td>\n",
       "      <td>1.357325</td>\n",
       "      <td>0.966041</td>\n",
       "      <td>-1.981139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.564641</td>\n",
       "      <td>3.638629</td>\n",
       "      <td>-1.522415</td>\n",
       "      <td>-1.541705</td>\n",
       "      <td>1.616697</td>\n",
       "      <td>4.781310</td>\n",
       "      <td>3.190292</td>\n",
       "      <td>-0.890254</td>\n",
       "      <td>1.438826</td>\n",
       "      <td>-3.828748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516313</td>\n",
       "      <td>2.165426</td>\n",
       "      <td>-0.628486</td>\n",
       "      <td>-0.386923</td>\n",
       "      <td>0.492518</td>\n",
       "      <td>1.442381</td>\n",
       "      <td>1.332905</td>\n",
       "      <td>-1.958175</td>\n",
       "      <td>-0.348803</td>\n",
       "      <td>-1.804124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537282</td>\n",
       "      <td>0.966618</td>\n",
       "      <td>-0.115420</td>\n",
       "      <td>0.670755</td>\n",
       "      <td>-0.958516</td>\n",
       "      <td>0.871440</td>\n",
       "      <td>0.508186</td>\n",
       "      <td>-1.034471</td>\n",
       "      <td>-1.654176</td>\n",
       "      <td>-1.910503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278385</td>\n",
       "      <td>1.065828</td>\n",
       "      <td>-1.724917</td>\n",
       "      <td>-2.235667</td>\n",
       "      <td>0.715107</td>\n",
       "      <td>0.731249</td>\n",
       "      <td>-0.674119</td>\n",
       "      <td>0.598330</td>\n",
       "      <td>-0.524283</td>\n",
       "      <td>1.047610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.906303</td>\n",
       "      <td>-0.527162</td>\n",
       "      <td>-1.511787</td>\n",
       "      <td>-1.697166</td>\n",
       "      <td>-0.585131</td>\n",
       "      <td>0.160046</td>\n",
       "      <td>-2.225249</td>\n",
       "      <td>1.480886</td>\n",
       "      <td>-0.934154</td>\n",
       "      <td>1.151678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.225603</td>\n",
       "      <td>-1.389881</td>\n",
       "      <td>-0.406775</td>\n",
       "      <td>-1.606446</td>\n",
       "      <td>2.500944</td>\n",
       "      <td>-1.089977</td>\n",
       "      <td>0.452517</td>\n",
       "      <td>-1.765429</td>\n",
       "      <td>1.297249</td>\n",
       "      <td>4.705105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.650153</td>\n",
       "      <td>-0.692165</td>\n",
       "      <td>-2.049206</td>\n",
       "      <td>-1.610471</td>\n",
       "      <td>0.119157</td>\n",
       "      <td>-0.876080</td>\n",
       "      <td>-1.368269</td>\n",
       "      <td>-1.302577</td>\n",
       "      <td>-1.285505</td>\n",
       "      <td>3.328569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.186603</td>\n",
       "      <td>-1.414598</td>\n",
       "      <td>-0.121520</td>\n",
       "      <td>-1.440709</td>\n",
       "      <td>1.630283</td>\n",
       "      <td>-2.034632</td>\n",
       "      <td>-1.537456</td>\n",
       "      <td>-1.421465</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>3.413932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.788676</td>\n",
       "      <td>-0.222547</td>\n",
       "      <td>0.328570</td>\n",
       "      <td>-1.654945</td>\n",
       "      <td>0.764075</td>\n",
       "      <td>0.620435</td>\n",
       "      <td>-0.132118</td>\n",
       "      <td>-1.291040</td>\n",
       "      <td>-2.338172</td>\n",
       "      <td>2.036021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.125100  1.178124  0.493516  0.790880 -0.614278  1.347020  1.419515   \n",
       "1   -0.564641  3.638629 -1.522415 -1.541705  1.616697  4.781310  3.190292   \n",
       "2    0.516313  2.165426 -0.628486 -0.386923  0.492518  1.442381  1.332905   \n",
       "3    0.537282  0.966618 -0.115420  0.670755 -0.958516  0.871440  0.508186   \n",
       "4    0.278385  1.065828 -1.724917 -2.235667  0.715107  0.731249 -0.674119   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -0.906303 -0.527162 -1.511787 -1.697166 -0.585131  0.160046 -2.225249   \n",
       "996  1.225603 -1.389881 -0.406775 -1.606446  2.500944 -1.089977  0.452517   \n",
       "997  1.650153 -0.692165 -2.049206 -1.610471  0.119157 -0.876080 -1.368269   \n",
       "998 -1.186603 -1.414598 -0.121520 -1.440709  1.630283 -2.034632 -1.537456   \n",
       "999  0.788676 -0.222547  0.328570 -1.654945  0.764075  0.620435 -0.132118   \n",
       "\n",
       "            7         8         9  \n",
       "0    1.357325  0.966041 -1.981139  \n",
       "1   -0.890254  1.438826 -3.828748  \n",
       "2   -1.958175 -0.348803 -1.804124  \n",
       "3   -1.034471 -1.654176 -1.910503  \n",
       "4    0.598330 -0.524283  1.047610  \n",
       "..        ...       ...       ...  \n",
       "995  1.480886 -0.934154  1.151678  \n",
       "996 -1.765429  1.297249  4.705105  \n",
       "997 -1.302577 -1.285505  3.328569  \n",
       "998 -1.421465 -0.028340  3.413932  \n",
       "999 -1.291040 -2.338172  2.036021  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
